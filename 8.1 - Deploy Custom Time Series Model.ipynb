{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3660089-37d7-4f85-b85d-62b398d44746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mStored 's3_datalake_path_csv' (str)\n",
      "Stored 'local_data_path_csv' (str)\n",
      "Stored 's3_datalake_path_parquet' (str)\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "%run 0-Environment_Setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cff3779b-618f-4926-b735-114d7ea8e942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import model card libraries\n",
    "from sagemaker.model_card import (\n",
    "    ModelCard,\n",
    "    ModelOverview,\n",
    "    ObjectiveFunction,\n",
    "    Function,\n",
    "    TrainingDetails,\n",
    "    TrainingJobDetails,\n",
    "    IntendedUses,\n",
    "    BusinessDetails,\n",
    "    EvaluationJob,\n",
    "    AdditionalInformation,\n",
    "    Metric,\n",
    "    MetricGroup,\n",
    "    ModelCardStatusEnum,\n",
    "    ObjectiveFunctionEnum,\n",
    "    FacetEnum,\n",
    "    RiskRatingEnum,\n",
    "    MetricTypeEnum,\n",
    "    EvaluationMetricTypeEnum,\n",
    "    HyperParameter\n",
    ")\n",
    "\n",
    "from sagemaker.transformer import Transformer\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a04ba70b-754d-4345-95a8-9e992ac49578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set session variables\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "train_prefix = \"store-sales-forecasting/train\"\n",
    "test_prefix = \"store-sales-forecasting/test\"\n",
    "val_prefix = \"store-sales-forecasting/val\"\n",
    "transform_input_prefix = \"store-sales-forecasting/transform-input\"\n",
    "transform_output_prefix = \"store-sales-forecasting/transform-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "567b75de-016f-48e0-9e7e-346e7d2c93d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Models': [{'ModelName': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46',\n",
       "   'ModelArn': 'arn:aws:sagemaker:us-east-1:342408968837:model/store-sales-forecasting-custom-model-2024-10-15-05-53-46',\n",
       "   'CreationTime': datetime.datetime(2024, 10, 15, 5, 53, 47, 276000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': '3248e4ff-9a3c-4b3c-958a-519db5773e86',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3248e4ff-9a3c-4b3c-958a-519db5773e86',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '234',\n",
       "   'date': 'Tue, 15 Oct 2024 06:16:00 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List available models\n",
    "sm_client.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7bd5a872-b71a-449c-be26-c07f501cd431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store-sales-forecasting-custom-model-2024-10-15-05-53-46\n",
      "{'ModelName': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46', 'PrimaryContainer': {'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.6-cpu', 'Mode': 'SingleModel', 'ModelDataUrl': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz', 'ModelDataSource': {'S3DataSource': {'S3Uri': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz', 'S3DataType': 'S3Object', 'CompressionType': 'Gzip'}}, 'Environment': {'SAGEMAKER_TFS_NGINX_LOGLEVEL': 'info'}}, 'ExecutionRoleArn': 'arn:aws:iam::342408968837:role/LabRole', 'CreationTime': datetime.datetime(2024, 10, 15, 5, 53, 47, 276000, tzinfo=tzlocal()), 'ModelArn': 'arn:aws:sagemaker:us-east-1:342408968837:model/store-sales-forecasting-custom-model-2024-10-15-05-53-46', 'EnableNetworkIsolation': False, 'DeploymentRecommendation': {'RecommendationStatus': 'COMPLETED', 'RealTimeInferenceRecommendations': [{'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/waO1grQ5', 'InstanceType': 'ml.c6i.xlarge', 'Environment': {}}, {'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/Fl7Duel9', 'InstanceType': 'ml.c5.2xlarge', 'Environment': {}}, {'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/V7SKdrtB', 'InstanceType': 'ml.c5.large', 'Environment': {}}]}, 'ResponseMetadata': {'RequestId': '2d15b6f7-d80c-43cd-8f52-7981ff0e30f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2d15b6f7-d80c-43cd-8f52-7981ff0e30f1', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1399', 'date': 'Tue, 15 Oct 2024 07:23:57 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Get most recent model info\n",
    "model_name = sm_client.list_models()['Models'][0]['ModelName']\n",
    "model_info = sm_client.describe_model(ModelName=model_name)\n",
    "model_container = {\n",
    "    \"Image\": model_info['PrimaryContainer']['Image'],\n",
    "    \"ModelDataUrl\": model_info['PrimaryContainer']['ModelDataUrl']\n",
    "}\n",
    "    \n",
    "print(model_name)\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "296b588a-8faa-4715-b9da-25bf4a80fea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure a transformer for the model\n",
    "transformer = Transformer(\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=f's3://{sagemaker_session.default_bucket()}/store-sales-forecasting/transform-output/',\n",
    "    accept=\"application/jsonlines\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46dfcdd4-2469-464f-9de6-6a0f488e348b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: tensorflow-inference-2024-10-15-06-49-21-583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34mINFO:__main__:PYTHON SERVICE: False\u001b[0m\n",
      "\u001b[34mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[34mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[34mmodel_config_list: {\n",
      "  config: {\n",
      "    name: 'model'\n",
      "    base_path: '/opt/ml/model'\n",
      "    model_platform: 'tensorflow'\n",
      "    model_version_policy: {\n",
      "      specific: {\n",
      "        versions: 1\n",
      "      }\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:23.588990: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:23.589082: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34mTensorFlow ModelServer: 2.6.0-rc2+dev.sha.dca3641\u001b[0m\n",
      "\u001b[34mTensorFlow Library: 2.6.0\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0    \u001b[0m\n",
      "\u001b[34mINFO:__main__:started tensorflow serving (pid: 16)\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:Trying to connect with model server: http://localhost:10001/v1/models/model\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2940>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.042529: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.042615: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.044364: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.044397: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144641: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144675: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144683: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144694: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144927: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.163685: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.163716: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.163821: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.164783: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2bb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.253389: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.374139: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.418720: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 273791 microseconds.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.424606: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.431612: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.431641: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.432689: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.432750: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.432764: I tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.433933: I tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[34m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[34m[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.434758: I tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2dc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:<Response [200]>\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:model: http://localhost:10001/v1/models/model is available now\u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[34mload_module modules/ngx_http_js_module.so;\u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr info;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_import tensorflowServing.js;\n",
      "  proxy_read_timeout 60;  \n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "    set $tfs_version 2.6;\n",
      "    set $default_tfs_model model;\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "    location /ping {\n",
      "        js_content tensorflowServing.ping;\n",
      "    }\n",
      "    location /invocations {\n",
      "        js_content tensorflowServing.invocations;\n",
      "    }\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "  \u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[34mnginx version: nginx/1.22.0\u001b[0m\n",
      "\u001b[34mbuilt by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34mbuilt with OpenSSL 1.1.1f  31 Mar 2020\u001b[0m\n",
      "\u001b[34mTLS SNI support enabled\u001b[0m\n",
      "\u001b[34mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.22.0/debian/debuild-base/nginx-1.22.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[34mINFO:__main__:started nginx (pid: 73)\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: nginx/1.22.0\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: built by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: OS: Linux 4.14.352-268.568.amzn2.x86_64\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker processes\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 74\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 75\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 76\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 77\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:27 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:27 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:27 [info] 74#74: *1 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\u001b[32m2024-10-15T06:54:27.598:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:31 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:31 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:31 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Oct/2024:06:54:31 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:33 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:33 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:33 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Oct/2024:06:54:33 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[34mINFO:__main__:PYTHON SERVICE: False\u001b[0m\n",
      "\u001b[34mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[34mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[35mINFO:__main__:PYTHON SERVICE: False\u001b[0m\n",
      "\u001b[35mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[35mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[34mmodel_config_list: {\n",
      "  config: {\n",
      "    name: 'model'\n",
      "    base_path: '/opt/ml/model'\n",
      "    model_platform: 'tensorflow'\n",
      "    model_version_policy: {\n",
      "      specific: {\n",
      "        versions: 1\n",
      "      }\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:23.588990: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:23.589082: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34mTensorFlow ModelServer: 2.6.0-rc2+dev.sha.dca3641\u001b[0m\n",
      "\u001b[34mTensorFlow Library: 2.6.0\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0    \u001b[0m\n",
      "\u001b[34mINFO:__main__:started tensorflow serving (pid: 16)\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:Trying to connect with model server: http://localhost:10001/v1/models/model\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2940>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.042529: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.042615: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.044364: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.044397: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144641: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144675: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144683: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144694: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.144927: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.163685: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.163716: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.163821: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.164783: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2bb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.253389: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.374139: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.418720: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 273791 microseconds.\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.424606: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.431612: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.431641: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.432689: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.432750: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.432764: I tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.433933: I tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[34m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[34m[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[34m2024-10-15 06:54:24.434758: I tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2dc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:<Response [200]>\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:model: http://localhost:10001/v1/models/model is available now\u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[34mload_module modules/ngx_http_js_module.so;\u001b[0m\n",
      "\u001b[35mmodel_config_list: {\n",
      "  config: {\n",
      "    name: 'model'\n",
      "    base_path: '/opt/ml/model'\n",
      "    model_platform: 'tensorflow'\n",
      "    model_version_policy: {\n",
      "      specific: {\n",
      "        versions: 1\n",
      "      }\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:23.588990: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:23.589082: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35mTensorFlow ModelServer: 2.6.0-rc2+dev.sha.dca3641\u001b[0m\n",
      "\u001b[35mTensorFlow Library: 2.6.0\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0    \u001b[0m\n",
      "\u001b[35mINFO:__main__:started tensorflow serving (pid: 16)\u001b[0m\n",
      "\u001b[35mINFO:tfs_utils:Trying to connect with model server: http://localhost:10001/v1/models/model\u001b[0m\n",
      "\u001b[35mWARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2940>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.042529: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.042615: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.044364: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.044397: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.144641: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.144675: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.144683: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.144694: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.144927: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.163685: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.163716: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.163821: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.164783: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[35mWARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2bb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.253389: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.374139: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.418720: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 273791 microseconds.\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.424606: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.431612: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.431641: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.432689: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.432750: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.432764: I tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.433933: I tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[35m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[35m[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[35m2024-10-15 06:54:24.434758: I tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[35mWARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7292de2dc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[35mINFO:tfs_utils:<Response [200]>\u001b[0m\n",
      "\u001b[35mINFO:tfs_utils:model: http://localhost:10001/v1/models/model is available now\u001b[0m\n",
      "\u001b[35mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[35mload_module modules/ngx_http_js_module.so;\u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr info;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_import tensorflowServing.js;\n",
      "  proxy_read_timeout 60;  \n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "    set $tfs_version 2.6;\n",
      "    set $default_tfs_model model;\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "    location /ping {\n",
      "        js_content tensorflowServing.ping;\n",
      "    }\n",
      "    location /invocations {\n",
      "        js_content tensorflowServing.invocations;\n",
      "    }\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "  \u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[34mnginx version: nginx/1.22.0\u001b[0m\n",
      "\u001b[34mbuilt by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34mbuilt with OpenSSL 1.1.1f  31 Mar 2020\u001b[0m\n",
      "\u001b[34mTLS SNI support enabled\u001b[0m\n",
      "\u001b[34mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.22.0/debian/debuild-base/nginx-1.22.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[34mINFO:__main__:started nginx (pid: 73)\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: nginx/1.22.0\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: built by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: OS: Linux 4.14.352-268.568.amzn2.x86_64\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker processes\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 74\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 75\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 76\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:24 [notice] 73#73: start worker process 77\u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr info;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_import tensorflowServing.js;\n",
      "  proxy_read_timeout 60;  \n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "    set $tfs_version 2.6;\n",
      "    set $default_tfs_model model;\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "    location /ping {\n",
      "        js_content tensorflowServing.ping;\n",
      "    }\n",
      "    location /invocations {\n",
      "        js_content tensorflowServing.invocations;\n",
      "    }\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "  \u001b[0m\n",
      "\u001b[35mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[35mnginx version: nginx/1.22.0\u001b[0m\n",
      "\u001b[35mbuilt by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[35mbuilt with OpenSSL 1.1.1f  31 Mar 2020\u001b[0m\n",
      "\u001b[35mTLS SNI support enabled\u001b[0m\n",
      "\u001b[35mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.22.0/debian/debuild-base/nginx-1.22.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[35mINFO:__main__:started nginx (pid: 73)\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: nginx/1.22.0\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: built by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: OS: Linux 4.14.352-268.568.amzn2.x86_64\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: start worker processes\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: start worker process 74\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: start worker process 75\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: start worker process 76\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:24 [notice] 73#73: start worker process 77\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:27 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:27 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:27 [info] 74#74: *1 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Oct/2024:06:54:27 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Oct/2024:06:54:27 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:27 [info] 74#74: *1 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\u001b[32m2024-10-15T06:54:27.598:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:31 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:31 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:31 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Oct/2024:06:54:31 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/15 06:54:33 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Oct/2024:06:54:33 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/15 06:54:33 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Oct/2024:06:54:33 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run a batch transform job\n",
    "transformer.transform(\n",
    "    data=f\"s3://{sagemaker_session.default_bucket()}/{transform_input_prefix}\",\n",
    "    content_type=\"application/jsonlines\",\n",
    "    split_type=\"Line\"\n",
    ")\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5fbd1f8e-491a-4354-9cbb-3314a7bff071",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/val/val_targets.npy to transform-results/val_targets.npy\n",
      "download: s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/train/global_mean.npy to transform-results/global_mean.npy\n",
      "download: s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/train/global_stddev.npy to transform-results/global_stddev.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['transform-results/validation_data.ndjson.out']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download predictions from the batch transform job and true labels and normalization statistics\n",
    "transform_results_local_path = \"transform-results/\"\n",
    "val_targets_path = f\"s3://{sagemaker_session.default_bucket()}/{val_prefix}/val_targets.npy\"\n",
    "global_mean_path = f\"s3://{sagemaker_session.default_bucket()}/{train_prefix}/global_mean.npy\"\n",
    "global_stddev_path = f\"s3://{sagemaker_session.default_bucket()}/{train_prefix}/global_stddev.npy\"\n",
    "\n",
    "!aws s3 cp $val_targets_path $transform_results_local_path\n",
    "!aws s3 cp $global_mean_path $transform_results_local_path\n",
    "!aws s3 cp $global_stddev_path $transform_results_local_path\n",
    "sagemaker_session.download_data(path=transform_results_local_path, bucket=bucket, key_prefix=transform_output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e39c13fa-a801-4133-8f2d-75838132d518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 54, 1)\n",
      "[11066.08424029    72.62890566    23.37328494]\n",
      "[9928.63142484   26.6484683    43.2551771 ]\n"
     ]
    }
   ],
   "source": [
    "# Load npy objects\n",
    "val_targets = np.load(os.path.join(transform_results_local_path, 'val_targets.npy'))\n",
    "global_mean = np.load(os.path.join(transform_results_local_path, 'global_mean.npy'))\n",
    "global_stddev = np.load(os.path.join(transform_results_local_path, 'global_stddev.npy'))\n",
    "\n",
    "print(val_targets.shape)\n",
    "print(global_mean)\n",
    "print(global_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae945d7e-05d9-45e6-bb0f-cb211d7ab080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 54, 1)\n"
     ]
    }
   ],
   "source": [
    "# Deserialize the batch transform predictions\n",
    "import json\n",
    "\n",
    "with open(\"transform-results/validation_data.ndjson.out\", \"r\") as f:\n",
    "    predictions = []\n",
    "    for line in f:\n",
    "        obj = json.loads(line.strip())\n",
    "        predictions.extend(obj[\"predictions\"])\n",
    "\n",
    "predictions_array = np.array(predictions)\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "393713d0-8de4-4889-9d7a-e8d96cb039d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6825064042745805 MAE: 0.3680909023199403\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE and MAE on the normalized scale\n",
    "targets_flat = val_targets.flatten()\n",
    "predictions_flat = predictions_array.flatten()\n",
    "\n",
    "rmse = root_mean_squared_error(targets_flat, predictions_flat)\n",
    "mae = mean_absolute_error(targets_flat, predictions_flat)\n",
    "print(f\"RMSE: {rmse} MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "77175964-deb1-44ff-9823-b83438d97483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>actual_sales</th>\n",
       "      <th>predicted_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>13492.286087</td>\n",
       "      <td>12083.339608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7423</th>\n",
       "      <td>25</td>\n",
       "      <td>6874.695968</td>\n",
       "      <td>7183.365875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>35</td>\n",
       "      <td>10965.232037</td>\n",
       "      <td>13711.871552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>15</td>\n",
       "      <td>2574.605005</td>\n",
       "      <td>7627.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>35</td>\n",
       "      <td>13104.922932</td>\n",
       "      <td>10874.825765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>33</td>\n",
       "      <td>8512.265194</td>\n",
       "      <td>11260.313070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>23</td>\n",
       "      <td>13755.465668</td>\n",
       "      <td>18343.848409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>51</td>\n",
       "      <td>1220.737713</td>\n",
       "      <td>409.334942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8490</th>\n",
       "      <td>12</td>\n",
       "      <td>3479.584656</td>\n",
       "      <td>8257.628545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>1</td>\n",
       "      <td>14730.430556</td>\n",
       "      <td>16105.068781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>47</td>\n",
       "      <td>59776.353642</td>\n",
       "      <td>34369.506649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>3</td>\n",
       "      <td>18693.992032</td>\n",
       "      <td>17671.219363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>30</td>\n",
       "      <td>12675.693980</td>\n",
       "      <td>13321.036367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>50</td>\n",
       "      <td>29745.767200</td>\n",
       "      <td>23619.598492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>48</td>\n",
       "      <td>43393.774567</td>\n",
       "      <td>41099.328822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>6</td>\n",
       "      <td>16585.430234</td>\n",
       "      <td>20993.917334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>34</td>\n",
       "      <td>5083.268890</td>\n",
       "      <td>7450.953155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>50</td>\n",
       "      <td>21089.139441</td>\n",
       "      <td>23559.228540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687</th>\n",
       "      <td>19</td>\n",
       "      <td>10606.819704</td>\n",
       "      <td>14066.557682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>29</td>\n",
       "      <td>4137.743201</td>\n",
       "      <td>5894.872529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_nbr  actual_sales  predicted_sales\n",
       "26           26  13492.286087     12083.339608\n",
       "7423         25   6874.695968      7183.365875\n",
       "1061         35  10965.232037     13711.871552\n",
       "4983         15   2574.605005      7627.465347\n",
       "1277         35  13104.922932     10874.825765\n",
       "7269         33   8512.265194     11260.313070\n",
       "5045         23  13755.465668     18343.848409\n",
       "1941         51   1220.737713       409.334942\n",
       "8490         12   3479.584656      8257.628545\n",
       "3835          1  14730.430556     16105.068781\n",
       "1397         47  59776.353642     34369.506649\n",
       "3243          3  18693.992032     17671.219363\n",
       "3594         30  12675.693980     13321.036367\n",
       "3020         50  29745.767200     23619.598492\n",
       "4476         48  43393.774567     41099.328822\n",
       "2166          6  16585.430234     20993.917334\n",
       "7810         34   5083.268890      7450.953155\n",
       "3830         50  21089.139441     23559.228540\n",
       "7687         19  10606.819704     14066.557682\n",
       "4241         29   4137.743201      5894.872529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6776.354533133197 MAE: 3654.638899970415\n"
     ]
    }
   ],
   "source": [
    "# Denormalize to the original scale of the data\n",
    "targets_denormalized = val_targets * global_stddev[0] + global_mean[0]\n",
    "predictions_denormalized = predictions_array * global_stddev[0] + global_mean[0]\n",
    "\n",
    "targets_flat = targets_denormalized.flatten()\n",
    "predictions_flat = predictions_denormalized.flatten()\n",
    "\n",
    "# Join the predictions and actual sales values for each store/date into a dataframe\n",
    "n = predictions_denormalized.shape[0]\n",
    "store_numbers = list(range(54)) * n\n",
    "predictions_df = pd.DataFrame({'store_nbr': store_numbers, 'actual_sales': targets_flat, 'predicted_sales': predictions_flat})\n",
    "\n",
    "# View a random sample of 20 predicted vs actual sales values\n",
    "display(predictions_df.sample(20))\n",
    "\n",
    "# Compute RMSE and MAE on the original scale\n",
    "rmse = root_mean_squared_error(targets_flat, predictions_flat)\n",
    "mae = mean_absolute_error(targets_flat, predictions_flat)\n",
    "print(f\"RMSE: {rmse} MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "488815fd-599e-4d4d-887c-b9615a03d461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(27, 2, figsize=(15, 50), sharex=True)\n",
    "# axs = axs.ravel()\n",
    "# for i in range(54):\n",
    "#     ax = axs[i]\n",
    "#     store_data = predictions_df[predictions_df[\"store_nbr\"] == i]\n",
    "\n",
    "#     ax.plot(store_data.index, store_data['actual_sales'], label='Actual Sales')\n",
    "#     ax.plot(store_data.index, store_data['predicted_sales'], label='Predicted Sales')\n",
    "\n",
    "#     ax.set_title(f\"Store {i+1}\")\n",
    "#     ax.set_ylabel(\"Sales\")\n",
    "\n",
    "# fig.legend(['Actual Sales', 'Predicted Sales'], loc='upper center', ncol=2)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c7cf8bde-c462-4159-91fc-3adf027c23de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPackageGroup Arn : arn:aws:sagemaker:us-east-1:342408968837:model-package-group/store-sales-forecasting-custom-model-group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'store-sales-forecasting-custom-model-group',\n",
       " 'ModelPackageGroupArn': 'arn:aws:sagemaker:us-east-1:342408968837:model-package-group/store-sales-forecasting-custom-model-group',\n",
       " 'ModelPackageGroupDescription': 'This model group contains time series forecasting models for predicting store sales for 54 Favorita stores.',\n",
       " 'CreationTime': datetime.datetime(2024, 10, 15, 7, 17, 16, 785000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:342408968837:user-profile/d-2cr7fbmrqyrg/jlawton',\n",
       "  'UserProfileName': 'jlawton',\n",
       "  'DomainId': 'd-2cr7fbmrqyrg',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::342408968837:assumed-role/LabRole/SageMaker',\n",
       "   'PrincipalId': 'AROAU7OJKHKCWCCLLHI6O:SageMaker'}},\n",
       " 'ModelPackageGroupStatus': 'Completed',\n",
       " 'ResponseMetadata': {'RequestId': 'e1638ad0-0f8f-4448-b3bc-ca1c854d1b44',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e1638ad0-0f8f-4448-b3bc-ca1c854d1b44',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '705',\n",
       "   'date': 'Tue, 15 Oct 2024 07:17:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and create model group\n",
    "model_package_group_name = \"store-sales-forecasting-custom-model-group\"\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"This model group contains time series forecasting models for predicting store sales for 54 Favorita stores.\"\n",
    "}\n",
    "\n",
    "create_model_package_group_response = sm_client.create_model_package_group(**model_package_group_input_dict)\n",
    "print('ModelPackageGroup Arn : {}'.format(create_model_package_group_response['ModelPackageGroupArn']))\n",
    "\n",
    "# Check that the model group was created\n",
    "describe_model_package_group_response = sm_client.describe_model_package_group(ModelPackageGroupName=model_package_group_name)\n",
    "describe_model_package_group_response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "75021cb0-850f-4262-91ce-5e4be93bb081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.6-cpu',\n",
       " 'Mode': 'SingleModel',\n",
       " 'ModelDataUrl': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz',\n",
       " 'ModelDataSource': {'S3DataSource': {'S3Uri': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz',\n",
       "   'S3DataType': 'S3Object',\n",
       "   'CompressionType': 'Gzip'}},\n",
       " 'Environment': {'SAGEMAKER_TFS_NGINX_LOGLEVEL': 'info'}}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dc73a8f4-c109-4359-8c7e-3212209f183b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the model container\n",
    "modelpackage_inference_specification =  {\n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\": [model_container],\n",
    "        \"SupportedContentTypes\": [ \"text/csv\" ],\n",
    "        \"SupportedResponseMIMETypes\": [ \"text/csv\" ],\n",
    "      \n",
    "    }\n",
    " }\n",
    "\n",
    "# Specify package details\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_name,\n",
    "    \"ModelPackageDescription\" : \"Custom store sales forecasting model using CNN-GRU architecture\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6cb48530-4cf0-47f5-8aaf-4805d158bdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPackage Version ARN : arn:aws:sagemaker:us-east-1:342408968837:model-package/store-sales-forecasting-custom-model-group/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'store-sales-forecasting-custom-model-group',\n",
       " 'ModelPackageVersion': 1,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:342408968837:model-package/store-sales-forecasting-custom-model-group/1',\n",
       " 'ModelPackageDescription': 'Custom store sales forecasting model using CNN-GRU architecture',\n",
       " 'CreationTime': datetime.datetime(2024, 10, 15, 7, 24, 21, 721000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.6-cpu',\n",
       "    'ImageDigest': 'sha256:de3fd33aa1fa3225474fced65a5ed5bdcdce841319b517697d080b37ff5bacce',\n",
       "    'ModelDataUrl': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz'}],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['text/csv']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'PendingManualApproval',\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:342408968837:user-profile/d-2cr7fbmrqyrg/jlawton',\n",
       "  'UserProfileName': 'jlawton',\n",
       "  'DomainId': 'd-2cr7fbmrqyrg',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::342408968837:assumed-role/LabRole/SageMaker',\n",
       "   'PrincipalId': 'AROAU7OJKHKCWCCLLHI6O:SageMaker'}},\n",
       " 'ResponseMetadata': {'RequestId': 'cfc7c705-180c-49a7-beb3-e9686ebc40f4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'cfc7c705-180c-49a7-beb3-e9686ebc40f4',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1273',\n",
       "   'date': 'Tue, 15 Oct 2024 07:24:21 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model package\n",
    "create_model_package_response = sm_client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))\n",
    "\n",
    "# Check that the model package was created\n",
    "describe_model_package_response = sm_client.describe_model_package(ModelPackageName=model_package_arn)\n",
    "describe_model_package_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dc7de271-21c6-4d9e-9bdf-87e855df3366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model overview\n",
    "model_overview = ModelOverview.from_model_name(\n",
    "    model_name=model_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    model_description=\"Model to predict store sales for 54 Favorita stores based on historical sales data, oil prices, and seasonal information.\",\n",
    "    problem_type=\"Time Series Forecasting\",\n",
    "    algorithm_type=\"CNN-GRU\",\n",
    "    model_creator=\"AAI 540 Team 5\",\n",
    "    model_owner=\"AAI 540 Team 5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c0260980-4c17-4e54-867e-3036ce2cea46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job id: arn:aws:sagemaker:us-east-1:342408968837:training-job/tensorflow-training-2024-10-15-05-41-38-410\n",
      "Training image: ['763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6-cpu-py38']\n",
      "Training Metrics: \n",
      "[{'name': 'loss', 'value': 0.4708000123500824}, {'name': 'root_mean_squared_error', 'value': 0.6825000047683716}, {'name': 'mean_absolute_error', 'value': 0.36809998750686646}, {'name': 'val_loss', 'value': 0.36169999837875366}, {'name': 'val_root_mean_squared_error', 'value': 0.597000002861023}, {'name': 'val_mean_absolute_error', 'value': 0.36320000886917114}, {'name': 'epoch', 'value': 19.0}]\n"
     ]
    }
   ],
   "source": [
    "# Define objective funtion\n",
    "objective_function = ObjectiveFunction(\n",
    "    function=Function(\n",
    "        function=ObjectiveFunctionEnum.MINIMIZE,\n",
    "        facet=FacetEnum.LOSS,\n",
    "    ),\n",
    "    notes=\"The model optimizes for mean squared error during training.\",\n",
    ")\n",
    "\n",
    "# Get hyperparameters from the training job\n",
    "model_training_job_name = model_info['PrimaryContainer']['ModelDataUrl'].split('/')[-3]\n",
    "job = sm_client.describe_training_job(TrainingJobName=model_training_job_name)\n",
    "hyperparameters = [HyperParameter(key, value) for key, value in job['HyperParameters'].items()]\n",
    "\n",
    "# Create job details to include the hyperparameters in the training details\n",
    "training_job_details = TrainingJobDetails(\n",
    "    hyper_parameters=hyperparameters\n",
    ")\n",
    "\n",
    "# Define and view training details\n",
    "training_details = TrainingDetails.from_model_overview(\n",
    "    model_overview=model_overview,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    objective_function=objective_function,\n",
    "    training_job_details=training_job_details\n",
    ")\n",
    "print(f\"Training job id: {training_details.training_job_details.training_arn}\")\n",
    "print(\n",
    "    f\"Training image: {training_details.training_job_details.training_environment.container_image}\"\n",
    ")\n",
    "print(\"Training Metrics: \")\n",
    "print(\n",
    "    [\n",
    "        {\"name\": i.name, \"value\": i.value}\n",
    "        for i in training_details.training_job_details.training_metrics\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "54ec10f6-5b08-4f25-a6b3-8790c4ef07e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define intended uses and business_details\n",
    "intended_uses = IntendedUses(\n",
    "    purpose_of_model=\"This model is designed to forecast store sales for Favorita stores.\",\n",
    "    intended_uses=\"This model is intended to forecast sales for the 54 currently operational Favorita stores.\",\n",
    "    factors_affecting_model_efficiency=\"N/A\",\n",
    "    risk_rating=RiskRatingEnum.LOW,\n",
    "    explanations_for_risk_rating=\"No PII or other sensitive information is used in this model.\",\n",
    ")\n",
    "business_details = BusinessDetails(\n",
    "    business_problem=\"Predicting Favorita store sales.\",\n",
    "    business_stakeholders=\"Favorita store managers, owners, and stakeholders.\",\n",
    "    line_of_business=\"Sales\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "118a7762-ffd7-48ff-b2f2-2f4e9c9ed39b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_card.model_card:Creating model card with name: store-sales-forecasting-custom-model-card\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model card store-sales-forecasting-custom-model-card is successfully created with id arn:aws:sagemaker:us-east-1:342408968837:model-card/store-sales-forecasting-custom-model-card\n"
     ]
    }
   ],
   "source": [
    "# Create the model card\n",
    "model_card_name = \"store-sales-forecasting-custom-model-card\"\n",
    "model_card = ModelCard(\n",
    "    name=model_card_name,\n",
    "    status=ModelCardStatusEnum.DRAFT,\n",
    "    model_overview=model_overview,\n",
    "    training_details=training_details,\n",
    "    intended_uses=intended_uses,\n",
    "    business_details=business_details,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "model_card.create()\n",
    "print(f\"Model card {model_card.name} is successfully created with id {model_card.arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "94597ace-4d15-402c-abbb-fb8656fbd97d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_card.model_card:Model card store-sales-forecasting-custom-model-card is successfully exported to s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/export/store-sales-forecasting-custom-model-card/store-sales-forecasting-custom-model-card-1728977351-d496.pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \r"
     ]
    }
   ],
   "source": [
    "# Export the model card as a PDF and store in S3\n",
    "s3_output_path = f\"s3://{bucket}/store-sales-forecasting/export\"\n",
    "pdf_s3_url = model_card.export_pdf(s3_output_path=s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31643d25-2a71-45f9-8317-04b4a2235974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
