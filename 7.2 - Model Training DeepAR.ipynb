{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VII.2 - Train DeepAR model and publish to model store\n",
    "\n",
    "University of San Diego - MS Applied AI\n",
    "\n",
    "AAI-540 Team 5\n",
    "\n",
    "October 21, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Stored 's3_datalake_path_csv' (str)\n",
      "Stored 'local_data_path_csv' (str)\n",
      "Stored 's3_datalake_path_parquet' (str)\n"
     ]
    }
   ],
   "source": [
    "# setup environment\n",
    "%run 0-Environment_Setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "# configure model image and output path\n",
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)\n",
    "s3_output_path = s3_deepar_gold_dataset_path + \"/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training job with vanilla hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# initialize estimator\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m5.xlarge\",\n",
    "    base_job_name=\"store-sales-forecasting-deepar\",\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vanilla hyperparameters\n",
    "hyperparameters = {\n",
    "    \"time_freq\": deepar_freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(deepar_context_length),\n",
    "    \"prediction_length\": str(deepar_prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters to model\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: store-sales-forecasting-deepar-2024-10-01-04-02-13-037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 04:02:15 Starting - Starting the training job...\n",
      "2024-10-01 04:02:30 Starting - Preparing the instances for training...\n",
      "2024-10-01 04:03:09 Downloading - Downloading input data...\n",
      "2024-10-01 04:03:29 Downloading - Downloading the training image........................\n",
      "2024-10-01 04:07:32 Training - Training image download completed. Training in progress..Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '15', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '5E-4', 'mini_batch_size': '64', 'prediction_length': '7', 'time_freq': '1D'}\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '5E-4', 'likelihood': 'student-t', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '15', 'epochs': '400', 'prediction_length': '7', 'time_freq': '1D'}\n",
      "Process 7 is a worker.\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Detected entry point for worker worker\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Using early stopping with patience 40\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] random_seed is None\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] [cardinality=auto] Inferred value of cardinality=[54] from dataset.\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=3 from dataset.\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Training set statistics:\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Real time series\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] number of time series: 54\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] number of observations: 72900\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] mean target length: 1350.0\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] min/mean/max target: 0.0/11041.492954389574/235450.203125\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] mean abs(target): 11041.492954389574\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] contains missing values: no\n",
      "[10/01/2024 04:07:44 INFO 140492683822912] Small number of time series. Doing 12 passes over dataset with prob 0.9876543209876543 per epoch.\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] Test set statistics:\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] Real time series\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] number of time series: 1242\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] number of observations: 1781028\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] mean target length: 1434.0\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] min/mean/max target: 0.0/11285.128959651393/235450.203125\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] mean abs(target): 11285.128959651393\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] contains missing values: no\n",
      "/opt/amazon/lib/python3.8/site-packages/algorithm/core/date_feature_set.py:44: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  return index.weekofyear / 51.0 - 0.5\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] #memory_usage::<batchbuffer> = 29.92919921875 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] nvidia-smi: took 0.031 seconds to run.\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] nvidia-smi identified 0 GPUs.\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] Number of GPUs being used: 0\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] Create Store: local\n",
      "#metrics {\"StartTime\": 1727755665.414668, \"EndTime\": 1727755665.4768486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 59.27705764770508, \"count\": 1, \"min\": 59.27705764770508, \"max\": 59.27705764770508}}}\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] Number of GPUs being used: 0\n",
      "[10/01/2024 04:07:45 INFO 140492683822912] #memory_usage::<model> = 8 mb\n",
      "#metrics {\"StartTime\": 1727755665.476929, \"EndTime\": 1727755665.5685074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 153.70535850524902, \"count\": 1, \"min\": 153.70535850524902, \"max\": 153.70535850524902}}}\n",
      "[04:07:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 10240 bytes with malloc directly\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] Epoch[0] Batch[0] avg_epoch_loss=10.970476\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=10.970476150512695\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] Epoch[0] Batch[5] avg_epoch_loss=10.753217\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=10.75321658452352\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] Epoch[0] Batch [5]#011Speed: 925.78 samples/sec#011loss=10.753217\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] Epoch[0] Batch[10] avg_epoch_loss=10.565986\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=10.341308975219727\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] Epoch[0] Batch [10]#011Speed: 895.05 samples/sec#011loss=10.341309\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] processed a total of 644 examples\n",
      "#metrics {\"StartTime\": 1727755665.5685651, \"EndTime\": 1727755666.9785693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 1409.9290370941162, \"count\": 1, \"min\": 1409.9290370941162, \"max\": 1409.9290370941162}}}\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=456.7243548512548 records/second\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=0, train loss <loss>=10.565985853021795\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:46 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_57c8997a-cabb-4d8a-bfe2-239c3c7e6213-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755666.978649, \"EndTime\": 1727755666.988601, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.490013122558594, \"count\": 1, \"min\": 9.490013122558594, \"max\": 9.490013122558594}}}\n",
      "[10/01/2024 04:07:47 INFO 140492683822912] Epoch[1] Batch[0] avg_epoch_loss=10.273478\n",
      "[10/01/2024 04:07:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=10.273477554321289\n",
      "[10/01/2024 04:07:47 INFO 140492683822912] Epoch[1] Batch[5] avg_epoch_loss=10.111727\n",
      "[10/01/2024 04:07:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=10.111727237701416\n",
      "[10/01/2024 04:07:47 INFO 140492683822912] Epoch[1] Batch [5]#011Speed: 936.23 samples/sec#011loss=10.111727\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] Epoch[1] Batch[10] avg_epoch_loss=10.067506\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=10.014440727233886\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] Epoch[1] Batch [10]#011Speed: 770.49 samples/sec#011loss=10.014441\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] processed a total of 729 examples\n",
      "#metrics {\"StartTime\": 1727755666.9886537, \"EndTime\": 1727755668.362556, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1373.8455772399902, \"count\": 1, \"min\": 1373.8455772399902, \"max\": 1373.8455772399902}}}\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=530.5878205823429 records/second\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=1, train loss <loss>=10.019700368245443\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_0fa450b0-6929-4683-8dde-b637a1e8eb84-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755668.3626256, \"EndTime\": 1727755668.3725855, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.439229965209961, \"count\": 1, \"min\": 9.439229965209961, \"max\": 9.439229965209961}}}\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] Epoch[2] Batch[0] avg_epoch_loss=9.907936\n",
      "[10/01/2024 04:07:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=9.907936096191406\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] Epoch[2] Batch[5] avg_epoch_loss=9.882830\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=9.882830142974854\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] Epoch[2] Batch [5]#011Speed: 919.23 samples/sec#011loss=9.882830\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755668.372638, \"EndTime\": 1727755669.5857446, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1213.057279586792, \"count\": 1, \"min\": 1213.057279586792, \"max\": 1213.057279586792}}}\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=520.9548574596594 records/second\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=2, train loss <loss>=9.85710163116455\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:49 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_c9dac8ee-45eb-44a5-b0d1-9c905961ea89-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755669.5858166, \"EndTime\": 1727755669.5966876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.53762435913086, \"count\": 1, \"min\": 10.53762435913086, \"max\": 10.53762435913086}}}\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] Epoch[3] Batch[0] avg_epoch_loss=9.845541\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=9.845541000366211\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] Epoch[3] Batch[5] avg_epoch_loss=9.832250\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=9.832249959309896\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] Epoch[3] Batch [5]#011Speed: 947.08 samples/sec#011loss=9.832250\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] Epoch[3] Batch[10] avg_epoch_loss=9.869549\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=9.914306831359863\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] Epoch[3] Batch [10]#011Speed: 839.45 samples/sec#011loss=9.914307\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] processed a total of 656 examples\n",
      "#metrics {\"StartTime\": 1727755669.5967436, \"EndTime\": 1727755670.879091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1282.296895980835, \"count\": 1, \"min\": 1282.296895980835, \"max\": 1282.296895980835}}}\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=511.5471805594986 records/second\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=3, train loss <loss>=9.869548537514426\n",
      "[10/01/2024 04:07:50 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:07:51 INFO 140492683822912] Epoch[4] Batch[0] avg_epoch_loss=9.878788\n",
      "[10/01/2024 04:07:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=9.878787994384766\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] Epoch[4] Batch[5] avg_epoch_loss=9.769390\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=9.769390106201172\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] Epoch[4] Batch [5]#011Speed: 705.27 samples/sec#011loss=9.769390\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] processed a total of 620 examples\n",
      "#metrics {\"StartTime\": 1727755670.879151, \"EndTime\": 1727755672.4580774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1578.6635875701904, \"count\": 1, \"min\": 1578.6635875701904, \"max\": 1578.6635875701904}}}\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=392.71335066397376 records/second\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=4, train loss <loss>=9.723650264739991\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:52 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_1f5dbba0-8652-4942-95f0-339848fc297c-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755672.4581451, \"EndTime\": 1727755672.483842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 25.355100631713867, \"count\": 1, \"min\": 25.355100631713867, \"max\": 25.355100631713867}}}\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] Epoch[5] Batch[0] avg_epoch_loss=9.611888\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=9.61188793182373\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] Epoch[5] Batch[5] avg_epoch_loss=9.659976\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=9.65997568766276\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] Epoch[5] Batch [5]#011Speed: 936.99 samples/sec#011loss=9.659976\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] Epoch[5] Batch[10] avg_epoch_loss=9.691762\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=9.729905319213866\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] Epoch[5] Batch [10]#011Speed: 775.68 samples/sec#011loss=9.729905\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] processed a total of 664 examples\n",
      "#metrics {\"StartTime\": 1727755672.4839122, \"EndTime\": 1727755673.8461957, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1362.2255325317383, \"count\": 1, \"min\": 1362.2255325317383, \"max\": 1362.2255325317383}}}\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=487.40582163581445 records/second\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=5, train loss <loss>=9.691761883822354\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:53 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_ec33413f-7b64-423e-991b-1cdcbe219b18-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755673.8462555, \"EndTime\": 1727755673.8569937, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.304450988769531, \"count\": 1, \"min\": 10.304450988769531, \"max\": 10.304450988769531}}}\n",
      "[10/01/2024 04:07:54 INFO 140492683822912] Epoch[6] Batch[0] avg_epoch_loss=9.713057\n",
      "[10/01/2024 04:07:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=9.713056564331055\n",
      "[10/01/2024 04:07:54 INFO 140492683822912] Epoch[6] Batch[5] avg_epoch_loss=9.579193\n",
      "[10/01/2024 04:07:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=9.579193433125814\n",
      "[10/01/2024 04:07:54 INFO 140492683822912] Epoch[6] Batch [5]#011Speed: 950.76 samples/sec#011loss=9.579193\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] Epoch[6] Batch[10] avg_epoch_loss=9.661289\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=9.75980281829834\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] Epoch[6] Batch [10]#011Speed: 870.00 samples/sec#011loss=9.759803\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] processed a total of 652 examples\n",
      "#metrics {\"StartTime\": 1727755673.8570485, \"EndTime\": 1727755675.1521075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1295.0105667114258, \"count\": 1, \"min\": 1295.0105667114258, \"max\": 1295.0105667114258}}}\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.4355749433731 records/second\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=6, train loss <loss>=9.661288608204234\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_03e56865-71e9-4db2-aed5-364040176cd0-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755675.1521704, \"EndTime\": 1727755675.162943, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.486602783203125, \"count\": 1, \"min\": 10.486602783203125, \"max\": 10.486602783203125}}}\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] Epoch[7] Batch[0] avg_epoch_loss=9.598695\n",
      "[10/01/2024 04:07:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=9.598694801330566\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] Epoch[7] Batch[5] avg_epoch_loss=9.561779\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=9.561778863271078\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] Epoch[7] Batch [5]#011Speed: 925.05 samples/sec#011loss=9.561779\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] processed a total of 619 examples\n",
      "#metrics {\"StartTime\": 1727755675.1629977, \"EndTime\": 1727755676.364377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1201.328992843628, \"count\": 1, \"min\": 1201.328992843628, \"max\": 1201.328992843628}}}\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.2174879211523 records/second\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=7, train loss <loss>=9.466412353515626\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_02e1f277-f81b-4d91-83b3-1cff55945daa-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755676.3644521, \"EndTime\": 1727755676.374522, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.627580642700195, \"count\": 1, \"min\": 9.627580642700195, \"max\": 9.627580642700195}}}\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] Epoch[8] Batch[0] avg_epoch_loss=9.483535\n",
      "[10/01/2024 04:07:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=9.483534812927246\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] Epoch[8] Batch[5] avg_epoch_loss=9.473073\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=9.473073323567709\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] Epoch[8] Batch [5]#011Speed: 939.61 samples/sec#011loss=9.473073\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] processed a total of 606 examples\n",
      "#metrics {\"StartTime\": 1727755676.3745804, \"EndTime\": 1727755677.5849955, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1210.3614807128906, \"count\": 1, \"min\": 1210.3614807128906, \"max\": 1210.3614807128906}}}\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.63742538936197 records/second\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=8, train loss <loss>=9.44425344467163\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:57 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_19f2e39f-1365-49e4-99a3-5245da7c22da-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755677.58506, \"EndTime\": 1727755677.5964081, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.020421981811523, \"count\": 1, \"min\": 11.020421981811523, \"max\": 11.020421981811523}}}\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] Epoch[9] Batch[0] avg_epoch_loss=9.547860\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=9.547860145568848\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] Epoch[9] Batch[5] avg_epoch_loss=9.383135\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=9.383135318756104\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] Epoch[9] Batch [5]#011Speed: 915.04 samples/sec#011loss=9.383135\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] Epoch[9] Batch[10] avg_epoch_loss=9.336756\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=9.281101036071778\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] Epoch[9] Batch [10]#011Speed: 912.02 samples/sec#011loss=9.281101\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] processed a total of 641 examples\n",
      "#metrics {\"StartTime\": 1727755677.5964973, \"EndTime\": 1727755678.8765147, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1279.9646854400635, \"count\": 1, \"min\": 1279.9646854400635, \"max\": 1279.9646854400635}}}\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.75980822281645 records/second\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=9, train loss <loss>=9.336756099354137\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:07:58 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_4479b2b7-b9e6-4223-994f-12896b3dc119-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755678.8765764, \"EndTime\": 1727755678.8872166, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.351896286010742, \"count\": 1, \"min\": 10.351896286010742, \"max\": 10.351896286010742}}}\n",
      "[10/01/2024 04:07:59 INFO 140492683822912] Epoch[10] Batch[0] avg_epoch_loss=9.221094\n",
      "[10/01/2024 04:07:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=9.221094131469727\n",
      "[10/01/2024 04:07:59 INFO 140492683822912] Epoch[10] Batch[5] avg_epoch_loss=9.351812\n",
      "[10/01/2024 04:07:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=9.351812044779459\n",
      "[10/01/2024 04:07:59 INFO 140492683822912] Epoch[10] Batch [5]#011Speed: 916.33 samples/sec#011loss=9.351812\n",
      "[10/01/2024 04:08:00 INFO 140492683822912] processed a total of 639 examples\n",
      "#metrics {\"StartTime\": 1727755678.8872724, \"EndTime\": 1727755680.1195693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1232.2468757629395, \"count\": 1, \"min\": 1232.2468757629395, \"max\": 1232.2468757629395}}}\n",
      "[10/01/2024 04:08:00 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.5246873608845 records/second\n",
      "[10/01/2024 04:08:00 INFO 140492683822912] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[10/01/2024 04:08:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=10, train loss <loss>=9.352270603179932\n",
      "[10/01/2024 04:08:00 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:00 INFO 140492683822912] Epoch[11] Batch[0] avg_epoch_loss=9.371865\n",
      "[10/01/2024 04:08:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=9.371865272521973\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] Epoch[11] Batch[5] avg_epoch_loss=9.340246\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=9.340245564778646\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] Epoch[11] Batch [5]#011Speed: 919.09 samples/sec#011loss=9.340246\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] processed a total of 606 examples\n",
      "#metrics {\"StartTime\": 1727755680.119637, \"EndTime\": 1727755681.3365555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1216.5019512176514, \"count\": 1, \"min\": 1216.5019512176514, \"max\": 1216.5019512176514}}}\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=498.10863096900346 records/second\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=11, train loss <loss>=9.390515804290771\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] Epoch[12] Batch[0] avg_epoch_loss=9.319927\n",
      "[10/01/2024 04:08:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=9.319927215576172\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] Epoch[12] Batch[5] avg_epoch_loss=9.248274\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=9.248273849487305\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] Epoch[12] Batch [5]#011Speed: 724.95 samples/sec#011loss=9.248274\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] processed a total of 605 examples\n",
      "#metrics {\"StartTime\": 1727755681.336625, \"EndTime\": 1727755682.821596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1484.6556186676025, \"count\": 1, \"min\": 1484.6556186676025, \"max\": 1484.6556186676025}}}\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=407.46703320524824 records/second\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=12, train loss <loss>=9.276284408569335\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:02 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_0c3f6bc5-811d-4e0b-aa90-c09cc6cbb1f2-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755682.8216846, \"EndTime\": 1727755682.8380578, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 15.734195709228516, \"count\": 1, \"min\": 15.734195709228516, \"max\": 15.734195709228516}}}\n",
      "[10/01/2024 04:08:03 INFO 140492683822912] Epoch[13] Batch[0] avg_epoch_loss=9.215592\n",
      "[10/01/2024 04:08:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=9.215592384338379\n",
      "[10/01/2024 04:08:03 INFO 140492683822912] Epoch[13] Batch[5] avg_epoch_loss=9.245876\n",
      "[10/01/2024 04:08:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=9.245876471201578\n",
      "[10/01/2024 04:08:03 INFO 140492683822912] Epoch[13] Batch [5]#011Speed: 923.15 samples/sec#011loss=9.245876\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755682.8381782, \"EndTime\": 1727755684.1618593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1323.6145973205566, \"count\": 1, \"min\": 1323.6145973205566, \"max\": 1323.6145973205566}}}\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=477.4403893873083 records/second\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=13, train loss <loss>=9.25817403793335\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_4a6e5d08-bf20-41fd-8e12-b22a9702ee96-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755684.161935, \"EndTime\": 1727755684.1723678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.821891784667969, \"count\": 1, \"min\": 9.821891784667969, \"max\": 9.821891784667969}}}\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] Epoch[14] Batch[0] avg_epoch_loss=9.180819\n",
      "[10/01/2024 04:08:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=9.180818557739258\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] Epoch[14] Batch[5] avg_epoch_loss=9.181476\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=9.181475957234701\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] Epoch[14] Batch [5]#011Speed: 899.34 samples/sec#011loss=9.181476\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] Epoch[14] Batch[10] avg_epoch_loss=9.163838\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=9.142671394348145\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] Epoch[14] Batch [10]#011Speed: 839.75 samples/sec#011loss=9.142671\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] processed a total of 659 examples\n",
      "#metrics {\"StartTime\": 1727755684.172433, \"EndTime\": 1727755685.4843652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1311.8715286254883, \"count\": 1, \"min\": 1311.8715286254883, \"max\": 1311.8715286254883}}}\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.2977987222514 records/second\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=14, train loss <loss>=9.163837519558994\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:05 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_c4fe8c3e-ac63-4ec5-86ba-7f921abcb46c-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755685.4844308, \"EndTime\": 1727755685.4944782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.66644287109375, \"count\": 1, \"min\": 9.66644287109375, \"max\": 9.66644287109375}}}\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] Epoch[15] Batch[0] avg_epoch_loss=9.254343\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=9.254343032836914\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] Epoch[15] Batch[5] avg_epoch_loss=9.171021\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=9.171020984649658\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] Epoch[15] Batch [5]#011Speed: 896.80 samples/sec#011loss=9.171021\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] processed a total of 621 examples\n",
      "#metrics {\"StartTime\": 1727755685.4945393, \"EndTime\": 1727755686.7265806, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1231.985092163086, \"count\": 1, \"min\": 1231.985092163086, \"max\": 1231.985092163086}}}\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=504.02045291471836 records/second\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=15, train loss <loss>=9.205931377410888\n",
      "[10/01/2024 04:08:06 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] Epoch[16] Batch[0] avg_epoch_loss=9.083845\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=9.083845138549805\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] Epoch[16] Batch[5] avg_epoch_loss=9.187534\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=9.187534173329672\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] Epoch[16] Batch [5]#011Speed: 900.45 samples/sec#011loss=9.187534\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] processed a total of 608 examples\n",
      "#metrics {\"StartTime\": 1727755686.7266579, \"EndTime\": 1727755687.9506612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1223.5493659973145, \"count\": 1, \"min\": 1223.5493659973145, \"max\": 1223.5493659973145}}}\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=496.86298169986213 records/second\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=16, train loss <loss>=9.150085353851319\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:07 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_140f93ea-5bd7-4aa3-9abf-a88e657f0877-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755687.9507382, \"EndTime\": 1727755687.9606872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.482383728027344, \"count\": 1, \"min\": 9.482383728027344, \"max\": 9.482383728027344}}}\n",
      "[10/01/2024 04:08:08 INFO 140492683822912] Epoch[17] Batch[0] avg_epoch_loss=9.165538\n",
      "[10/01/2024 04:08:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=9.16553783416748\n",
      "[10/01/2024 04:08:08 INFO 140492683822912] Epoch[17] Batch[5] avg_epoch_loss=9.173570\n",
      "[10/01/2024 04:08:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=9.173569997151693\n",
      "[10/01/2024 04:08:08 INFO 140492683822912] Epoch[17] Batch [5]#011Speed: 940.75 samples/sec#011loss=9.173570\n",
      "[10/01/2024 04:08:09 INFO 140492683822912] processed a total of 611 examples\n",
      "#metrics {\"StartTime\": 1727755687.9607453, \"EndTime\": 1727755689.1859658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1225.165605545044, \"count\": 1, \"min\": 1225.165605545044, \"max\": 1225.165605545044}}}\n",
      "[10/01/2024 04:08:09 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=498.66878894877374 records/second\n",
      "[10/01/2024 04:08:09 INFO 140492683822912] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[10/01/2024 04:08:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=17, train loss <loss>=9.19598331451416\n",
      "[10/01/2024 04:08:09 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:09 INFO 140492683822912] Epoch[18] Batch[0] avg_epoch_loss=9.317335\n",
      "[10/01/2024 04:08:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=9.31733512878418\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] Epoch[18] Batch[5] avg_epoch_loss=9.210309\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=9.21030886967977\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] Epoch[18] Batch [5]#011Speed: 931.58 samples/sec#011loss=9.210309\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] Epoch[18] Batch[10] avg_epoch_loss=9.288794\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=9.382975959777832\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] Epoch[18] Batch [10]#011Speed: 867.54 samples/sec#011loss=9.382976\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] processed a total of 645 examples\n",
      "#metrics {\"StartTime\": 1727755689.1860335, \"EndTime\": 1727755690.483603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1297.2602844238281, \"count\": 1, \"min\": 1297.2602844238281, \"max\": 1297.2602844238281}}}\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=497.15974619792144 records/second\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=18, train loss <loss>=9.288793910633434\n",
      "[10/01/2024 04:08:10 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] Epoch[19] Batch[0] avg_epoch_loss=9.170150\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=9.170149803161621\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] Epoch[19] Batch[5] avg_epoch_loss=9.176581\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=9.176580746968588\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] Epoch[19] Batch [5]#011Speed: 922.99 samples/sec#011loss=9.176581\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] processed a total of 639 examples\n",
      "#metrics {\"StartTime\": 1727755690.4836786, \"EndTime\": 1727755691.7154694, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1231.2426567077637, \"count\": 1, \"min\": 1231.2426567077637, \"max\": 1231.2426567077637}}}\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.9405370364884 records/second\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=19, train loss <loss>=9.16776876449585\n",
      "[10/01/2024 04:08:11 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] Epoch[20] Batch[0] avg_epoch_loss=9.200374\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=9.200373649597168\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] Epoch[20] Batch[5] avg_epoch_loss=9.133903\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=9.13390302658081\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] Epoch[20] Batch [5]#011Speed: 914.05 samples/sec#011loss=9.133903\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] processed a total of 613 examples\n",
      "#metrics {\"StartTime\": 1727755691.7155464, \"EndTime\": 1727755692.9358637, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1219.881534576416, \"count\": 1, \"min\": 1219.881534576416, \"max\": 1219.881534576416}}}\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.46509265507507 records/second\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=20, train loss <loss>=9.1022123336792\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:12 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_aada3ec4-0560-4d36-bbca-b80a629b4f86-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755692.935933, \"EndTime\": 1727755692.946882, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.524272918701172, \"count\": 1, \"min\": 10.524272918701172, \"max\": 10.524272918701172}}}\n",
      "[10/01/2024 04:08:13 INFO 140492683822912] Epoch[21] Batch[0] avg_epoch_loss=9.105446\n",
      "[10/01/2024 04:08:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=9.105445861816406\n",
      "[10/01/2024 04:08:13 INFO 140492683822912] Epoch[21] Batch[5] avg_epoch_loss=9.056763\n",
      "[10/01/2024 04:08:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=9.056763331095377\n",
      "[10/01/2024 04:08:13 INFO 140492683822912] Epoch[21] Batch [5]#011Speed: 942.03 samples/sec#011loss=9.056763\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] processed a total of 621 examples\n",
      "#metrics {\"StartTime\": 1727755692.9469383, \"EndTime\": 1727755694.1628258, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1215.8348560333252, \"count\": 1, \"min\": 1215.8348560333252, \"max\": 1215.8348560333252}}}\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=510.7202959071008 records/second\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=21, train loss <loss>=9.012792015075684\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_fa17aefd-c3c6-4af5-abd5-9dd793685985-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755694.1628916, \"EndTime\": 1727755694.1743572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.003732681274414, \"count\": 1, \"min\": 11.003732681274414, \"max\": 11.003732681274414}}}\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] Epoch[22] Batch[0] avg_epoch_loss=9.073404\n",
      "[10/01/2024 04:08:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=9.073404312133789\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] Epoch[22] Batch[5] avg_epoch_loss=9.131940\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=9.131940205891928\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] Epoch[22] Batch [5]#011Speed: 934.33 samples/sec#011loss=9.131940\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] processed a total of 596 examples\n",
      "#metrics {\"StartTime\": 1727755694.1744323, \"EndTime\": 1727755695.3968506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1222.269058227539, \"count\": 1, \"min\": 1222.269058227539, \"max\": 1222.269058227539}}}\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=487.5599494848528 records/second\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=22, train loss <loss>=9.075123500823974\n",
      "[10/01/2024 04:08:15 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] Epoch[23] Batch[0] avg_epoch_loss=9.020577\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=9.020577430725098\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] Epoch[23] Batch[5] avg_epoch_loss=9.125281\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=9.125281174977621\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] Epoch[23] Batch [5]#011Speed: 921.72 samples/sec#011loss=9.125281\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] Epoch[23] Batch[10] avg_epoch_loss=9.050498\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=8.960758209228516\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] Epoch[23] Batch [10]#011Speed: 798.35 samples/sec#011loss=8.960758\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] processed a total of 648 examples\n",
      "#metrics {\"StartTime\": 1727755695.3969595, \"EndTime\": 1727755696.7971935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1399.8053073883057, \"count\": 1, \"min\": 1399.8053073883057, \"max\": 1399.8053073883057}}}\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=462.89077166202935 records/second\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=23, train loss <loss>=9.050498008728027\n",
      "[10/01/2024 04:08:16 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:17 INFO 140492683822912] Epoch[24] Batch[0] avg_epoch_loss=8.907047\n",
      "[10/01/2024 04:08:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=8.907047271728516\n",
      "[10/01/2024 04:08:17 INFO 140492683822912] Epoch[24] Batch[5] avg_epoch_loss=8.992987\n",
      "[10/01/2024 04:08:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=8.99298652013143\n",
      "[10/01/2024 04:08:17 INFO 140492683822912] Epoch[24] Batch [5]#011Speed: 897.37 samples/sec#011loss=8.992987\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] Epoch[24] Batch[10] avg_epoch_loss=9.106149\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=9.241944313049316\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] Epoch[24] Batch [10]#011Speed: 885.57 samples/sec#011loss=9.241944\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] processed a total of 666 examples\n",
      "#metrics {\"StartTime\": 1727755696.7972555, \"EndTime\": 1727755698.088811, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1291.1534309387207, \"count\": 1, \"min\": 1291.1534309387207, \"max\": 1291.1534309387207}}}\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.7813826136618 records/second\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=24, train loss <loss>=9.106149153275924\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] Epoch[25] Batch[0] avg_epoch_loss=9.114334\n",
      "[10/01/2024 04:08:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=9.114334106445312\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] Epoch[25] Batch[5] avg_epoch_loss=9.086118\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=9.086118380228678\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] Epoch[25] Batch [5]#011Speed: 920.75 samples/sec#011loss=9.086118\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] processed a total of 619 examples\n",
      "#metrics {\"StartTime\": 1727755698.0888734, \"EndTime\": 1727755699.3240628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1234.7631454467773, \"count\": 1, \"min\": 1234.7631454467773, \"max\": 1234.7631454467773}}}\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=501.27074469266137 records/second\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=25, train loss <loss>=9.06218147277832\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] Epoch[26] Batch[0] avg_epoch_loss=8.870821\n",
      "[10/01/2024 04:08:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=8.870820999145508\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] Epoch[26] Batch[5] avg_epoch_loss=9.000805\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=9.000805060068766\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] Epoch[26] Batch [5]#011Speed: 921.23 samples/sec#011loss=9.000805\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] Epoch[26] Batch[10] avg_epoch_loss=9.090962\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=9.199151420593262\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] Epoch[26] Batch [10]#011Speed: 837.57 samples/sec#011loss=9.199151\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] processed a total of 651 examples\n",
      "#metrics {\"StartTime\": 1727755699.3241305, \"EndTime\": 1727755700.6597369, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1335.2468013763428, \"count\": 1, \"min\": 1335.2468013763428, \"max\": 1335.2468013763428}}}\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=487.5139294060597 records/second\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=26, train loss <loss>=9.09096249667081\n",
      "[10/01/2024 04:08:20 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] Epoch[27] Batch[0] avg_epoch_loss=9.081375\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=9.081375122070312\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] Epoch[27] Batch[5] avg_epoch_loss=8.922066\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=8.922065734863281\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] Epoch[27] Batch [5]#011Speed: 933.20 samples/sec#011loss=8.922066\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] processed a total of 623 examples\n",
      "#metrics {\"StartTime\": 1727755700.6598027, \"EndTime\": 1727755701.8619087, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1201.7338275909424, \"count\": 1, \"min\": 1201.7338275909424, \"max\": 1201.7338275909424}}}\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.3721712026811 records/second\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=27, train loss <loss>=8.93909912109375\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:21 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_6e8ffb83-50e8-4945-aa70-b317d175afb5-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755701.8619835, \"EndTime\": 1727755701.8720648, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.645462036132812, \"count\": 1, \"min\": 9.645462036132812, \"max\": 9.645462036132812}}}\n",
      "[10/01/2024 04:08:22 INFO 140492683822912] Epoch[28] Batch[0] avg_epoch_loss=8.955739\n",
      "[10/01/2024 04:08:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=8.95573902130127\n",
      "[10/01/2024 04:08:22 INFO 140492683822912] Epoch[28] Batch[5] avg_epoch_loss=8.984398\n",
      "[10/01/2024 04:08:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=8.984398206075033\n",
      "[10/01/2024 04:08:22 INFO 140492683822912] Epoch[28] Batch [5]#011Speed: 914.32 samples/sec#011loss=8.984398\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] processed a total of 611 examples\n",
      "#metrics {\"StartTime\": 1727755701.8721209, \"EndTime\": 1727755703.075003, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1202.8286457061768, \"count\": 1, \"min\": 1202.8286457061768, \"max\": 1202.8286457061768}}}\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=507.9252826200791 records/second\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=28, train loss <loss>=9.024045467376709\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] Epoch[29] Batch[0] avg_epoch_loss=8.973116\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=8.973115921020508\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] Epoch[29] Batch[5] avg_epoch_loss=8.973818\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=8.973818143208822\n",
      "[10/01/2024 04:08:23 INFO 140492683822912] Epoch[29] Batch [5]#011Speed: 947.08 samples/sec#011loss=8.973818\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] processed a total of 628 examples\n",
      "#metrics {\"StartTime\": 1727755703.0750778, \"EndTime\": 1727755704.2690709, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1193.523645401001, \"count\": 1, \"min\": 1193.523645401001, \"max\": 1193.523645401001}}}\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=526.1293479947835 records/second\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=29, train loss <loss>=8.937860774993897\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_1a60279b-7c8c-475d-953c-658b628c2c2d-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755704.2691357, \"EndTime\": 1727755704.279361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.663581848144531, \"count\": 1, \"min\": 9.663581848144531, \"max\": 9.663581848144531}}}\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] Epoch[30] Batch[0] avg_epoch_loss=9.007667\n",
      "[10/01/2024 04:08:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=9.00766658782959\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] Epoch[30] Batch[5] avg_epoch_loss=9.000674\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=9.0006742477417\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] Epoch[30] Batch [5]#011Speed: 929.02 samples/sec#011loss=9.000674\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] processed a total of 615 examples\n",
      "#metrics {\"StartTime\": 1727755704.279444, \"EndTime\": 1727755705.5070026, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1227.508306503296, \"count\": 1, \"min\": 1227.508306503296, \"max\": 1227.508306503296}}}\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.97514212600936 records/second\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=30, train loss <loss>=9.05002565383911\n",
      "[10/01/2024 04:08:25 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] Epoch[31] Batch[0] avg_epoch_loss=8.954301\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=8.954300880432129\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] Epoch[31] Batch[5] avg_epoch_loss=8.896186\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=8.896185715993246\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] Epoch[31] Batch [5]#011Speed: 918.52 samples/sec#011loss=8.896186\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] processed a total of 607 examples\n",
      "#metrics {\"StartTime\": 1727755705.5070689, \"EndTime\": 1727755706.7291193, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1221.7061519622803, \"count\": 1, \"min\": 1221.7061519622803, \"max\": 1221.7061519622803}}}\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=496.80581927685216 records/second\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=31, train loss <loss>=8.903005027770996\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:26 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_fa66e5ea-2460-4922-baff-10ca6242ec90-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755706.729187, \"EndTime\": 1727755706.7400858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.565757751464844, \"count\": 1, \"min\": 10.565757751464844, \"max\": 10.565757751464844}}}\n",
      "[10/01/2024 04:08:27 INFO 140492683822912] Epoch[32] Batch[0] avg_epoch_loss=8.970787\n",
      "[10/01/2024 04:08:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=8.970787048339844\n",
      "[10/01/2024 04:08:27 INFO 140492683822912] Epoch[32] Batch[5] avg_epoch_loss=8.900387\n",
      "[10/01/2024 04:08:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=8.900387446085611\n",
      "[10/01/2024 04:08:27 INFO 140492683822912] Epoch[32] Batch [5]#011Speed: 908.52 samples/sec#011loss=8.900387\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] Epoch[32] Batch[10] avg_epoch_loss=8.983839\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=9.083981895446778\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] Epoch[32] Batch [10]#011Speed: 829.74 samples/sec#011loss=9.083982\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] processed a total of 664 examples\n",
      "#metrics {\"StartTime\": 1727755706.740142, \"EndTime\": 1727755708.0358655, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1295.6745624542236, \"count\": 1, \"min\": 1295.6745624542236, \"max\": 1295.6745624542236}}}\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=512.4393827656609 records/second\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=32, train loss <loss>=8.983839468522506\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] Epoch[33] Batch[0] avg_epoch_loss=8.907376\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=8.907376289367676\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] Epoch[33] Batch[5] avg_epoch_loss=8.860923\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=8.860922654469809\n",
      "[10/01/2024 04:08:28 INFO 140492683822912] Epoch[33] Batch [5]#011Speed: 928.92 samples/sec#011loss=8.860923\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] processed a total of 633 examples\n",
      "#metrics {\"StartTime\": 1727755708.0359266, \"EndTime\": 1727755709.2449923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1208.8017463684082, \"count\": 1, \"min\": 1208.8017463684082, \"max\": 1208.8017463684082}}}\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=523.6127009183062 records/second\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=33, train loss <loss>=8.8557297706604\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_c442dc54-3690-473d-9f20-b6bac99b401c-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755709.2450652, \"EndTime\": 1727755709.255295, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.622335433959961, \"count\": 1, \"min\": 9.622335433959961, \"max\": 9.622335433959961}}}\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] Epoch[34] Batch[0] avg_epoch_loss=8.863306\n",
      "[10/01/2024 04:08:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=8.863306045532227\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] Epoch[34] Batch[5] avg_epoch_loss=8.834906\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=8.834906260172525\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] Epoch[34] Batch [5]#011Speed: 900.32 samples/sec#011loss=8.834906\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] Epoch[34] Batch[10] avg_epoch_loss=8.958058\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=9.105840110778809\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] Epoch[34] Batch [10]#011Speed: 864.56 samples/sec#011loss=9.105840\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] processed a total of 653 examples\n",
      "#metrics {\"StartTime\": 1727755709.2553544, \"EndTime\": 1727755710.554669, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1299.2579936981201, \"count\": 1, \"min\": 1299.2579936981201, \"max\": 1299.2579936981201}}}\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.5560119348957 records/second\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=34, train loss <loss>=8.95805801044811\n",
      "[10/01/2024 04:08:30 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] Epoch[35] Batch[0] avg_epoch_loss=8.872377\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=8.872377395629883\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] Epoch[35] Batch[5] avg_epoch_loss=8.810684\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=8.810684204101562\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] Epoch[35] Batch [5]#011Speed: 911.42 samples/sec#011loss=8.810684\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755710.5547385, \"EndTime\": 1727755711.7789001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1223.741054534912, \"count\": 1, \"min\": 1223.741054534912, \"max\": 1223.741054534912}}}\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=516.401237586247 records/second\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=35, train loss <loss>=8.78917760848999\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:31 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_7ad2ebcd-4cd0-4f4f-9ca9-aedb4ae03aec-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755711.7789788, \"EndTime\": 1727755711.7912233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.845111846923828, \"count\": 1, \"min\": 11.845111846923828, \"max\": 11.845111846923828}}}\n",
      "[10/01/2024 04:08:32 INFO 140492683822912] Epoch[36] Batch[0] avg_epoch_loss=8.568988\n",
      "[10/01/2024 04:08:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=8.568987846374512\n",
      "[10/01/2024 04:08:32 INFO 140492683822912] Epoch[36] Batch[5] avg_epoch_loss=8.857630\n",
      "[10/01/2024 04:08:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=8.857629776000977\n",
      "[10/01/2024 04:08:32 INFO 140492683822912] Epoch[36] Batch [5]#011Speed: 871.49 samples/sec#011loss=8.857630\n",
      "[10/01/2024 04:08:33 INFO 140492683822912] processed a total of 627 examples\n",
      "#metrics {\"StartTime\": 1727755711.7912893, \"EndTime\": 1727755713.0925622, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1301.2185096740723, \"count\": 1, \"min\": 1301.2185096740723, \"max\": 1301.2185096740723}}}\n",
      "[10/01/2024 04:08:33 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=481.8172855429821 records/second\n",
      "[10/01/2024 04:08:33 INFO 140492683822912] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[10/01/2024 04:08:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=36, train loss <loss>=8.822760200500488\n",
      "[10/01/2024 04:08:33 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:33 INFO 140492683822912] Epoch[37] Batch[0] avg_epoch_loss=9.115202\n",
      "[10/01/2024 04:08:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=9.115201950073242\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] Epoch[37] Batch[5] avg_epoch_loss=8.996752\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=8.99675194422404\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] Epoch[37] Batch [5]#011Speed: 935.13 samples/sec#011loss=8.996752\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] processed a total of 607 examples\n",
      "#metrics {\"StartTime\": 1727755713.0926378, \"EndTime\": 1727755714.2884023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1195.3434944152832, \"count\": 1, \"min\": 1195.3434944152832, \"max\": 1195.3434944152832}}}\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=507.7611888980077 records/second\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=37, train loss <loss>=8.937135887145995\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] Epoch[38] Batch[0] avg_epoch_loss=8.842185\n",
      "[10/01/2024 04:08:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=8.842185020446777\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] Epoch[38] Batch[5] avg_epoch_loss=8.915149\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=8.915149370829264\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] Epoch[38] Batch [5]#011Speed: 946.19 samples/sec#011loss=8.915149\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] Epoch[38] Batch[10] avg_epoch_loss=9.010865\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=9.125722694396973\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] Epoch[38] Batch [10]#011Speed: 879.38 samples/sec#011loss=9.125723\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] processed a total of 651 examples\n",
      "#metrics {\"StartTime\": 1727755714.2884688, \"EndTime\": 1727755715.564527, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1275.585412979126, \"count\": 1, \"min\": 1275.585412979126, \"max\": 1275.585412979126}}}\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=510.3156591585906 records/second\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=38, train loss <loss>=9.010864517905496\n",
      "[10/01/2024 04:08:35 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] Epoch[39] Batch[0] avg_epoch_loss=8.854034\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=8.854034423828125\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] Epoch[39] Batch[5] avg_epoch_loss=8.856813\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=8.856812795003256\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] Epoch[39] Batch [5]#011Speed: 926.32 samples/sec#011loss=8.856813\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] processed a total of 629 examples\n",
      "#metrics {\"StartTime\": 1727755715.5645907, \"EndTime\": 1727755716.776787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1211.817979812622, \"count\": 1, \"min\": 1211.817979812622, \"max\": 1211.817979812622}}}\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=519.0084913264061 records/second\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=39, train loss <loss>=8.886424160003662\n",
      "[10/01/2024 04:08:36 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] Epoch[40] Batch[0] avg_epoch_loss=8.724395\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=8.724394798278809\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] Epoch[40] Batch[5] avg_epoch_loss=8.783143\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=8.783143202463785\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] Epoch[40] Batch [5]#011Speed: 912.51 samples/sec#011loss=8.783143\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] processed a total of 621 examples\n",
      "#metrics {\"StartTime\": 1727755716.7768614, \"EndTime\": 1727755717.9920678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1214.8594856262207, \"count\": 1, \"min\": 1214.8594856262207, \"max\": 1214.8594856262207}}}\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=511.1271949181296 records/second\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=40, train loss <loss>=8.842021560668945\n",
      "[10/01/2024 04:08:37 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:38 INFO 140492683822912] Epoch[41] Batch[0] avg_epoch_loss=8.902863\n",
      "[10/01/2024 04:08:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=8.902862548828125\n",
      "[10/01/2024 04:08:38 INFO 140492683822912] Epoch[41] Batch[5] avg_epoch_loss=8.717217\n",
      "[10/01/2024 04:08:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=8.717217445373535\n",
      "[10/01/2024 04:08:38 INFO 140492683822912] Epoch[41] Batch [5]#011Speed: 919.45 samples/sec#011loss=8.717217\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] Epoch[41] Batch[10] avg_epoch_loss=8.699226\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=8.67763729095459\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] Epoch[41] Batch [10]#011Speed: 884.29 samples/sec#011loss=8.677637\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] processed a total of 641 examples\n",
      "#metrics {\"StartTime\": 1727755717.992137, \"EndTime\": 1727755719.2864397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1293.8237190246582, \"count\": 1, \"min\": 1293.8237190246582, \"max\": 1293.8237190246582}}}\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=495.38752825371193 records/second\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=41, train loss <loss>=8.699226466092197\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_e37ee053-8c2b-4eb2-8d3d-d68737b9ee84-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755719.2865195, \"EndTime\": 1727755719.2963595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.365081787109375, \"count\": 1, \"min\": 9.365081787109375, \"max\": 9.365081787109375}}}\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] Epoch[42] Batch[0] avg_epoch_loss=8.706369\n",
      "[10/01/2024 04:08:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=8.706369400024414\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] Epoch[42] Batch[5] avg_epoch_loss=8.760946\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=8.76094643274943\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] Epoch[42] Batch [5]#011Speed: 941.95 samples/sec#011loss=8.760946\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] Epoch[42] Batch[10] avg_epoch_loss=8.722062\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=8.675399875640869\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] Epoch[42] Batch [10]#011Speed: 870.45 samples/sec#011loss=8.675400\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] processed a total of 662 examples\n",
      "#metrics {\"StartTime\": 1727755719.2964225, \"EndTime\": 1727755720.5824077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1285.9294414520264, \"count\": 1, \"min\": 1285.9294414520264, \"max\": 1285.9294414520264}}}\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=514.7621781518886 records/second\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=42, train loss <loss>=8.72206163406372\n",
      "[10/01/2024 04:08:40 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] Epoch[43] Batch[0] avg_epoch_loss=8.743338\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=8.743337631225586\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] Epoch[43] Batch[5] avg_epoch_loss=8.804239\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=8.804239432017008\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] Epoch[43] Batch [5]#011Speed: 910.93 samples/sec#011loss=8.804239\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] Epoch[43] Batch[10] avg_epoch_loss=8.853123\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=8.911782455444335\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] Epoch[43] Batch [10]#011Speed: 824.91 samples/sec#011loss=8.911782\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] processed a total of 668 examples\n",
      "#metrics {\"StartTime\": 1727755720.5824764, \"EndTime\": 1727755721.883793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1300.920009613037, \"count\": 1, \"min\": 1300.920009613037, \"max\": 1300.920009613037}}}\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.4419236751789 records/second\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=43, train loss <loss>=8.853122624483975\n",
      "[10/01/2024 04:08:41 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:42 INFO 140492683822912] Epoch[44] Batch[0] avg_epoch_loss=8.930516\n",
      "[10/01/2024 04:08:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=8.930516242980957\n",
      "[10/01/2024 04:08:42 INFO 140492683822912] Epoch[44] Batch[5] avg_epoch_loss=8.819496\n",
      "[10/01/2024 04:08:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=8.819496313730875\n",
      "[10/01/2024 04:08:42 INFO 140492683822912] Epoch[44] Batch [5]#011Speed: 844.71 samples/sec#011loss=8.819496\n",
      "[10/01/2024 04:08:43 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755721.8838623, \"EndTime\": 1727755723.1403005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1256.0672760009766, \"count\": 1, \"min\": 1256.0672760009766, \"max\": 1256.0672760009766}}}\n",
      "[10/01/2024 04:08:43 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.1145973071565 records/second\n",
      "[10/01/2024 04:08:43 INFO 140492683822912] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[10/01/2024 04:08:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=44, train loss <loss>=8.826984119415282\n",
      "[10/01/2024 04:08:43 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:43 INFO 140492683822912] Epoch[45] Batch[0] avg_epoch_loss=8.988501\n",
      "[10/01/2024 04:08:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=8.988500595092773\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] Epoch[45] Batch[5] avg_epoch_loss=8.841555\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=8.841554959615072\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] Epoch[45] Batch [5]#011Speed: 908.60 samples/sec#011loss=8.841555\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] processed a total of 615 examples\n",
      "#metrics {\"StartTime\": 1727755723.1403732, \"EndTime\": 1727755724.3653889, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1224.5852947235107, \"count\": 1, \"min\": 1224.5852947235107, \"max\": 1224.5852947235107}}}\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.16624983282196 records/second\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=45, train loss <loss>=8.7898512840271\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] Epoch[46] Batch[0] avg_epoch_loss=8.924083\n",
      "[10/01/2024 04:08:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=8.92408275604248\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] Epoch[46] Batch[5] avg_epoch_loss=8.892784\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=8.892783641815186\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] Epoch[46] Batch [5]#011Speed: 929.91 samples/sec#011loss=8.892784\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] Epoch[46] Batch[10] avg_epoch_loss=8.925536\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=8.96483917236328\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] Epoch[46] Batch [10]#011Speed: 872.75 samples/sec#011loss=8.964839\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] processed a total of 656 examples\n",
      "#metrics {\"StartTime\": 1727755724.3654647, \"EndTime\": 1727755725.6568003, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1290.903091430664, \"count\": 1, \"min\": 1290.903091430664, \"max\": 1290.903091430664}}}\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.1317721485792 records/second\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=46, train loss <loss>=8.925536155700684\n",
      "[10/01/2024 04:08:45 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] Epoch[47] Batch[0] avg_epoch_loss=9.028345\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=9.028345108032227\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] Epoch[47] Batch[5] avg_epoch_loss=8.821031\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=8.821031252543131\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] Epoch[47] Batch [5]#011Speed: 931.50 samples/sec#011loss=8.821031\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] processed a total of 622 examples\n",
      "#metrics {\"StartTime\": 1727755725.6568685, \"EndTime\": 1727755726.8884647, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1231.2963008880615, \"count\": 1, \"min\": 1231.2963008880615, \"max\": 1231.2963008880615}}}\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.1164160598258 records/second\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=47, train loss <loss>=8.818199253082275\n",
      "[10/01/2024 04:08:46 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:47 INFO 140492683822912] Epoch[48] Batch[0] avg_epoch_loss=8.685740\n",
      "[10/01/2024 04:08:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=8.68574047088623\n",
      "[10/01/2024 04:08:47 INFO 140492683822912] Epoch[48] Batch[5] avg_epoch_loss=8.778306\n",
      "[10/01/2024 04:08:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=8.778305689493815\n",
      "[10/01/2024 04:08:47 INFO 140492683822912] Epoch[48] Batch [5]#011Speed: 893.42 samples/sec#011loss=8.778306\n",
      "[10/01/2024 04:08:48 INFO 140492683822912] processed a total of 613 examples\n",
      "#metrics {\"StartTime\": 1727755726.8885355, \"EndTime\": 1727755728.1161377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1227.1525859832764, \"count\": 1, \"min\": 1227.1525859832764, \"max\": 1227.1525859832764}}}\n",
      "[10/01/2024 04:08:48 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=499.4865184148509 records/second\n",
      "[10/01/2024 04:08:48 INFO 140492683822912] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[10/01/2024 04:08:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=48, train loss <loss>=8.731180953979493\n",
      "[10/01/2024 04:08:48 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:48 INFO 140492683822912] Epoch[49] Batch[0] avg_epoch_loss=8.746148\n",
      "[10/01/2024 04:08:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=8.746148109436035\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] Epoch[49] Batch[5] avg_epoch_loss=8.786648\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=8.786647955576578\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] Epoch[49] Batch [5]#011Speed: 918.17 samples/sec#011loss=8.786648\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] processed a total of 618 examples\n",
      "#metrics {\"StartTime\": 1727755728.116215, \"EndTime\": 1727755729.343181, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1226.5338897705078, \"count\": 1, \"min\": 1226.5338897705078, \"max\": 1226.5338897705078}}}\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.8180479868016 records/second\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=49, train loss <loss>=8.821279907226563\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] Epoch[50] Batch[0] avg_epoch_loss=8.800882\n",
      "[10/01/2024 04:08:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=8.800882339477539\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] Epoch[50] Batch[5] avg_epoch_loss=8.719155\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=8.719154834747314\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] Epoch[50] Batch [5]#011Speed: 920.86 samples/sec#011loss=8.719155\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] processed a total of 628 examples\n",
      "#metrics {\"StartTime\": 1727755729.343249, \"EndTime\": 1727755730.5581312, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1214.5462036132812, \"count\": 1, \"min\": 1214.5462036132812, \"max\": 1214.5462036132812}}}\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=517.0239371756606 records/second\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=50, train loss <loss>=8.707426261901855\n",
      "[10/01/2024 04:08:50 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] Epoch[51] Batch[0] avg_epoch_loss=8.712709\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=8.712709426879883\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] Epoch[51] Batch[5] avg_epoch_loss=8.723286\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=8.723286310831705\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] Epoch[51] Batch [5]#011Speed: 923.02 samples/sec#011loss=8.723286\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] Epoch[51] Batch[10] avg_epoch_loss=8.827602\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=8.952781677246094\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] Epoch[51] Batch [10]#011Speed: 852.02 samples/sec#011loss=8.952782\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] processed a total of 656 examples\n",
      "#metrics {\"StartTime\": 1727755730.5581973, \"EndTime\": 1727755731.880951, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1322.3624229431152, \"count\": 1, \"min\": 1322.3624229431152, \"max\": 1322.3624229431152}}}\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=496.04554124579306 records/second\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=51, train loss <loss>=8.82760238647461\n",
      "[10/01/2024 04:08:51 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:52 INFO 140492683822912] Epoch[52] Batch[0] avg_epoch_loss=8.809689\n",
      "[10/01/2024 04:08:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=8.809688568115234\n",
      "[10/01/2024 04:08:52 INFO 140492683822912] Epoch[52] Batch[5] avg_epoch_loss=8.870925\n",
      "[10/01/2024 04:08:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=8.870924631754557\n",
      "[10/01/2024 04:08:52 INFO 140492683822912] Epoch[52] Batch [5]#011Speed: 829.19 samples/sec#011loss=8.870925\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] Epoch[52] Batch[10] avg_epoch_loss=8.805478\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=8.726941299438476\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] Epoch[52] Batch [10]#011Speed: 797.46 samples/sec#011loss=8.726941\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] processed a total of 697 examples\n",
      "#metrics {\"StartTime\": 1727755731.881017, \"EndTime\": 1727755733.252887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1371.5832233428955, \"count\": 1, \"min\": 1371.5832233428955, \"max\": 1371.5832233428955}}}\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.1305246288872 records/second\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=52, train loss <loss>=8.805477662519975\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] Epoch[53] Batch[0] avg_epoch_loss=8.550768\n",
      "[10/01/2024 04:08:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=8.55076789855957\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] Epoch[53] Batch[5] avg_epoch_loss=8.825990\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=8.825990358988443\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] Epoch[53] Batch [5]#011Speed: 912.23 samples/sec#011loss=8.825990\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] processed a total of 610 examples\n",
      "#metrics {\"StartTime\": 1727755733.252964, \"EndTime\": 1727755734.4655323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1211.890697479248, \"count\": 1, \"min\": 1211.890697479248, \"max\": 1211.890697479248}}}\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.30047339478057 records/second\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=53, train loss <loss>=8.792423057556153\n",
      "[10/01/2024 04:08:54 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] Epoch[54] Batch[0] avg_epoch_loss=8.808213\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=8.808213233947754\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] Epoch[54] Batch[5] avg_epoch_loss=8.809821\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=8.809821446736654\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] Epoch[54] Batch [5]#011Speed: 930.66 samples/sec#011loss=8.809821\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] processed a total of 622 examples\n",
      "#metrics {\"StartTime\": 1727755734.4655995, \"EndTime\": 1727755735.6698961, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1203.874111175537, \"count\": 1, \"min\": 1203.874111175537, \"max\": 1203.874111175537}}}\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=516.6226529165035 records/second\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=54, train loss <loss>=8.82182559967041\n",
      "[10/01/2024 04:08:55 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] Epoch[55] Batch[0] avg_epoch_loss=8.855705\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=8.855705261230469\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] Epoch[55] Batch[5] avg_epoch_loss=8.790287\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=8.790287335713705\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] Epoch[55] Batch [5]#011Speed: 940.71 samples/sec#011loss=8.790287\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] Epoch[55] Batch[10] avg_epoch_loss=8.798755\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=8.808915901184083\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] Epoch[55] Batch [10]#011Speed: 826.05 samples/sec#011loss=8.808916\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] processed a total of 666 examples\n",
      "#metrics {\"StartTime\": 1727755735.6699636, \"EndTime\": 1727755736.9583507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1288.0785465240479, \"count\": 1, \"min\": 1288.0785465240479, \"max\": 1288.0785465240479}}}\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=517.0099783398232 records/second\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=55, train loss <loss>=8.798754865472967\n",
      "[10/01/2024 04:08:56 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:08:57 INFO 140492683822912] Epoch[56] Batch[0] avg_epoch_loss=8.557764\n",
      "[10/01/2024 04:08:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=8.557764053344727\n",
      "[10/01/2024 04:08:57 INFO 140492683822912] Epoch[56] Batch[5] avg_epoch_loss=8.661320\n",
      "[10/01/2024 04:08:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=8.661320368448893\n",
      "[10/01/2024 04:08:57 INFO 140492683822912] Epoch[56] Batch [5]#011Speed: 875.04 samples/sec#011loss=8.661320\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] processed a total of 608 examples\n",
      "#metrics {\"StartTime\": 1727755736.958419, \"EndTime\": 1727755738.1842587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1225.473165512085, \"count\": 1, \"min\": 1225.473165512085, \"max\": 1225.473165512085}}}\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=496.091462685127 records/second\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=56, train loss <loss>=8.682370853424072\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_9cbd727f-b3a7-45c6-b2d1-b30827089445-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755738.1843355, \"EndTime\": 1727755738.1942463, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.421348571777344, \"count\": 1, \"min\": 9.421348571777344, \"max\": 9.421348571777344}}}\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] Epoch[57] Batch[0] avg_epoch_loss=8.746379\n",
      "[10/01/2024 04:08:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=8.746378898620605\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] Epoch[57] Batch[5] avg_epoch_loss=8.794339\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=8.794339179992676\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] Epoch[57] Batch [5]#011Speed: 904.48 samples/sec#011loss=8.794339\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] Epoch[57] Batch[10] avg_epoch_loss=8.818114\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=8.846644592285156\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] Epoch[57] Batch [10]#011Speed: 898.85 samples/sec#011loss=8.846645\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] processed a total of 643 examples\n",
      "#metrics {\"StartTime\": 1727755738.1943119, \"EndTime\": 1727755739.4892423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1294.8758602142334, \"count\": 1, \"min\": 1294.8758602142334, \"max\": 1294.8758602142334}}}\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=496.53777410781765 records/second\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=57, train loss <loss>=8.81811436739835\n",
      "[10/01/2024 04:08:59 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] Epoch[58] Batch[0] avg_epoch_loss=8.934727\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=8.93472671508789\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] Epoch[58] Batch[5] avg_epoch_loss=8.827176\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=8.827175935109457\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] Epoch[58] Batch [5]#011Speed: 942.42 samples/sec#011loss=8.827176\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] processed a total of 618 examples\n",
      "#metrics {\"StartTime\": 1727755739.4893036, \"EndTime\": 1727755740.6932397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1203.4804821014404, \"count\": 1, \"min\": 1203.4804821014404, \"max\": 1203.4804821014404}}}\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.4414456100624 records/second\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=58, train loss <loss>=8.806625080108642\n",
      "[10/01/2024 04:09:00 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:01 INFO 140492683822912] Epoch[59] Batch[0] avg_epoch_loss=8.659199\n",
      "[10/01/2024 04:09:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=8.659198760986328\n",
      "[10/01/2024 04:09:01 INFO 140492683822912] Epoch[59] Batch[5] avg_epoch_loss=8.635754\n",
      "[10/01/2024 04:09:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=8.635753949483236\n",
      "[10/01/2024 04:09:01 INFO 140492683822912] Epoch[59] Batch [5]#011Speed: 693.17 samples/sec#011loss=8.635754\n",
      "[10/01/2024 04:09:02 INFO 140492683822912] processed a total of 620 examples\n",
      "#metrics {\"StartTime\": 1727755740.693369, \"EndTime\": 1727755742.1559155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1462.216854095459, \"count\": 1, \"min\": 1462.216854095459, \"max\": 1462.216854095459}}}\n",
      "[10/01/2024 04:09:02 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=423.9848866835502 records/second\n",
      "[10/01/2024 04:09:02 INFO 140492683822912] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[10/01/2024 04:09:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=59, train loss <loss>=8.730422973632812\n",
      "[10/01/2024 04:09:02 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:02 INFO 140492683822912] Epoch[60] Batch[0] avg_epoch_loss=8.783667\n",
      "[10/01/2024 04:09:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=8.783666610717773\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] Epoch[60] Batch[5] avg_epoch_loss=8.711977\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=8.711977005004883\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] Epoch[60] Batch [5]#011Speed: 699.86 samples/sec#011loss=8.711977\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] processed a total of 585 examples\n",
      "#metrics {\"StartTime\": 1727755742.1559842, \"EndTime\": 1727755743.577188, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1420.903205871582, \"count\": 1, \"min\": 1420.903205871582, \"max\": 1420.903205871582}}}\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=411.68212025865995 records/second\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=60, train loss <loss>=8.80184268951416\n",
      "[10/01/2024 04:09:03 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] Epoch[61] Batch[0] avg_epoch_loss=8.647119\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=8.64711856842041\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] Epoch[61] Batch[5] avg_epoch_loss=8.763930\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=8.763930002848307\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] Epoch[61] Batch [5]#011Speed: 922.84 samples/sec#011loss=8.763930\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] Epoch[61] Batch[10] avg_epoch_loss=8.780700\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=8.800823402404784\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] Epoch[61] Batch [10]#011Speed: 798.96 samples/sec#011loss=8.800823\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] processed a total of 688 examples\n",
      "#metrics {\"StartTime\": 1727755743.5772548, \"EndTime\": 1727755744.8777616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1300.07004737854, \"count\": 1, \"min\": 1300.07004737854, \"max\": 1300.07004737854}}}\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=529.1645047254146 records/second\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=61, train loss <loss>=8.780699729919434\n",
      "[10/01/2024 04:09:04 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:05 INFO 140492683822912] Epoch[62] Batch[0] avg_epoch_loss=8.654251\n",
      "[10/01/2024 04:09:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=8.654251098632812\n",
      "[10/01/2024 04:09:05 INFO 140492683822912] Epoch[62] Batch[5] avg_epoch_loss=8.729102\n",
      "[10/01/2024 04:09:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=8.72910245259603\n",
      "[10/01/2024 04:09:05 INFO 140492683822912] Epoch[62] Batch [5]#011Speed: 922.77 samples/sec#011loss=8.729102\n",
      "[10/01/2024 04:09:06 INFO 140492683822912] processed a total of 639 examples\n",
      "#metrics {\"StartTime\": 1727755744.877824, \"EndTime\": 1727755746.1003067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1222.043752670288, \"count\": 1, \"min\": 1222.043752670288, \"max\": 1222.043752670288}}}\n",
      "[10/01/2024 04:09:06 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=522.8526100295082 records/second\n",
      "[10/01/2024 04:09:06 INFO 140492683822912] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[10/01/2024 04:09:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=62, train loss <loss>=8.69704465866089\n",
      "[10/01/2024 04:09:06 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:06 INFO 140492683822912] Epoch[63] Batch[0] avg_epoch_loss=8.710941\n",
      "[10/01/2024 04:09:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=8.710941314697266\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] Epoch[63] Batch[5] avg_epoch_loss=8.707457\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=8.707456588745117\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] Epoch[63] Batch [5]#011Speed: 871.65 samples/sec#011loss=8.707457\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] processed a total of 630 examples\n",
      "#metrics {\"StartTime\": 1727755746.1003733, \"EndTime\": 1727755747.3500588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1249.2907047271729, \"count\": 1, \"min\": 1249.2907047271729, \"max\": 1249.2907047271729}}}\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=504.2460215231049 records/second\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=63, train loss <loss>=8.66268253326416\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_d3b63525-5967-4b7d-bbc6-e5534b56dcee-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755747.350128, \"EndTime\": 1727755747.360952, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.490655899047852, \"count\": 1, \"min\": 10.490655899047852, \"max\": 10.490655899047852}}}\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] Epoch[64] Batch[0] avg_epoch_loss=8.726101\n",
      "[10/01/2024 04:09:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=8.72610092163086\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] Epoch[64] Batch[5] avg_epoch_loss=8.688853\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=8.68885326385498\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] Epoch[64] Batch [5]#011Speed: 915.85 samples/sec#011loss=8.688853\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] Epoch[64] Batch[10] avg_epoch_loss=8.780798\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=8.89113121032715\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] Epoch[64] Batch [10]#011Speed: 881.39 samples/sec#011loss=8.891131\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] processed a total of 648 examples\n",
      "#metrics {\"StartTime\": 1727755747.3610084, \"EndTime\": 1727755748.6562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1295.1388359069824, \"count\": 1, \"min\": 1295.1388359069824, \"max\": 1295.1388359069824}}}\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.29700229595784 records/second\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=64, train loss <loss>=8.780797784978693\n",
      "[10/01/2024 04:09:08 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] Epoch[65] Batch[0] avg_epoch_loss=9.003256\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=9.003255844116211\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] Epoch[65] Batch[5] avg_epoch_loss=8.870274\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=8.87027359008789\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] Epoch[65] Batch [5]#011Speed: 924.85 samples/sec#011loss=8.870274\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] processed a total of 617 examples\n",
      "#metrics {\"StartTime\": 1727755748.6562626, \"EndTime\": 1727755749.868373, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1211.838722229004, \"count\": 1, \"min\": 1211.838722229004, \"max\": 1211.838722229004}}}\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=509.10159032428135 records/second\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=65, train loss <loss>=8.781496906280518\n",
      "[10/01/2024 04:09:09 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:10 INFO 140492683822912] Epoch[66] Batch[0] avg_epoch_loss=8.645834\n",
      "[10/01/2024 04:09:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=8.645833969116211\n",
      "[10/01/2024 04:09:10 INFO 140492683822912] Epoch[66] Batch[5] avg_epoch_loss=8.805892\n",
      "[10/01/2024 04:09:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=8.805891513824463\n",
      "[10/01/2024 04:09:10 INFO 140492683822912] Epoch[66] Batch [5]#011Speed: 927.38 samples/sec#011loss=8.805892\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] Epoch[66] Batch[10] avg_epoch_loss=8.729011\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=8.636754608154297\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] Epoch[66] Batch [10]#011Speed: 856.62 samples/sec#011loss=8.636755\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] processed a total of 661 examples\n",
      "#metrics {\"StartTime\": 1727755749.8684406, \"EndTime\": 1727755751.1555576, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1286.8070602416992, \"count\": 1, \"min\": 1286.8070602416992, \"max\": 1286.8070602416992}}}\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.6339801907707 records/second\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=66, train loss <loss>=8.729011102156205\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] Epoch[67] Batch[0] avg_epoch_loss=8.590563\n",
      "[10/01/2024 04:09:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=8.59056282043457\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] Epoch[67] Batch[5] avg_epoch_loss=8.672823\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=8.672823111216227\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] Epoch[67] Batch [5]#011Speed: 921.97 samples/sec#011loss=8.672823\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] Epoch[67] Batch[10] avg_epoch_loss=8.686451\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=8.702804374694825\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] Epoch[67] Batch [10]#011Speed: 855.05 samples/sec#011loss=8.702804\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] processed a total of 664 examples\n",
      "#metrics {\"StartTime\": 1727755751.1556268, \"EndTime\": 1727755752.4465563, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1290.5659675598145, \"count\": 1, \"min\": 1290.5659675598145, \"max\": 1290.5659675598145}}}\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=514.4673110305333 records/second\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=67, train loss <loss>=8.686450958251953\n",
      "[10/01/2024 04:09:12 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] Epoch[68] Batch[0] avg_epoch_loss=8.556217\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=8.556217193603516\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] Epoch[68] Batch[5] avg_epoch_loss=8.689679\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=8.689678510030111\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] Epoch[68] Batch [5]#011Speed: 924.13 samples/sec#011loss=8.689679\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] processed a total of 606 examples\n",
      "#metrics {\"StartTime\": 1727755752.4466164, \"EndTime\": 1727755753.6572926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1210.3395462036133, \"count\": 1, \"min\": 1210.3395462036133, \"max\": 1210.3395462036133}}}\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.6452155774782 records/second\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=68, train loss <loss>=8.633088302612304\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:09:13 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_81b28fd5-9d6f-4065-a8c5-f6c006927806-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755753.6573598, \"EndTime\": 1727755753.668459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.51950454711914, \"count\": 1, \"min\": 10.51950454711914, \"max\": 10.51950454711914}}}\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] Epoch[69] Batch[0] avg_epoch_loss=8.720855\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=8.720854759216309\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] Epoch[69] Batch[5] avg_epoch_loss=8.974245\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=8.974245389302572\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] Epoch[69] Batch [5]#011Speed: 936.34 samples/sec#011loss=8.974245\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] Epoch[69] Batch[10] avg_epoch_loss=9.139869\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=9.338617134094239\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] Epoch[69] Batch [10]#011Speed: 854.38 samples/sec#011loss=9.338617\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] processed a total of 655 examples\n",
      "#metrics {\"StartTime\": 1727755753.6685166, \"EndTime\": 1727755754.9561923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1287.628412246704, \"count\": 1, \"min\": 1287.628412246704, \"max\": 1287.628412246704}}}\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.6547298497014 records/second\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=69, train loss <loss>=9.13986890966242\n",
      "[10/01/2024 04:09:14 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:15 INFO 140492683822912] Epoch[70] Batch[0] avg_epoch_loss=8.851495\n",
      "[10/01/2024 04:09:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=8.851494789123535\n",
      "[10/01/2024 04:09:15 INFO 140492683822912] Epoch[70] Batch[5] avg_epoch_loss=8.796930\n",
      "[10/01/2024 04:09:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=8.796929677327475\n",
      "[10/01/2024 04:09:15 INFO 140492683822912] Epoch[70] Batch [5]#011Speed: 934.29 samples/sec#011loss=8.796930\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] Epoch[70] Batch[10] avg_epoch_loss=8.856167\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=8.927251625061036\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] Epoch[70] Batch [10]#011Speed: 862.62 samples/sec#011loss=8.927252\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] processed a total of 648 examples\n",
      "#metrics {\"StartTime\": 1727755754.9562485, \"EndTime\": 1727755756.2449408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1288.400650024414, \"count\": 1, \"min\": 1288.400650024414, \"max\": 1288.400650024414}}}\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.91359033485395 records/second\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=70, train loss <loss>=8.856166926297275\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] Epoch[71] Batch[0] avg_epoch_loss=8.686101\n",
      "[10/01/2024 04:09:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=8.686100959777832\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] Epoch[71] Batch[5] avg_epoch_loss=8.839399\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=8.839399178822836\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] Epoch[71] Batch [5]#011Speed: 922.98 samples/sec#011loss=8.839399\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] Epoch[71] Batch[10] avg_epoch_loss=8.800494\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=8.753807640075683\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] Epoch[71] Batch [10]#011Speed: 914.73 samples/sec#011loss=8.753808\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] processed a total of 643 examples\n",
      "#metrics {\"StartTime\": 1727755756.2450037, \"EndTime\": 1727755757.524644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1279.372215270996, \"count\": 1, \"min\": 1279.372215270996, \"max\": 1279.372215270996}}}\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.55091441417267 records/second\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=71, train loss <loss>=8.800493933937766\n",
      "[10/01/2024 04:09:17 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] Epoch[72] Batch[0] avg_epoch_loss=8.685212\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=8.685212135314941\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] Epoch[72] Batch[5] avg_epoch_loss=8.751716\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=8.751716136932373\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] Epoch[72] Batch [5]#011Speed: 935.98 samples/sec#011loss=8.751716\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] processed a total of 611 examples\n",
      "#metrics {\"StartTime\": 1727755757.524715, \"EndTime\": 1727755758.7290447, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1203.8064002990723, \"count\": 1, \"min\": 1203.8064002990723, \"max\": 1203.8064002990723}}}\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=507.51518384931074 records/second\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=72, train loss <loss>=8.746677875518799\n",
      "[10/01/2024 04:09:18 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:19 INFO 140492683822912] Epoch[73] Batch[0] avg_epoch_loss=8.660042\n",
      "[10/01/2024 04:09:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=8.660041809082031\n",
      "[10/01/2024 04:09:19 INFO 140492683822912] Epoch[73] Batch[5] avg_epoch_loss=8.739146\n",
      "[10/01/2024 04:09:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=8.73914623260498\n",
      "[10/01/2024 04:09:19 INFO 140492683822912] Epoch[73] Batch [5]#011Speed: 936.13 samples/sec#011loss=8.739146\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] Epoch[73] Batch[10] avg_epoch_loss=8.636485\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=8.513292407989502\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] Epoch[73] Batch [10]#011Speed: 838.99 samples/sec#011loss=8.513292\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] processed a total of 665 examples\n",
      "#metrics {\"StartTime\": 1727755758.7291138, \"EndTime\": 1727755760.0145054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1285.081148147583, \"count\": 1, \"min\": 1285.081148147583, \"max\": 1285.081148147583}}}\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=517.4333695206137 records/second\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=73, train loss <loss>=8.636485403234309\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] Epoch[74] Batch[0] avg_epoch_loss=8.808323\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=8.80832290649414\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] Epoch[74] Batch[5] avg_epoch_loss=8.677368\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=8.67736848195394\n",
      "[10/01/2024 04:09:20 INFO 140492683822912] Epoch[74] Batch [5]#011Speed: 930.99 samples/sec#011loss=8.677368\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] processed a total of 625 examples\n",
      "#metrics {\"StartTime\": 1727755760.014581, \"EndTime\": 1727755761.2179215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1202.6550769805908, \"count\": 1, \"min\": 1202.6550769805908, \"max\": 1202.6550769805908}}}\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=519.6406458479237 records/second\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=74, train loss <loss>=8.631125259399415\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_df74bece-4cd4-4ced-942d-a7701986aaea-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755761.2179892, \"EndTime\": 1727755761.2287443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.426521301269531, \"count\": 1, \"min\": 10.426521301269531, \"max\": 10.426521301269531}}}\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] Epoch[75] Batch[0] avg_epoch_loss=8.532869\n",
      "[10/01/2024 04:09:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=8.532869338989258\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] Epoch[75] Batch[5] avg_epoch_loss=8.694515\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=8.694515228271484\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] Epoch[75] Batch [5]#011Speed: 930.34 samples/sec#011loss=8.694515\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] Epoch[75] Batch[10] avg_epoch_loss=8.789814\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=8.904172134399413\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] Epoch[75] Batch [10]#011Speed: 892.53 samples/sec#011loss=8.904172\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] processed a total of 654 examples\n",
      "#metrics {\"StartTime\": 1727755761.2288008, \"EndTime\": 1727755762.504649, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1275.7995128631592, \"count\": 1, \"min\": 1275.7995128631592, \"max\": 1275.7995128631592}}}\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=512.5851481055983 records/second\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=75, train loss <loss>=8.789813821965998\n",
      "[10/01/2024 04:09:22 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] Epoch[76] Batch[0] avg_epoch_loss=8.910514\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=8.910513877868652\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] Epoch[76] Batch[5] avg_epoch_loss=8.797832\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=8.797832489013672\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] Epoch[76] Batch [5]#011Speed: 944.83 samples/sec#011loss=8.797832\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] Epoch[76] Batch[10] avg_epoch_loss=8.754505\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=8.70251293182373\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] Epoch[76] Batch [10]#011Speed: 857.93 samples/sec#011loss=8.702513\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] processed a total of 667 examples\n",
      "#metrics {\"StartTime\": 1727755762.504709, \"EndTime\": 1727755763.7862544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1281.2695503234863, \"count\": 1, \"min\": 1281.2695503234863, \"max\": 1281.2695503234863}}}\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=520.4807651377704 records/second\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=76, train loss <loss>=8.7545054175637\n",
      "[10/01/2024 04:09:23 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] Epoch[77] Batch[0] avg_epoch_loss=8.638189\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=8.638189315795898\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] Epoch[77] Batch[5] avg_epoch_loss=8.659131\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=8.659131209055582\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] Epoch[77] Batch [5]#011Speed: 952.83 samples/sec#011loss=8.659131\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] processed a total of 637 examples\n",
      "#metrics {\"StartTime\": 1727755763.7864604, \"EndTime\": 1727755764.9838605, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1197.037696838379, \"count\": 1, \"min\": 1197.037696838379, \"max\": 1197.037696838379}}}\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=532.0962196629941 records/second\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=77, train loss <loss>=8.663620471954346\n",
      "[10/01/2024 04:09:24 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:25 INFO 140492683822912] Epoch[78] Batch[0] avg_epoch_loss=8.551926\n",
      "[10/01/2024 04:09:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=8.551925659179688\n",
      "[10/01/2024 04:09:25 INFO 140492683822912] Epoch[78] Batch[5] avg_epoch_loss=8.771318\n",
      "[10/01/2024 04:09:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=8.771317799886068\n",
      "[10/01/2024 04:09:25 INFO 140492683822912] Epoch[78] Batch [5]#011Speed: 949.79 samples/sec#011loss=8.771318\n",
      "[10/01/2024 04:09:26 INFO 140492683822912] processed a total of 636 examples\n",
      "#metrics {\"StartTime\": 1727755764.983928, \"EndTime\": 1727755766.1852221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1200.7718086242676, \"count\": 1, \"min\": 1200.7718086242676, \"max\": 1200.7718086242676}}}\n",
      "[10/01/2024 04:09:26 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=529.6158017287112 records/second\n",
      "[10/01/2024 04:09:26 INFO 140492683822912] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[10/01/2024 04:09:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=78, train loss <loss>=8.711937046051025\n",
      "[10/01/2024 04:09:26 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:26 INFO 140492683822912] Epoch[79] Batch[0] avg_epoch_loss=8.759109\n",
      "[10/01/2024 04:09:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=8.759108543395996\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] Epoch[79] Batch[5] avg_epoch_loss=8.697207\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=8.697206815083822\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] Epoch[79] Batch [5]#011Speed: 945.19 samples/sec#011loss=8.697207\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] Epoch[79] Batch[10] avg_epoch_loss=8.643869\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=8.579864692687988\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] Epoch[79] Batch [10]#011Speed: 856.86 samples/sec#011loss=8.579865\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] processed a total of 645 examples\n",
      "#metrics {\"StartTime\": 1727755766.185289, \"EndTime\": 1727755767.4769049, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1291.3014888763428, \"count\": 1, \"min\": 1291.3014888763428, \"max\": 1291.3014888763428}}}\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=499.4612893077581 records/second\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=79, train loss <loss>=8.64386948672208\n",
      "[10/01/2024 04:09:27 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] Epoch[80] Batch[0] avg_epoch_loss=8.569449\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=8.569449424743652\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] Epoch[80] Batch[5] avg_epoch_loss=8.671622\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=8.671621640523275\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] Epoch[80] Batch [5]#011Speed: 934.97 samples/sec#011loss=8.671622\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755767.4769673, \"EndTime\": 1727755768.6827297, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1205.4991722106934, \"count\": 1, \"min\": 1205.4991722106934, \"max\": 1205.4991722106934}}}\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=524.2219538400719 records/second\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=80, train loss <loss>=8.66674633026123\n",
      "[10/01/2024 04:09:28 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] Epoch[81] Batch[0] avg_epoch_loss=8.818377\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=8.818377494812012\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] Epoch[81] Batch[5] avg_epoch_loss=8.631063\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=8.631063302357992\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] Epoch[81] Batch [5]#011Speed: 953.89 samples/sec#011loss=8.631063\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] Epoch[81] Batch[10] avg_epoch_loss=8.664117\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=8.703781890869141\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] Epoch[81] Batch [10]#011Speed: 876.91 samples/sec#011loss=8.703782\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] processed a total of 655 examples\n",
      "#metrics {\"StartTime\": 1727755768.6827981, \"EndTime\": 1727755769.9544334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1271.153450012207, \"count\": 1, \"min\": 1271.153450012207, \"max\": 1271.153450012207}}}\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.2418670746188 records/second\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=81, train loss <loss>=8.664117206226695\n",
      "[10/01/2024 04:09:29 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:30 INFO 140492683822912] Epoch[82] Batch[0] avg_epoch_loss=8.645557\n",
      "[10/01/2024 04:09:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=8.645557403564453\n",
      "[10/01/2024 04:09:30 INFO 140492683822912] Epoch[82] Batch[5] avg_epoch_loss=8.644536\n",
      "[10/01/2024 04:09:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=8.6445361773173\n",
      "[10/01/2024 04:09:30 INFO 140492683822912] Epoch[82] Batch [5]#011Speed: 944.51 samples/sec#011loss=8.644536\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] Epoch[82] Batch[10] avg_epoch_loss=8.460346\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=8.239318466186523\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] Epoch[82] Batch [10]#011Speed: 871.07 samples/sec#011loss=8.239318\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] processed a total of 649 examples\n",
      "#metrics {\"StartTime\": 1727755769.9544978, \"EndTime\": 1727755771.2867174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1331.8097591400146, \"count\": 1, \"min\": 1331.8097591400146, \"max\": 1331.8097591400146}}}\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=487.2708971226152 records/second\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=82, train loss <loss>=8.460346308621494\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_dca1474a-2b2b-4a4e-a16f-2d7cd33fb536-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755771.2867837, \"EndTime\": 1727755771.2963288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.09733772277832, \"count\": 1, \"min\": 9.09733772277832, \"max\": 9.09733772277832}}}\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] Epoch[83] Batch[0] avg_epoch_loss=8.460825\n",
      "[10/01/2024 04:09:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=8.460824966430664\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] Epoch[83] Batch[5] avg_epoch_loss=8.656446\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=8.656445821126303\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] Epoch[83] Batch [5]#011Speed: 930.83 samples/sec#011loss=8.656446\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] processed a total of 639 examples\n",
      "#metrics {\"StartTime\": 1727755771.2963915, \"EndTime\": 1727755772.495474, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1199.0292072296143, \"count\": 1, \"min\": 1199.0292072296143, \"max\": 1199.0292072296143}}}\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=532.8841976675383 records/second\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=83, train loss <loss>=8.63921422958374\n",
      "[10/01/2024 04:09:32 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] Epoch[84] Batch[0] avg_epoch_loss=8.453347\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=8.453347206115723\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] Epoch[84] Batch[5] avg_epoch_loss=8.510962\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=8.51096216837565\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] Epoch[84] Batch [5]#011Speed: 929.85 samples/sec#011loss=8.510962\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] Epoch[84] Batch[10] avg_epoch_loss=8.454160\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=8.385998439788818\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] Epoch[84] Batch [10]#011Speed: 881.73 samples/sec#011loss=8.385998\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] processed a total of 660 examples\n",
      "#metrics {\"StartTime\": 1727755772.4955485, \"EndTime\": 1727755773.7789707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1283.0731868743896, \"count\": 1, \"min\": 1283.0731868743896, \"max\": 1283.0731868743896}}}\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=514.3505142686415 records/second\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=84, train loss <loss>=8.454160473563455\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:09:33 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_2b41bdd0-bb47-486f-9b1a-9c051a0f7613-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755773.779036, \"EndTime\": 1727755773.7889125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.432077407836914, \"count\": 1, \"min\": 9.432077407836914, \"max\": 9.432077407836914}}}\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] Epoch[85] Batch[0] avg_epoch_loss=9.058109\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=9.058109283447266\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] Epoch[85] Batch[5] avg_epoch_loss=9.132143\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=9.132142861684164\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] Epoch[85] Batch [5]#011Speed: 953.85 samples/sec#011loss=9.132143\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] processed a total of 639 examples\n",
      "#metrics {\"StartTime\": 1727755773.7889767, \"EndTime\": 1727755774.9877913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1198.7648010253906, \"count\": 1, \"min\": 1198.7648010253906, \"max\": 1198.7648010253906}}}\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=532.9542404613358 records/second\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=85, train loss <loss>=9.23288860321045\n",
      "[10/01/2024 04:09:34 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:35 INFO 140492683822912] Epoch[86] Batch[0] avg_epoch_loss=9.183923\n",
      "[10/01/2024 04:09:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=9.18392276763916\n",
      "[10/01/2024 04:09:35 INFO 140492683822912] Epoch[86] Batch[5] avg_epoch_loss=9.109581\n",
      "[10/01/2024 04:09:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=9.109581311543783\n",
      "[10/01/2024 04:09:35 INFO 140492683822912] Epoch[86] Batch [5]#011Speed: 938.91 samples/sec#011loss=9.109581\n",
      "[10/01/2024 04:09:36 INFO 140492683822912] processed a total of 630 examples\n",
      "#metrics {\"StartTime\": 1727755774.9878607, \"EndTime\": 1727755776.1908684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1202.3627758026123, \"count\": 1, \"min\": 1202.3627758026123, \"max\": 1202.3627758026123}}}\n",
      "[10/01/2024 04:09:36 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=523.9213590013496 records/second\n",
      "[10/01/2024 04:09:36 INFO 140492683822912] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[10/01/2024 04:09:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=86, train loss <loss>=9.038706970214843\n",
      "[10/01/2024 04:09:36 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:36 INFO 140492683822912] Epoch[87] Batch[0] avg_epoch_loss=8.838428\n",
      "[10/01/2024 04:09:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=8.838428497314453\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] Epoch[87] Batch[5] avg_epoch_loss=8.834655\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=8.834654649098715\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] Epoch[87] Batch [5]#011Speed: 927.96 samples/sec#011loss=8.834655\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] Epoch[87] Batch[10] avg_epoch_loss=8.763428\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=8.67795696258545\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] Epoch[87] Batch [10]#011Speed: 838.15 samples/sec#011loss=8.677957\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] processed a total of 671 examples\n",
      "#metrics {\"StartTime\": 1727755776.190942, \"EndTime\": 1727755777.4922407, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1300.8909225463867, \"count\": 1, \"min\": 1300.8909225463867, \"max\": 1300.8909225463867}}}\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.7499743900573 records/second\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=87, train loss <loss>=8.76342842795632\n",
      "[10/01/2024 04:09:37 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] Epoch[88] Batch[0] avg_epoch_loss=8.897247\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=8.897247314453125\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] Epoch[88] Batch[5] avg_epoch_loss=8.821167\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=8.8211669921875\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] Epoch[88] Batch [5]#011Speed: 916.69 samples/sec#011loss=8.821167\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] Epoch[88] Batch[10] avg_epoch_loss=8.870136\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=8.928899383544922\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] Epoch[88] Batch [10]#011Speed: 896.78 samples/sec#011loss=8.928899\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] processed a total of 647 examples\n",
      "#metrics {\"StartTime\": 1727755777.4923358, \"EndTime\": 1727755778.784703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1291.9244766235352, \"count\": 1, \"min\": 1291.9244766235352, \"max\": 1291.9244766235352}}}\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.7690746829636 records/second\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=88, train loss <loss>=8.870136260986328\n",
      "[10/01/2024 04:09:38 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] Epoch[89] Batch[0] avg_epoch_loss=8.787146\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=8.787145614624023\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] Epoch[89] Batch[5] avg_epoch_loss=8.776800\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=8.77679967880249\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] Epoch[89] Batch [5]#011Speed: 945.15 samples/sec#011loss=8.776800\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] processed a total of 611 examples\n",
      "#metrics {\"StartTime\": 1727755778.784762, \"EndTime\": 1727755779.983916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1198.8914012908936, \"count\": 1, \"min\": 1198.8914012908936, \"max\": 1198.8914012908936}}}\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=509.5968483068717 records/second\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=89, train loss <loss>=8.839237689971924\n",
      "[10/01/2024 04:09:39 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:40 INFO 140492683822912] Epoch[90] Batch[0] avg_epoch_loss=8.682425\n",
      "[10/01/2024 04:09:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=8.682425498962402\n",
      "[10/01/2024 04:09:40 INFO 140492683822912] Epoch[90] Batch[5] avg_epoch_loss=8.765485\n",
      "[10/01/2024 04:09:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=8.76548465092977\n",
      "[10/01/2024 04:09:40 INFO 140492683822912] Epoch[90] Batch [5]#011Speed: 937.95 samples/sec#011loss=8.765485\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] Epoch[90] Batch[10] avg_epoch_loss=8.742821\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=8.715624046325683\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] Epoch[90] Batch [10]#011Speed: 883.97 samples/sec#011loss=8.715624\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] processed a total of 649 examples\n",
      "#metrics {\"StartTime\": 1727755779.9839828, \"EndTime\": 1727755781.2628975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1278.4018516540527, \"count\": 1, \"min\": 1278.4018516540527, \"max\": 1278.4018516540527}}}\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=507.61028421927114 records/second\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=90, train loss <loss>=8.742820739746094\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] Epoch[91] Batch[0] avg_epoch_loss=8.738400\n",
      "[10/01/2024 04:09:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=8.738399505615234\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] Epoch[91] Batch[5] avg_epoch_loss=8.705502\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=8.705501874287924\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] Epoch[91] Batch [5]#011Speed: 935.59 samples/sec#011loss=8.705502\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] processed a total of 635 examples\n",
      "#metrics {\"StartTime\": 1727755781.263007, \"EndTime\": 1727755782.5028598, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1239.5756244659424, \"count\": 1, \"min\": 1239.5756244659424, \"max\": 1239.5756244659424}}}\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=512.2273647009363 records/second\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=91, train loss <loss>=8.700494194030762\n",
      "[10/01/2024 04:09:42 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] Epoch[92] Batch[0] avg_epoch_loss=8.784006\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=8.784006118774414\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] Epoch[92] Batch[5] avg_epoch_loss=8.668827\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=8.668826580047607\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] Epoch[92] Batch [5]#011Speed: 908.65 samples/sec#011loss=8.668827\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] processed a total of 635 examples\n",
      "#metrics {\"StartTime\": 1727755782.502935, \"EndTime\": 1727755783.7376935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1234.2638969421387, \"count\": 1, \"min\": 1234.2638969421387, \"max\": 1234.2638969421387}}}\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=514.4350497952889 records/second\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=92, train loss <loss>=8.700086784362792\n",
      "[10/01/2024 04:09:43 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] Epoch[93] Batch[0] avg_epoch_loss=8.597442\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=8.597441673278809\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] Epoch[93] Batch[5] avg_epoch_loss=8.619237\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=8.619236628214518\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] Epoch[93] Batch [5]#011Speed: 941.00 samples/sec#011loss=8.619237\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] processed a total of 637 examples\n",
      "#metrics {\"StartTime\": 1727755783.737762, \"EndTime\": 1727755784.9499927, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1211.9104862213135, \"count\": 1, \"min\": 1211.9104862213135, \"max\": 1211.9104862213135}}}\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=525.569746626978 records/second\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=93, train loss <loss>=8.658958530426025\n",
      "[10/01/2024 04:09:44 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:45 INFO 140492683822912] Epoch[94] Batch[0] avg_epoch_loss=8.884259\n",
      "[10/01/2024 04:09:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=8.884259223937988\n",
      "[10/01/2024 04:09:45 INFO 140492683822912] Epoch[94] Batch[5] avg_epoch_loss=8.668235\n",
      "[10/01/2024 04:09:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=8.668234825134277\n",
      "[10/01/2024 04:09:45 INFO 140492683822912] Epoch[94] Batch [5]#011Speed: 932.26 samples/sec#011loss=8.668235\n",
      "[10/01/2024 04:09:46 INFO 140492683822912] processed a total of 610 examples\n",
      "#metrics {\"StartTime\": 1727755784.9500673, \"EndTime\": 1727755786.1591585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1208.3511352539062, \"count\": 1, \"min\": 1208.3511352539062, \"max\": 1208.3511352539062}}}\n",
      "[10/01/2024 04:09:46 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=504.7589984702512 records/second\n",
      "[10/01/2024 04:09:46 INFO 140492683822912] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[10/01/2024 04:09:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=94, train loss <loss>=8.68593101501465\n",
      "[10/01/2024 04:09:46 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:46 INFO 140492683822912] Epoch[95] Batch[0] avg_epoch_loss=8.677719\n",
      "[10/01/2024 04:09:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=8.677719116210938\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] Epoch[95] Batch[5] avg_epoch_loss=8.659381\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=8.659380753835043\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] Epoch[95] Batch [5]#011Speed: 935.75 samples/sec#011loss=8.659381\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755786.159271, \"EndTime\": 1727755787.3631737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1203.3967971801758, \"count\": 1, \"min\": 1203.3967971801758, \"max\": 1203.3967971801758}}}\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=525.1340724196857 records/second\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=95, train loss <loss>=8.60709981918335\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] Epoch[96] Batch[0] avg_epoch_loss=8.721531\n",
      "[10/01/2024 04:09:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=8.72153091430664\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] Epoch[96] Batch[5] avg_epoch_loss=8.662951\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=8.662951469421387\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] Epoch[96] Batch [5]#011Speed: 827.75 samples/sec#011loss=8.662951\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] processed a total of 631 examples\n",
      "#metrics {\"StartTime\": 1727755787.3632452, \"EndTime\": 1727755788.6118538, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1248.1341361999512, \"count\": 1, \"min\": 1248.1341361999512, \"max\": 1248.1341361999512}}}\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.50249389085553 records/second\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=96, train loss <loss>=8.6863543510437\n",
      "[10/01/2024 04:09:48 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] Epoch[97] Batch[0] avg_epoch_loss=8.588425\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=8.588424682617188\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] Epoch[97] Batch[5] avg_epoch_loss=8.610300\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=8.610299905141195\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] Epoch[97] Batch [5]#011Speed: 931.07 samples/sec#011loss=8.610300\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] processed a total of 609 examples\n",
      "#metrics {\"StartTime\": 1727755788.6119232, \"EndTime\": 1727755789.8083596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1196.0704326629639, \"count\": 1, \"min\": 1196.0704326629639, \"max\": 1196.0704326629639}}}\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=509.12613589274576 records/second\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=97, train loss <loss>=8.501770257949829\n",
      "[10/01/2024 04:09:49 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:50 INFO 140492683822912] Epoch[98] Batch[0] avg_epoch_loss=8.804212\n",
      "[10/01/2024 04:09:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=8.804211616516113\n",
      "[10/01/2024 04:09:50 INFO 140492683822912] Epoch[98] Batch[5] avg_epoch_loss=8.692528\n",
      "[10/01/2024 04:09:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=8.692527770996094\n",
      "[10/01/2024 04:09:50 INFO 140492683822912] Epoch[98] Batch [5]#011Speed: 945.42 samples/sec#011loss=8.692528\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] Epoch[98] Batch[10] avg_epoch_loss=8.514184\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=8.300170707702637\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] Epoch[98] Batch [10]#011Speed: 890.06 samples/sec#011loss=8.300171\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] processed a total of 647 examples\n",
      "#metrics {\"StartTime\": 1727755789.808427, \"EndTime\": 1727755791.0976002, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1288.825273513794, \"count\": 1, \"min\": 1288.825273513794, \"max\": 1288.825273513794}}}\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=501.9695568034385 records/second\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=98, train loss <loss>=8.51418365131725\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] Epoch[99] Batch[0] avg_epoch_loss=8.773457\n",
      "[10/01/2024 04:09:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=8.773456573486328\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] Epoch[99] Batch[5] avg_epoch_loss=8.768638\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=8.768637657165527\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] Epoch[99] Batch [5]#011Speed: 950.68 samples/sec#011loss=8.768638\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] processed a total of 622 examples\n",
      "#metrics {\"StartTime\": 1727755791.097667, \"EndTime\": 1727755792.2970936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1198.9772319793701, \"count\": 1, \"min\": 1198.9772319793701, \"max\": 1198.9772319793701}}}\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.7316501302369 records/second\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=99, train loss <loss>=8.800265789031982\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] Epoch[100] Batch[0] avg_epoch_loss=9.078194\n",
      "[10/01/2024 04:09:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=9.078193664550781\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] Epoch[100] Batch[5] avg_epoch_loss=8.783474\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=8.78347380956014\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] Epoch[100] Batch [5]#011Speed: 896.87 samples/sec#011loss=8.783474\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] processed a total of 637 examples\n",
      "#metrics {\"StartTime\": 1727755792.2971606, \"EndTime\": 1727755793.5267959, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1229.2046546936035, \"count\": 1, \"min\": 1229.2046546936035, \"max\": 1229.2046546936035}}}\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.1796623476166 records/second\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=100, train loss <loss>=8.758074378967285\n",
      "[10/01/2024 04:09:53 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] Epoch[101] Batch[0] avg_epoch_loss=8.741437\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=8.741436958312988\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] Epoch[101] Batch[5] avg_epoch_loss=8.576246\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=8.576246420542398\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] Epoch[101] Batch [5]#011Speed: 943.61 samples/sec#011loss=8.576246\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] Epoch[101] Batch[10] avg_epoch_loss=8.557972\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=8.536042022705079\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] Epoch[101] Batch [10]#011Speed: 918.87 samples/sec#011loss=8.536042\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] processed a total of 642 examples\n",
      "#metrics {\"StartTime\": 1727755793.5268633, \"EndTime\": 1727755794.7936826, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1266.2746906280518, \"count\": 1, \"min\": 1266.2746906280518, \"max\": 1266.2746906280518}}}\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=506.96005402567124 records/second\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=101, train loss <loss>=8.557971694252707\n",
      "[10/01/2024 04:09:54 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] Epoch[102] Batch[0] avg_epoch_loss=8.666311\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=8.666311264038086\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] Epoch[102] Batch[5] avg_epoch_loss=8.708887\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=8.708886782328287\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] Epoch[102] Batch [5]#011Speed: 945.64 samples/sec#011loss=8.708887\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] processed a total of 640 examples\n",
      "#metrics {\"StartTime\": 1727755794.7937493, \"EndTime\": 1727755795.9941924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1200.0033855438232, \"count\": 1, \"min\": 1200.0033855438232, \"max\": 1200.0033855438232}}}\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=533.2828781393032 records/second\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=102, train loss <loss>=8.711353302001953\n",
      "[10/01/2024 04:09:55 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:56 INFO 140492683822912] Epoch[103] Batch[0] avg_epoch_loss=8.601993\n",
      "[10/01/2024 04:09:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=8.6019926071167\n",
      "[10/01/2024 04:09:56 INFO 140492683822912] Epoch[103] Batch[5] avg_epoch_loss=8.613963\n",
      "[10/01/2024 04:09:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=8.613962968190512\n",
      "[10/01/2024 04:09:56 INFO 140492683822912] Epoch[103] Batch [5]#011Speed: 932.38 samples/sec#011loss=8.613963\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] Epoch[103] Batch[10] avg_epoch_loss=8.705205\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=8.814694786071778\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] Epoch[103] Batch [10]#011Speed: 859.27 samples/sec#011loss=8.814695\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] processed a total of 663 examples\n",
      "#metrics {\"StartTime\": 1727755795.9942682, \"EndTime\": 1727755797.2800472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1285.301685333252, \"count\": 1, \"min\": 1285.301685333252, \"max\": 1285.301685333252}}}\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.7889571498895 records/second\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=103, train loss <loss>=8.705204703591086\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] Epoch[104] Batch[0] avg_epoch_loss=8.504117\n",
      "[10/01/2024 04:09:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=8.504117012023926\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] Epoch[104] Batch[5] avg_epoch_loss=8.583639\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=8.583639144897461\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] Epoch[104] Batch [5]#011Speed: 915.01 samples/sec#011loss=8.583639\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] processed a total of 625 examples\n",
      "#metrics {\"StartTime\": 1727755797.2801192, \"EndTime\": 1727755798.483992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1203.5019397735596, \"count\": 1, \"min\": 1203.5019397735596, \"max\": 1203.5019397735596}}}\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=519.2741998903784 records/second\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=104, train loss <loss>=8.570609378814698\n",
      "[10/01/2024 04:09:58 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] Epoch[105] Batch[0] avg_epoch_loss=8.761034\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=8.76103401184082\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] Epoch[105] Batch[5] avg_epoch_loss=8.558768\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=8.558767954508463\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] Epoch[105] Batch [5]#011Speed: 949.74 samples/sec#011loss=8.558768\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] Epoch[105] Batch[10] avg_epoch_loss=8.555352\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=8.551252174377442\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] Epoch[105] Batch [10]#011Speed: 867.42 samples/sec#011loss=8.551252\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] processed a total of 651 examples\n",
      "#metrics {\"StartTime\": 1727755798.4840589, \"EndTime\": 1727755799.7609763, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1276.4837741851807, \"count\": 1, \"min\": 1276.4837741851807, \"max\": 1276.4837741851807}}}\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=509.9572038088621 records/second\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=105, train loss <loss>=8.555351690812545\n",
      "[10/01/2024 04:09:59 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] Epoch[106] Batch[0] avg_epoch_loss=8.632385\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=8.63238525390625\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] Epoch[106] Batch[5] avg_epoch_loss=8.610666\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=8.610665639241537\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] Epoch[106] Batch [5]#011Speed: 936.61 samples/sec#011loss=8.610666\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] processed a total of 618 examples\n",
      "#metrics {\"StartTime\": 1727755799.7610414, \"EndTime\": 1727755800.9652467, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1203.861951828003, \"count\": 1, \"min\": 1203.861951828003, \"max\": 1203.861951828003}}}\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.3026586357342 records/second\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=106, train loss <loss>=8.628849124908447\n",
      "[10/01/2024 04:10:00 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:01 INFO 140492683822912] Epoch[107] Batch[0] avg_epoch_loss=8.774851\n",
      "[10/01/2024 04:10:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=8.774850845336914\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] Epoch[107] Batch[5] avg_epoch_loss=8.572926\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=8.57292636235555\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] Epoch[107] Batch [5]#011Speed: 731.05 samples/sec#011loss=8.572926\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] Epoch[107] Batch[10] avg_epoch_loss=8.581541\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=8.591878700256348\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] Epoch[107] Batch [10]#011Speed: 661.91 samples/sec#011loss=8.591879\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] processed a total of 675 examples\n",
      "#metrics {\"StartTime\": 1727755800.9653187, \"EndTime\": 1727755802.5184615, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1552.7050495147705, \"count\": 1, \"min\": 1552.7050495147705, \"max\": 1552.7050495147705}}}\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=434.6933530109194 records/second\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=107, train loss <loss>=8.581541061401367\n",
      "[10/01/2024 04:10:02 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] Epoch[108] Batch[0] avg_epoch_loss=8.653402\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=8.653402328491211\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] Epoch[108] Batch[5] avg_epoch_loss=8.640784\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=8.640783786773682\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] Epoch[108] Batch [5]#011Speed: 894.38 samples/sec#011loss=8.640784\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] Epoch[108] Batch[10] avg_epoch_loss=8.592420\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=8.534384155273438\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] Epoch[108] Batch [10]#011Speed: 789.56 samples/sec#011loss=8.534384\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] processed a total of 689 examples\n",
      "#metrics {\"StartTime\": 1727755802.518542, \"EndTime\": 1727755803.989368, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1470.442295074463, \"count\": 1, \"min\": 1470.442295074463, \"max\": 1470.442295074463}}}\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=468.53421363195 records/second\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=108, train loss <loss>=8.592420317909934\n",
      "[10/01/2024 04:10:03 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:04 INFO 140492683822912] Epoch[109] Batch[0] avg_epoch_loss=8.827857\n",
      "[10/01/2024 04:10:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=8.82785701751709\n",
      "[10/01/2024 04:10:04 INFO 140492683822912] Epoch[109] Batch[5] avg_epoch_loss=8.659796\n",
      "[10/01/2024 04:10:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=8.659795920054117\n",
      "[10/01/2024 04:10:04 INFO 140492683822912] Epoch[109] Batch [5]#011Speed: 925.52 samples/sec#011loss=8.659796\n",
      "[10/01/2024 04:10:05 INFO 140492683822912] processed a total of 636 examples\n",
      "#metrics {\"StartTime\": 1727755803.989438, \"EndTime\": 1727755805.2816715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1291.8355464935303, \"count\": 1, \"min\": 1291.8355464935303, \"max\": 1291.8355464935303}}}\n",
      "[10/01/2024 04:10:05 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=492.28411434611803 records/second\n",
      "[10/01/2024 04:10:05 INFO 140492683822912] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[10/01/2024 04:10:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=109, train loss <loss>=8.66983642578125\n",
      "[10/01/2024 04:10:05 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:05 INFO 140492683822912] Epoch[110] Batch[0] avg_epoch_loss=8.470703\n",
      "[10/01/2024 04:10:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=8.470703125\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] Epoch[110] Batch[5] avg_epoch_loss=8.677666\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=8.677665869394938\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] Epoch[110] Batch [5]#011Speed: 927.46 samples/sec#011loss=8.677666\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] Epoch[110] Batch[10] avg_epoch_loss=8.686686\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=8.697510719299316\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] Epoch[110] Batch [10]#011Speed: 837.02 samples/sec#011loss=8.697511\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] processed a total of 662 examples\n",
      "#metrics {\"StartTime\": 1727755805.28174, \"EndTime\": 1727755806.6456773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1363.5265827178955, \"count\": 1, \"min\": 1363.5265827178955, \"max\": 1363.5265827178955}}}\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=485.4723073364363 records/second\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=110, train loss <loss>=8.68668625571511\n",
      "[10/01/2024 04:10:06 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] Epoch[111] Batch[0] avg_epoch_loss=8.726102\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=8.726101875305176\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] Epoch[111] Batch[5] avg_epoch_loss=8.682170\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=8.682170391082764\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] Epoch[111] Batch [5]#011Speed: 922.40 samples/sec#011loss=8.682170\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] Epoch[111] Batch[10] avg_epoch_loss=8.669406\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=8.654088020324707\n",
      "[10/01/2024 04:10:07 INFO 140492683822912] Epoch[111] Batch [10]#011Speed: 782.08 samples/sec#011loss=8.654088\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] processed a total of 709 examples\n",
      "#metrics {\"StartTime\": 1727755806.6457403, \"EndTime\": 1727755808.0194101, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1373.3842372894287, \"count\": 1, \"min\": 1373.3842372894287, \"max\": 1373.3842372894287}}}\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=516.191922840651 records/second\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=111, train loss <loss>=8.723841587702433\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] Epoch[112] Batch[0] avg_epoch_loss=8.687786\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=8.687786102294922\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] Epoch[112] Batch[5] avg_epoch_loss=8.659939\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=8.659939289093018\n",
      "[10/01/2024 04:10:08 INFO 140492683822912] Epoch[112] Batch [5]#011Speed: 912.58 samples/sec#011loss=8.659939\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] Epoch[112] Batch[10] avg_epoch_loss=8.648778\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=8.635383415222169\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] Epoch[112] Batch [10]#011Speed: 877.44 samples/sec#011loss=8.635383\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] processed a total of 648 examples\n",
      "#metrics {\"StartTime\": 1727755808.019509, \"EndTime\": 1727755809.3170588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1297.1136569976807, \"count\": 1, \"min\": 1297.1136569976807, \"max\": 1297.1136569976807}}}\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=499.5332556378112 records/second\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=112, train loss <loss>=8.648777528242631\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] Epoch[113] Batch[0] avg_epoch_loss=8.527952\n",
      "[10/01/2024 04:10:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=8.527952194213867\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] Epoch[113] Batch[5] avg_epoch_loss=8.627185\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=8.627185185750326\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] Epoch[113] Batch [5]#011Speed: 912.03 samples/sec#011loss=8.627185\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] Epoch[113] Batch[10] avg_epoch_loss=8.563491\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=8.487058448791505\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] Epoch[113] Batch [10]#011Speed: 794.75 samples/sec#011loss=8.487058\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] processed a total of 696 examples\n",
      "#metrics {\"StartTime\": 1727755809.3171253, \"EndTime\": 1727755810.6179688, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1300.5404472351074, \"count\": 1, \"min\": 1300.5404472351074, \"max\": 1300.5404472351074}}}\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=535.123579741002 records/second\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=113, train loss <loss>=8.563491214405406\n",
      "[10/01/2024 04:10:10 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] Epoch[114] Batch[0] avg_epoch_loss=8.662628\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=8.662628173828125\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] Epoch[114] Batch[5] avg_epoch_loss=8.626988\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=8.62698761622111\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] Epoch[114] Batch [5]#011Speed: 926.61 samples/sec#011loss=8.626988\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] Epoch[114] Batch[10] avg_epoch_loss=8.687881\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=8.76095371246338\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] Epoch[114] Batch [10]#011Speed: 820.09 samples/sec#011loss=8.760954\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] processed a total of 649 examples\n",
      "#metrics {\"StartTime\": 1727755810.618032, \"EndTime\": 1727755811.934207, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1315.854549407959, \"count\": 1, \"min\": 1315.854549407959, \"max\": 1315.854549407959}}}\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=493.1793271129631 records/second\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=114, train loss <loss>=8.687881296331232\n",
      "[10/01/2024 04:10:11 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:12 INFO 140492683822912] Epoch[115] Batch[0] avg_epoch_loss=8.736329\n",
      "[10/01/2024 04:10:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=8.736329078674316\n",
      "[10/01/2024 04:10:12 INFO 140492683822912] Epoch[115] Batch[5] avg_epoch_loss=8.635168\n",
      "[10/01/2024 04:10:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=8.635167598724365\n",
      "[10/01/2024 04:10:12 INFO 140492683822912] Epoch[115] Batch [5]#011Speed: 925.22 samples/sec#011loss=8.635168\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] Epoch[115] Batch[10] avg_epoch_loss=8.698341\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=8.77414836883545\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] Epoch[115] Batch [10]#011Speed: 836.22 samples/sec#011loss=8.774148\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] processed a total of 673 examples\n",
      "#metrics {\"StartTime\": 1727755811.9342747, \"EndTime\": 1727755813.2280645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1293.416976928711, \"count\": 1, \"min\": 1293.416976928711, \"max\": 1293.416976928711}}}\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=520.2863179003983 records/second\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=115, train loss <loss>=8.698340676047586\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] Epoch[116] Batch[0] avg_epoch_loss=8.399285\n",
      "[10/01/2024 04:10:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=8.399285316467285\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] Epoch[116] Batch[5] avg_epoch_loss=8.571681\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=8.571680704752604\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] Epoch[116] Batch [5]#011Speed: 896.96 samples/sec#011loss=8.571681\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] processed a total of 623 examples\n",
      "#metrics {\"StartTime\": 1727755813.228135, \"EndTime\": 1727755814.4452553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1216.7716026306152, \"count\": 1, \"min\": 1216.7716026306152, \"max\": 1216.7716026306152}}}\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=511.96880206162825 records/second\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=116, train loss <loss>=8.655127716064452\n",
      "[10/01/2024 04:10:14 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] Epoch[117] Batch[0] avg_epoch_loss=8.592771\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=8.59277057647705\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] Epoch[117] Batch[5] avg_epoch_loss=8.537561\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=8.537560939788818\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] Epoch[117] Batch [5]#011Speed: 908.89 samples/sec#011loss=8.537561\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] Epoch[117] Batch[10] avg_epoch_loss=8.442220\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=8.327810478210449\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] Epoch[117] Batch [10]#011Speed: 857.84 samples/sec#011loss=8.327810\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] processed a total of 657 examples\n",
      "#metrics {\"StartTime\": 1727755814.4453242, \"EndTime\": 1727755815.7421093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1296.49019241333, \"count\": 1, \"min\": 1296.49019241333, \"max\": 1296.49019241333}}}\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=506.7184814504393 records/second\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=117, train loss <loss>=8.44221982088956\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:10:15 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_40922284-0474-447e-93a8-40f1b4256b88-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755815.74217, \"EndTime\": 1727755815.752984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.52236557006836, \"count\": 1, \"min\": 10.52236557006836, \"max\": 10.52236557006836}}}\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] Epoch[118] Batch[0] avg_epoch_loss=8.393891\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=8.393891334533691\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] Epoch[118] Batch[5] avg_epoch_loss=8.507780\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=8.507779757181803\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] Epoch[118] Batch [5]#011Speed: 908.40 samples/sec#011loss=8.507780\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] processed a total of 613 examples\n",
      "#metrics {\"StartTime\": 1727755815.7530432, \"EndTime\": 1727755816.9769235, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1223.8261699676514, \"count\": 1, \"min\": 1223.8261699676514, \"max\": 1223.8261699676514}}}\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.8459775542409 records/second\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=118, train loss <loss>=8.454924154281617\n",
      "[10/01/2024 04:10:16 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:17 INFO 140492683822912] Epoch[119] Batch[0] avg_epoch_loss=8.327549\n",
      "[10/01/2024 04:10:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=8.32754898071289\n",
      "[10/01/2024 04:10:17 INFO 140492683822912] Epoch[119] Batch[5] avg_epoch_loss=8.567284\n",
      "[10/01/2024 04:10:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=8.567283789316813\n",
      "[10/01/2024 04:10:17 INFO 140492683822912] Epoch[119] Batch [5]#011Speed: 923.81 samples/sec#011loss=8.567284\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] Epoch[119] Batch[10] avg_epoch_loss=8.628307\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=8.701534461975097\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] Epoch[119] Batch [10]#011Speed: 834.28 samples/sec#011loss=8.701534\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] processed a total of 668 examples\n",
      "#metrics {\"StartTime\": 1727755816.9769943, \"EndTime\": 1727755818.2758915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1298.302412033081, \"count\": 1, \"min\": 1298.302412033081, \"max\": 1298.302412033081}}}\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=514.421106688496 records/second\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=119, train loss <loss>=8.628306822343307\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] Epoch[120] Batch[0] avg_epoch_loss=8.531178\n",
      "[10/01/2024 04:10:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=8.53117847442627\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] Epoch[120] Batch[5] avg_epoch_loss=8.623863\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=8.623862743377686\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] Epoch[120] Batch [5]#011Speed: 928.05 samples/sec#011loss=8.623863\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] Epoch[120] Batch[10] avg_epoch_loss=8.589488\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=8.548239135742188\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] Epoch[120] Batch [10]#011Speed: 871.00 samples/sec#011loss=8.548239\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] processed a total of 677 examples\n",
      "#metrics {\"StartTime\": 1727755818.2759933, \"EndTime\": 1727755819.5505183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1273.7717628479004, \"count\": 1, \"min\": 1273.7717628479004, \"max\": 1273.7717628479004}}}\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=531.4550879184782 records/second\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=120, train loss <loss>=8.58948837627064\n",
      "[10/01/2024 04:10:19 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] Epoch[121] Batch[0] avg_epoch_loss=8.739348\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=8.739348411560059\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] Epoch[121] Batch[5] avg_epoch_loss=8.600660\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=8.600659688313803\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] Epoch[121] Batch [5]#011Speed: 940.51 samples/sec#011loss=8.600660\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] processed a total of 603 examples\n",
      "#metrics {\"StartTime\": 1727755819.5505784, \"EndTime\": 1727755820.7505808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1199.7272968292236, \"count\": 1, \"min\": 1199.7272968292236, \"max\": 1199.7272968292236}}}\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.57377098043764 records/second\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=121, train loss <loss>=8.639169025421143\n",
      "[10/01/2024 04:10:20 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:21 INFO 140492683822912] Epoch[122] Batch[0] avg_epoch_loss=8.537723\n",
      "[10/01/2024 04:10:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=8.53772258758545\n",
      "[10/01/2024 04:10:21 INFO 140492683822912] Epoch[122] Batch[5] avg_epoch_loss=8.566464\n",
      "[10/01/2024 04:10:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=8.566464106241861\n",
      "[10/01/2024 04:10:21 INFO 140492683822912] Epoch[122] Batch [5]#011Speed: 944.19 samples/sec#011loss=8.566464\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] Epoch[122] Batch[10] avg_epoch_loss=8.694199\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=8.847481727600098\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] Epoch[122] Batch [10]#011Speed: 842.55 samples/sec#011loss=8.847482\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] processed a total of 658 examples\n",
      "#metrics {\"StartTime\": 1727755820.750647, \"EndTime\": 1727755822.04038, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1289.1876697540283, \"count\": 1, \"min\": 1289.1876697540283, \"max\": 1289.1876697540283}}}\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=510.3612649057519 records/second\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=122, train loss <loss>=8.694199388677424\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] Epoch[123] Batch[0] avg_epoch_loss=8.717296\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=8.71729564666748\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] Epoch[123] Batch[5] avg_epoch_loss=8.603813\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=8.60381285349528\n",
      "[10/01/2024 04:10:22 INFO 140492683822912] Epoch[123] Batch [5]#011Speed: 932.36 samples/sec#011loss=8.603813\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] Epoch[123] Batch[10] avg_epoch_loss=8.569496\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=8.528316116333007\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] Epoch[123] Batch [10]#011Speed: 814.84 samples/sec#011loss=8.528316\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] processed a total of 682 examples\n",
      "#metrics {\"StartTime\": 1727755822.0404427, \"EndTime\": 1727755823.337448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1296.6248989105225, \"count\": 1, \"min\": 1296.6248989105225, \"max\": 1296.6248989105225}}}\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=525.9418828600127 records/second\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=123, train loss <loss>=8.569496154785156\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] Epoch[124] Batch[0] avg_epoch_loss=8.423789\n",
      "[10/01/2024 04:10:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=8.423789024353027\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] Epoch[124] Batch[5] avg_epoch_loss=8.596925\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=8.596924622853598\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] Epoch[124] Batch [5]#011Speed: 938.66 samples/sec#011loss=8.596925\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] Epoch[124] Batch[10] avg_epoch_loss=8.554840\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=8.504337692260743\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] Epoch[124] Batch [10]#011Speed: 844.41 samples/sec#011loss=8.504338\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] processed a total of 673 examples\n",
      "#metrics {\"StartTime\": 1727755823.3375146, \"EndTime\": 1727755824.6185522, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1280.623197555542, \"count\": 1, \"min\": 1280.623197555542, \"max\": 1280.623197555542}}}\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=525.4889922082323 records/second\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=124, train loss <loss>=8.554839654402299\n",
      "[10/01/2024 04:10:24 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] Epoch[125] Batch[0] avg_epoch_loss=8.461278\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=8.461277961730957\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] Epoch[125] Batch[5] avg_epoch_loss=8.515556\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=8.515556335449219\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] Epoch[125] Batch [5]#011Speed: 951.54 samples/sec#011loss=8.515556\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] processed a total of 637 examples\n",
      "#metrics {\"StartTime\": 1727755824.6186125, \"EndTime\": 1727755825.8266773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1207.7157497406006, \"count\": 1, \"min\": 1207.7157497406006, \"max\": 1207.7157497406006}}}\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=527.395139772644 records/second\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=125, train loss <loss>=8.5392427444458\n",
      "[10/01/2024 04:10:25 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:26 INFO 140492683822912] Epoch[126] Batch[0] avg_epoch_loss=8.339486\n",
      "[10/01/2024 04:10:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=8.339486122131348\n",
      "[10/01/2024 04:10:26 INFO 140492683822912] Epoch[126] Batch[5] avg_epoch_loss=8.506178\n",
      "[10/01/2024 04:10:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=8.50617774327596\n",
      "[10/01/2024 04:10:26 INFO 140492683822912] Epoch[126] Batch [5]#011Speed: 939.33 samples/sec#011loss=8.506178\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] processed a total of 624 examples\n",
      "#metrics {\"StartTime\": 1727755825.8267527, \"EndTime\": 1727755827.0255175, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1198.1194019317627, \"count\": 1, \"min\": 1198.1194019317627, \"max\": 1198.1194019317627}}}\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=520.7731981983775 records/second\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=126, train loss <loss>=8.524287509918214\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] Epoch[127] Batch[0] avg_epoch_loss=8.690293\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=8.690293312072754\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] Epoch[127] Batch[5] avg_epoch_loss=8.702634\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=8.702634334564209\n",
      "[10/01/2024 04:10:27 INFO 140492683822912] Epoch[127] Batch [5]#011Speed: 936.88 samples/sec#011loss=8.702634\n",
      "[10/01/2024 04:10:28 INFO 140492683822912] processed a total of 615 examples\n",
      "#metrics {\"StartTime\": 1727755827.0255833, \"EndTime\": 1727755828.227584, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1201.695203781128, \"count\": 1, \"min\": 1201.695203781128, \"max\": 1201.695203781128}}}\n",
      "[10/01/2024 04:10:28 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=511.73235542973566 records/second\n",
      "[10/01/2024 04:10:28 INFO 140492683822912] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[10/01/2024 04:10:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=127, train loss <loss>=8.529365158081054\n",
      "[10/01/2024 04:10:28 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:28 INFO 140492683822912] Epoch[128] Batch[0] avg_epoch_loss=8.521074\n",
      "[10/01/2024 04:10:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=8.521074295043945\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] Epoch[128] Batch[5] avg_epoch_loss=8.475908\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=8.475907643636068\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] Epoch[128] Batch [5]#011Speed: 923.62 samples/sec#011loss=8.475908\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] Epoch[128] Batch[10] avg_epoch_loss=8.483881\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=8.493449592590332\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] Epoch[128] Batch [10]#011Speed: 805.53 samples/sec#011loss=8.493450\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] processed a total of 696 examples\n",
      "#metrics {\"StartTime\": 1727755828.227656, \"EndTime\": 1727755829.5176473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1289.5634174346924, \"count\": 1, \"min\": 1289.5634174346924, \"max\": 1289.5634174346924}}}\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=539.6728437798157 records/second\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=128, train loss <loss>=8.483881256797098\n",
      "[10/01/2024 04:10:29 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] Epoch[129] Batch[0] avg_epoch_loss=8.696621\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=8.69662094116211\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] Epoch[129] Batch[5] avg_epoch_loss=8.592574\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=8.592574119567871\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] Epoch[129] Batch [5]#011Speed: 930.69 samples/sec#011loss=8.592574\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] Epoch[129] Batch[10] avg_epoch_loss=8.555023\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=8.50996265411377\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] Epoch[129] Batch [10]#011Speed: 880.22 samples/sec#011loss=8.509963\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] processed a total of 660 examples\n",
      "#metrics {\"StartTime\": 1727755829.5177188, \"EndTime\": 1727755830.7983181, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1280.195951461792, \"count\": 1, \"min\": 1280.195951461792, \"max\": 1280.195951461792}}}\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.5039301895541 records/second\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=129, train loss <loss>=8.555023453452371\n",
      "[10/01/2024 04:10:30 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:31 INFO 140492683822912] Epoch[130] Batch[0] avg_epoch_loss=8.480035\n",
      "[10/01/2024 04:10:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=8.480034828186035\n",
      "[10/01/2024 04:10:31 INFO 140492683822912] Epoch[130] Batch[5] avg_epoch_loss=8.465836\n",
      "[10/01/2024 04:10:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=8.46583636601766\n",
      "[10/01/2024 04:10:31 INFO 140492683822912] Epoch[130] Batch [5]#011Speed: 933.26 samples/sec#011loss=8.465836\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] Epoch[130] Batch[10] avg_epoch_loss=8.524395\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=8.594665336608887\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] Epoch[130] Batch [10]#011Speed: 852.47 samples/sec#011loss=8.594665\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] processed a total of 660 examples\n",
      "#metrics {\"StartTime\": 1727755830.7983801, \"EndTime\": 1727755832.0818124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1283.0939292907715, \"count\": 1, \"min\": 1283.0939292907715, \"max\": 1283.0939292907715}}}\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=514.3312101674144 records/second\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=130, train loss <loss>=8.524394989013672\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] Epoch[131] Batch[0] avg_epoch_loss=8.583805\n",
      "[10/01/2024 04:10:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=8.583805084228516\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] Epoch[131] Batch[5] avg_epoch_loss=8.568661\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=8.568660895029703\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] Epoch[131] Batch [5]#011Speed: 914.02 samples/sec#011loss=8.568661\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] processed a total of 634 examples\n",
      "#metrics {\"StartTime\": 1727755832.0819097, \"EndTime\": 1727755833.3080986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1225.8546352386475, \"count\": 1, \"min\": 1225.8546352386475, \"max\": 1225.8546352386475}}}\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=517.1465447280565 records/second\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=131, train loss <loss>=8.587900161743164\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] Epoch[132] Batch[0] avg_epoch_loss=8.683380\n",
      "[10/01/2024 04:10:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=8.683380126953125\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] Epoch[132] Batch[5] avg_epoch_loss=8.671872\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=8.67187245686849\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] Epoch[132] Batch [5]#011Speed: 913.01 samples/sec#011loss=8.671872\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] processed a total of 630 examples\n",
      "#metrics {\"StartTime\": 1727755833.30817, \"EndTime\": 1727755834.5111337, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1202.6290893554688, \"count\": 1, \"min\": 1202.6290893554688, \"max\": 1202.6290893554688}}}\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=523.809711846445 records/second\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=132, train loss <loss>=8.658887195587159\n",
      "[10/01/2024 04:10:34 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] Epoch[133] Batch[0] avg_epoch_loss=8.874398\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=8.874398231506348\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] Epoch[133] Batch[5] avg_epoch_loss=8.738946\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=8.738945643107096\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] Epoch[133] Batch [5]#011Speed: 930.19 samples/sec#011loss=8.738946\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] processed a total of 617 examples\n",
      "#metrics {\"StartTime\": 1727755834.5112019, \"EndTime\": 1727755835.7094343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1197.8578567504883, \"count\": 1, \"min\": 1197.8578567504883, \"max\": 1197.8578567504883}}}\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.0452541397001 records/second\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=133, train loss <loss>=8.752723693847656\n",
      "[10/01/2024 04:10:35 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] Epoch[134] Batch[0] avg_epoch_loss=8.693298\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=8.69329833984375\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] Epoch[134] Batch[5] avg_epoch_loss=8.529637\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=8.52963654200236\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] Epoch[134] Batch [5]#011Speed: 927.44 samples/sec#011loss=8.529637\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] Epoch[134] Batch[10] avg_epoch_loss=8.602863\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=8.690735626220704\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] Epoch[134] Batch [10]#011Speed: 884.60 samples/sec#011loss=8.690736\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] processed a total of 650 examples\n",
      "#metrics {\"StartTime\": 1727755835.709502, \"EndTime\": 1727755836.9949148, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1285.0499153137207, \"count\": 1, \"min\": 1285.0499153137207, \"max\": 1285.0499153137207}}}\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.77826622701286 records/second\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=134, train loss <loss>=8.602863398465244\n",
      "[10/01/2024 04:10:36 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:37 INFO 140492683822912] Epoch[135] Batch[0] avg_epoch_loss=8.637468\n",
      "[10/01/2024 04:10:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=8.637468338012695\n",
      "[10/01/2024 04:10:37 INFO 140492683822912] Epoch[135] Batch[5] avg_epoch_loss=8.532564\n",
      "[10/01/2024 04:10:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=8.532564163208008\n",
      "[10/01/2024 04:10:37 INFO 140492683822912] Epoch[135] Batch [5]#011Speed: 876.86 samples/sec#011loss=8.532564\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] Epoch[135] Batch[10] avg_epoch_loss=8.630929\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=8.748967552185059\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] Epoch[135] Batch [10]#011Speed: 871.93 samples/sec#011loss=8.748968\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] processed a total of 644 examples\n",
      "#metrics {\"StartTime\": 1727755836.9949822, \"EndTime\": 1727755838.302531, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1307.2686195373535, \"count\": 1, \"min\": 1307.2686195373535, \"max\": 1307.2686195373535}}}\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=492.59686843308407 records/second\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=135, train loss <loss>=8.630929340015758\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] Epoch[136] Batch[0] avg_epoch_loss=8.512921\n",
      "[10/01/2024 04:10:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=8.512921333312988\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] Epoch[136] Batch[5] avg_epoch_loss=8.617465\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=8.617465019226074\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] Epoch[136] Batch [5]#011Speed: 878.24 samples/sec#011loss=8.617465\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] Epoch[136] Batch[10] avg_epoch_loss=8.549231\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=8.467349624633789\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] Epoch[136] Batch [10]#011Speed: 868.92 samples/sec#011loss=8.467350\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] processed a total of 642 examples\n",
      "#metrics {\"StartTime\": 1727755838.302591, \"EndTime\": 1727755839.6154656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1312.5686645507812, \"count\": 1, \"min\": 1312.5686645507812, \"max\": 1312.5686645507812}}}\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=489.0694748313158 records/second\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=136, train loss <loss>=8.549230748956854\n",
      "[10/01/2024 04:10:39 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] Epoch[137] Batch[0] avg_epoch_loss=8.541092\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=8.541091918945312\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] Epoch[137] Batch[5] avg_epoch_loss=8.602907\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=8.602907498677572\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] Epoch[137] Batch [5]#011Speed: 925.95 samples/sec#011loss=8.602907\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] Epoch[137] Batch[10] avg_epoch_loss=8.538337\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=8.460852813720702\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] Epoch[137] Batch [10]#011Speed: 919.17 samples/sec#011loss=8.460853\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] processed a total of 642 examples\n",
      "#metrics {\"StartTime\": 1727755839.6155274, \"EndTime\": 1727755840.892517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1276.5233516693115, \"count\": 1, \"min\": 1276.5233516693115, \"max\": 1276.5233516693115}}}\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.8897287161922 records/second\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=137, train loss <loss>=8.538337187333541\n",
      "[10/01/2024 04:10:40 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:41 INFO 140492683822912] Epoch[138] Batch[0] avg_epoch_loss=8.290764\n",
      "[10/01/2024 04:10:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=8.290763854980469\n",
      "[10/01/2024 04:10:41 INFO 140492683822912] Epoch[138] Batch[5] avg_epoch_loss=8.562400\n",
      "[10/01/2024 04:10:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=8.562399864196777\n",
      "[10/01/2024 04:10:41 INFO 140492683822912] Epoch[138] Batch [5]#011Speed: 865.82 samples/sec#011loss=8.562400\n",
      "[10/01/2024 04:10:42 INFO 140492683822912] processed a total of 611 examples\n",
      "#metrics {\"StartTime\": 1727755840.8925807, \"EndTime\": 1727755842.1282907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1235.346794128418, \"count\": 1, \"min\": 1235.346794128418, \"max\": 1235.346794128418}}}\n",
      "[10/01/2024 04:10:42 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=494.5589180962938 records/second\n",
      "[10/01/2024 04:10:42 INFO 140492683822912] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[10/01/2024 04:10:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=138, train loss <loss>=8.627575588226318\n",
      "[10/01/2024 04:10:42 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:42 INFO 140492683822912] Epoch[139] Batch[0] avg_epoch_loss=8.566444\n",
      "[10/01/2024 04:10:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=8.566444396972656\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] Epoch[139] Batch[5] avg_epoch_loss=8.469875\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=8.469874540964762\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] Epoch[139] Batch [5]#011Speed: 947.76 samples/sec#011loss=8.469875\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] processed a total of 638 examples\n",
      "#metrics {\"StartTime\": 1727755842.1283586, \"EndTime\": 1727755843.338585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1209.8619937896729, \"count\": 1, \"min\": 1209.8619937896729, \"max\": 1209.8619937896729}}}\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=527.2821651631906 records/second\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=139, train loss <loss>=8.492333793640137\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] Epoch[140] Batch[0] avg_epoch_loss=8.571795\n",
      "[10/01/2024 04:10:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=8.571795463562012\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] Epoch[140] Batch[5] avg_epoch_loss=8.509964\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=8.509964148203531\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] Epoch[140] Batch [5]#011Speed: 919.17 samples/sec#011loss=8.509964\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] processed a total of 612 examples\n",
      "#metrics {\"StartTime\": 1727755843.338652, \"EndTime\": 1727755844.536707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1197.5524425506592, \"count\": 1, \"min\": 1197.5524425506592, \"max\": 1197.5524425506592}}}\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=510.9958458050753 records/second\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=140, train loss <loss>=8.546761512756348\n",
      "[10/01/2024 04:10:44 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] Epoch[141] Batch[0] avg_epoch_loss=8.634379\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=8.634379386901855\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] Epoch[141] Batch[5] avg_epoch_loss=8.534591\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=8.53459088007609\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] Epoch[141] Batch [5]#011Speed: 927.20 samples/sec#011loss=8.534591\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] Epoch[141] Batch[10] avg_epoch_loss=8.642018\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=8.770930290222168\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] Epoch[141] Batch [10]#011Speed: 875.81 samples/sec#011loss=8.770930\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] processed a total of 659 examples\n",
      "#metrics {\"StartTime\": 1727755844.5367785, \"EndTime\": 1727755845.819505, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1282.275915145874, \"count\": 1, \"min\": 1282.275915145874, \"max\": 1282.275915145874}}}\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.894120993636 records/second\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=141, train loss <loss>=8.642017884687943\n",
      "[10/01/2024 04:10:45 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:46 INFO 140492683822912] Epoch[142] Batch[0] avg_epoch_loss=8.694940\n",
      "[10/01/2024 04:10:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=8.694939613342285\n",
      "[10/01/2024 04:10:46 INFO 140492683822912] Epoch[142] Batch[5] avg_epoch_loss=8.586444\n",
      "[10/01/2024 04:10:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=8.586443901062012\n",
      "[10/01/2024 04:10:46 INFO 140492683822912] Epoch[142] Batch [5]#011Speed: 932.34 samples/sec#011loss=8.586444\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] processed a total of 636 examples\n",
      "#metrics {\"StartTime\": 1727755845.8195639, \"EndTime\": 1727755847.0191052, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1199.2676258087158, \"count\": 1, \"min\": 1199.2676258087158, \"max\": 1199.2676258087158}}}\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=530.2819157342358 records/second\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=142, train loss <loss>=8.572057247161865\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] Epoch[143] Batch[0] avg_epoch_loss=8.511216\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=8.511216163635254\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] Epoch[143] Batch[5] avg_epoch_loss=8.669117\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=8.669116655985514\n",
      "[10/01/2024 04:10:47 INFO 140492683822912] Epoch[143] Batch [5]#011Speed: 934.17 samples/sec#011loss=8.669117\n",
      "[10/01/2024 04:10:48 INFO 140492683822912] processed a total of 611 examples\n",
      "#metrics {\"StartTime\": 1727755847.0191696, \"EndTime\": 1727755848.2355373, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1216.0353660583496, \"count\": 1, \"min\": 1216.0353660583496, \"max\": 1216.0353660583496}}}\n",
      "[10/01/2024 04:10:48 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.4069835738276 records/second\n",
      "[10/01/2024 04:10:48 INFO 140492683822912] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[10/01/2024 04:10:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=143, train loss <loss>=8.640309906005859\n",
      "[10/01/2024 04:10:48 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:48 INFO 140492683822912] Epoch[144] Batch[0] avg_epoch_loss=8.644766\n",
      "[10/01/2024 04:10:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=8.644765853881836\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] Epoch[144] Batch[5] avg_epoch_loss=8.605793\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=8.605792681376139\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] Epoch[144] Batch [5]#011Speed: 878.82 samples/sec#011loss=8.605793\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] Epoch[144] Batch[10] avg_epoch_loss=8.650815\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=8.70484218597412\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] Epoch[144] Batch [10]#011Speed: 861.17 samples/sec#011loss=8.704842\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] processed a total of 657 examples\n",
      "#metrics {\"StartTime\": 1727755848.235615, \"EndTime\": 1727755849.5431607, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1307.1386814117432, \"count\": 1, \"min\": 1307.1386814117432, \"max\": 1307.1386814117432}}}\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.5846799874229 records/second\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=144, train loss <loss>=8.65081518346613\n",
      "[10/01/2024 04:10:49 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] Epoch[145] Batch[0] avg_epoch_loss=8.354258\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=8.354257583618164\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] Epoch[145] Batch[5] avg_epoch_loss=8.438323\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=8.438323338826498\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] Epoch[145] Batch [5]#011Speed: 904.16 samples/sec#011loss=8.438323\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] processed a total of 600 examples\n",
      "#metrics {\"StartTime\": 1727755849.5432284, \"EndTime\": 1727755850.748043, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1204.3895721435547, \"count\": 1, \"min\": 1204.3895721435547, \"max\": 1204.3895721435547}}}\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=498.1356697800199 records/second\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=145, train loss <loss>=8.513029384613038\n",
      "[10/01/2024 04:10:50 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] Epoch[146] Batch[0] avg_epoch_loss=8.754531\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=8.754530906677246\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] Epoch[146] Batch[5] avg_epoch_loss=8.633340\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=8.633339564005533\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] Epoch[146] Batch [5]#011Speed: 938.80 samples/sec#011loss=8.633340\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755850.7481134, \"EndTime\": 1727755851.9431815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1194.7569847106934, \"count\": 1, \"min\": 1194.7569847106934, \"max\": 1194.7569847106934}}}\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=528.9336400621519 records/second\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=146, train loss <loss>=8.61253719329834\n",
      "[10/01/2024 04:10:51 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:52 INFO 140492683822912] Epoch[147] Batch[0] avg_epoch_loss=8.614522\n",
      "[10/01/2024 04:10:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=8.614521980285645\n",
      "[10/01/2024 04:10:52 INFO 140492683822912] Epoch[147] Batch[5] avg_epoch_loss=8.449569\n",
      "[10/01/2024 04:10:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=8.44956906636556\n",
      "[10/01/2024 04:10:52 INFO 140492683822912] Epoch[147] Batch [5]#011Speed: 951.02 samples/sec#011loss=8.449569\n",
      "[10/01/2024 04:10:53 INFO 140492683822912] processed a total of 640 examples\n",
      "#metrics {\"StartTime\": 1727755851.9432514, \"EndTime\": 1727755853.1486888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1205.1002979278564, \"count\": 1, \"min\": 1205.1002979278564, \"max\": 1205.1002979278564}}}\n",
      "[10/01/2024 04:10:53 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=531.0321077686621 records/second\n",
      "[10/01/2024 04:10:53 INFO 140492683822912] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[10/01/2024 04:10:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=147, train loss <loss>=8.459592723846436\n",
      "[10/01/2024 04:10:53 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:53 INFO 140492683822912] Epoch[148] Batch[0] avg_epoch_loss=8.895749\n",
      "[10/01/2024 04:10:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=8.89574909210205\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] Epoch[148] Batch[5] avg_epoch_loss=8.559393\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=8.559393405914307\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] Epoch[148] Batch [5]#011Speed: 957.83 samples/sec#011loss=8.559393\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] processed a total of 613 examples\n",
      "#metrics {\"StartTime\": 1727755853.1487577, \"EndTime\": 1727755854.3656752, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1216.5515422821045, \"count\": 1, \"min\": 1216.5515422821045, \"max\": 1216.5515422821045}}}\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.8369855239684 records/second\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=148, train loss <loss>=8.548860836029053\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] Epoch[149] Batch[0] avg_epoch_loss=8.421009\n",
      "[10/01/2024 04:10:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=8.421009063720703\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] Epoch[149] Batch[5] avg_epoch_loss=8.487374\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=8.48737366994222\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] Epoch[149] Batch [5]#011Speed: 914.12 samples/sec#011loss=8.487374\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] Epoch[149] Batch[10] avg_epoch_loss=8.587312\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=8.707238388061523\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] Epoch[149] Batch [10]#011Speed: 874.38 samples/sec#011loss=8.707238\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] processed a total of 641 examples\n",
      "#metrics {\"StartTime\": 1727755854.3657525, \"EndTime\": 1727755855.6655285, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1299.314022064209, \"count\": 1, \"min\": 1299.314022064209, \"max\": 1299.314022064209}}}\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=493.29578787914375 records/second\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=149, train loss <loss>=8.587312178178268\n",
      "[10/01/2024 04:10:55 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] Epoch[150] Batch[0] avg_epoch_loss=8.539844\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=8.539843559265137\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] Epoch[150] Batch[5] avg_epoch_loss=8.668339\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=8.668338616689047\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] Epoch[150] Batch [5]#011Speed: 928.96 samples/sec#011loss=8.668339\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] processed a total of 639 examples\n",
      "#metrics {\"StartTime\": 1727755855.6656039, \"EndTime\": 1727755856.8849807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1219.006061553955, \"count\": 1, \"min\": 1219.006061553955, \"max\": 1219.006061553955}}}\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=524.1539880159747 records/second\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=150, train loss <loss>=8.623762321472167\n",
      "[10/01/2024 04:10:56 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:57 INFO 140492683822912] Epoch[151] Batch[0] avg_epoch_loss=8.652195\n",
      "[10/01/2024 04:10:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=8.65219497680664\n",
      "[10/01/2024 04:10:57 INFO 140492683822912] Epoch[151] Batch[5] avg_epoch_loss=8.595594\n",
      "[10/01/2024 04:10:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=8.595593611399332\n",
      "[10/01/2024 04:10:57 INFO 140492683822912] Epoch[151] Batch [5]#011Speed: 950.80 samples/sec#011loss=8.595594\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] Epoch[151] Batch[10] avg_epoch_loss=8.431402\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=8.23437213897705\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] Epoch[151] Batch [10]#011Speed: 866.90 samples/sec#011loss=8.234372\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] processed a total of 671 examples\n",
      "#metrics {\"StartTime\": 1727755856.8850498, \"EndTime\": 1727755858.1977952, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1312.3486042022705, \"count\": 1, \"min\": 1312.3486042022705, \"max\": 1312.3486042022705}}}\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=511.2578767917736 records/second\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=151, train loss <loss>=8.431402033025568\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_4f672a3b-4559-4f9b-9b59-71d2db285f76-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755858.197867, \"EndTime\": 1727755858.2087047, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.550498962402344, \"count\": 1, \"min\": 10.550498962402344, \"max\": 10.550498962402344}}}\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] Epoch[152] Batch[0] avg_epoch_loss=8.477128\n",
      "[10/01/2024 04:10:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=8.477128028869629\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] Epoch[152] Batch[5] avg_epoch_loss=8.544395\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=8.544394652048746\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] Epoch[152] Batch [5]#011Speed: 950.53 samples/sec#011loss=8.544395\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] processed a total of 623 examples\n",
      "#metrics {\"StartTime\": 1727755858.208763, \"EndTime\": 1727755859.4183517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1209.5379829406738, \"count\": 1, \"min\": 1209.5379829406738, \"max\": 1209.5379829406738}}}\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.0314870615913 records/second\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=152, train loss <loss>=8.625713348388672\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] Epoch[153] Batch[0] avg_epoch_loss=8.737046\n",
      "[10/01/2024 04:10:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=8.737046241760254\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] Epoch[153] Batch[5] avg_epoch_loss=8.588379\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=8.58837858835856\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] Epoch[153] Batch [5]#011Speed: 895.48 samples/sec#011loss=8.588379\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] Epoch[153] Batch[10] avg_epoch_loss=8.605246\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=8.62548770904541\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] Epoch[153] Batch [10]#011Speed: 881.37 samples/sec#011loss=8.625488\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] processed a total of 659 examples\n",
      "#metrics {\"StartTime\": 1727755859.4184194, \"EndTime\": 1727755860.716601, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1297.8687286376953, \"count\": 1, \"min\": 1297.8687286376953, \"max\": 1297.8687286376953}}}\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=507.6996459570685 records/second\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=153, train loss <loss>=8.605246370488947\n",
      "[10/01/2024 04:11:00 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:01 INFO 140492683822912] Epoch[154] Batch[0] avg_epoch_loss=8.484086\n",
      "[10/01/2024 04:11:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=8.484086036682129\n",
      "[10/01/2024 04:11:01 INFO 140492683822912] Epoch[154] Batch[5] avg_epoch_loss=8.498405\n",
      "[10/01/2024 04:11:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=8.498404820760092\n",
      "[10/01/2024 04:11:01 INFO 140492683822912] Epoch[154] Batch [5]#011Speed: 717.53 samples/sec#011loss=8.498405\n",
      "[10/01/2024 04:11:02 INFO 140492683822912] processed a total of 624 examples\n",
      "#metrics {\"StartTime\": 1727755860.7167091, \"EndTime\": 1727755862.2357829, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1518.6083316802979, \"count\": 1, \"min\": 1518.6083316802979, \"max\": 1518.6083316802979}}}\n",
      "[10/01/2024 04:11:02 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=410.87272445838414 records/second\n",
      "[10/01/2024 04:11:02 INFO 140492683822912] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[10/01/2024 04:11:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=154, train loss <loss>=8.521707153320312\n",
      "[10/01/2024 04:11:02 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:02 INFO 140492683822912] Epoch[155] Batch[0] avg_epoch_loss=8.479381\n",
      "[10/01/2024 04:11:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=8.47938060760498\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] Epoch[155] Batch[5] avg_epoch_loss=8.660965\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=8.660965124766031\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] Epoch[155] Batch [5]#011Speed: 634.01 samples/sec#011loss=8.660965\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] Epoch[155] Batch[10] avg_epoch_loss=8.695766\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=8.737526130676269\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] Epoch[155] Batch [10]#011Speed: 888.11 samples/sec#011loss=8.737526\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] processed a total of 649 examples\n",
      "#metrics {\"StartTime\": 1727755862.2358587, \"EndTime\": 1727755863.791765, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1555.2599430084229, \"count\": 1, \"min\": 1555.2599430084229, \"max\": 1555.2599430084229}}}\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=417.2626913863203 records/second\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=155, train loss <loss>=8.695765581997959\n",
      "[10/01/2024 04:11:03 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] Epoch[156] Batch[0] avg_epoch_loss=8.545099\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=8.545099258422852\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] Epoch[156] Batch[5] avg_epoch_loss=8.504855\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=8.504854996999105\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] Epoch[156] Batch [5]#011Speed: 940.38 samples/sec#011loss=8.504855\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] processed a total of 636 examples\n",
      "#metrics {\"StartTime\": 1727755863.7918458, \"EndTime\": 1727755864.9979596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1205.6822776794434, \"count\": 1, \"min\": 1205.6822776794434, \"max\": 1205.6822776794434}}}\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=527.4541763866354 records/second\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=156, train loss <loss>=8.539365291595459\n",
      "[10/01/2024 04:11:04 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:05 INFO 140492683822912] Epoch[157] Batch[0] avg_epoch_loss=8.459178\n",
      "[10/01/2024 04:11:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=8.45917797088623\n",
      "[10/01/2024 04:11:05 INFO 140492683822912] Epoch[157] Batch[5] avg_epoch_loss=8.561247\n",
      "[10/01/2024 04:11:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=8.561246554056803\n",
      "[10/01/2024 04:11:05 INFO 140492683822912] Epoch[157] Batch [5]#011Speed: 941.38 samples/sec#011loss=8.561247\n",
      "[10/01/2024 04:11:06 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755864.9980352, \"EndTime\": 1727755866.205654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1207.13210105896, \"count\": 1, \"min\": 1207.13210105896, \"max\": 1207.13210105896}}}\n",
      "[10/01/2024 04:11:06 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=523.5119473802187 records/second\n",
      "[10/01/2024 04:11:06 INFO 140492683822912] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[10/01/2024 04:11:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=157, train loss <loss>=8.562017917633057\n",
      "[10/01/2024 04:11:06 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:06 INFO 140492683822912] Epoch[158] Batch[0] avg_epoch_loss=8.602153\n",
      "[10/01/2024 04:11:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=8.602152824401855\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] Epoch[158] Batch[5] avg_epoch_loss=8.536780\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=8.536779562632242\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] Epoch[158] Batch [5]#011Speed: 919.73 samples/sec#011loss=8.536780\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] Epoch[158] Batch[10] avg_epoch_loss=8.579590\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=8.63096218109131\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] Epoch[158] Batch [10]#011Speed: 846.41 samples/sec#011loss=8.630962\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] processed a total of 672 examples\n",
      "#metrics {\"StartTime\": 1727755866.205722, \"EndTime\": 1727755867.5013454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1295.3054904937744, \"count\": 1, \"min\": 1295.3054904937744, \"max\": 1295.3054904937744}}}\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.7582455322781 records/second\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=158, train loss <loss>=8.57958984375\n",
      "[10/01/2024 04:11:07 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] Epoch[159] Batch[0] avg_epoch_loss=8.414562\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=8.414562225341797\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] Epoch[159] Batch[5] avg_epoch_loss=8.500007\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=8.500006675720215\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] Epoch[159] Batch [5]#011Speed: 844.21 samples/sec#011loss=8.500007\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] Epoch[159] Batch[10] avg_epoch_loss=8.554582\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=8.620073318481445\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] Epoch[159] Batch [10]#011Speed: 799.22 samples/sec#011loss=8.620073\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] processed a total of 672 examples\n",
      "#metrics {\"StartTime\": 1727755867.5014105, \"EndTime\": 1727755868.8442137, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1342.411756515503, \"count\": 1, \"min\": 1342.411756515503, \"max\": 1342.411756515503}}}\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.54391363268354 records/second\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=159, train loss <loss>=8.554582422429865\n",
      "[10/01/2024 04:11:08 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:09 INFO 140492683822912] Epoch[160] Batch[0] avg_epoch_loss=8.551096\n",
      "[10/01/2024 04:11:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=8.551095962524414\n",
      "[10/01/2024 04:11:09 INFO 140492683822912] Epoch[160] Batch[5] avg_epoch_loss=8.489502\n",
      "[10/01/2024 04:11:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=8.48950227101644\n",
      "[10/01/2024 04:11:09 INFO 140492683822912] Epoch[160] Batch [5]#011Speed: 922.75 samples/sec#011loss=8.489502\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] Epoch[160] Batch[10] avg_epoch_loss=8.583735\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=8.696814346313477\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] Epoch[160] Batch [10]#011Speed: 845.07 samples/sec#011loss=8.696814\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] processed a total of 662 examples\n",
      "#metrics {\"StartTime\": 1727755868.844304, \"EndTime\": 1727755870.1466267, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1301.9492626190186, \"count\": 1, \"min\": 1301.9492626190186, \"max\": 1301.9492626190186}}}\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.41835838593977 records/second\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=160, train loss <loss>=8.583735032515092\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] Epoch[161] Batch[0] avg_epoch_loss=8.547592\n",
      "[10/01/2024 04:11:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=8.547592163085938\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] Epoch[161] Batch[5] avg_epoch_loss=8.457476\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=8.457475980122885\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] Epoch[161] Batch [5]#011Speed: 920.31 samples/sec#011loss=8.457476\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] processed a total of 637 examples\n",
      "#metrics {\"StartTime\": 1727755870.1466937, \"EndTime\": 1727755871.3653615, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1218.3966636657715, \"count\": 1, \"min\": 1218.3966636657715, \"max\": 1218.3966636657715}}}\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=522.7718999393243 records/second\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=161, train loss <loss>=8.47304916381836\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] Epoch[162] Batch[0] avg_epoch_loss=8.549851\n",
      "[10/01/2024 04:11:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=8.549851417541504\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] Epoch[162] Batch[5] avg_epoch_loss=8.463894\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=8.463894367218018\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] Epoch[162] Batch [5]#011Speed: 936.24 samples/sec#011loss=8.463894\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] Epoch[162] Batch[10] avg_epoch_loss=8.374995\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=8.268316173553467\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] Epoch[162] Batch [10]#011Speed: 842.41 samples/sec#011loss=8.268316\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] processed a total of 648 examples\n",
      "#metrics {\"StartTime\": 1727755871.365439, \"EndTime\": 1727755872.6703396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1304.4822216033936, \"count\": 1, \"min\": 1304.4822216033936, \"max\": 1304.4822216033936}}}\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=496.70932613038053 records/second\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=162, train loss <loss>=8.374995188279586\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:11:12 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_246f7765-ddb7-4acd-b648-2af3a278b10a-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755872.6704156, \"EndTime\": 1727755872.6812978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.523557662963867, \"count\": 1, \"min\": 10.523557662963867, \"max\": 10.523557662963867}}}\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] Epoch[163] Batch[0] avg_epoch_loss=8.514146\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=8.514145851135254\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] Epoch[163] Batch[5] avg_epoch_loss=8.533320\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=8.533320426940918\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] Epoch[163] Batch [5]#011Speed: 918.45 samples/sec#011loss=8.533320\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] Epoch[163] Batch[10] avg_epoch_loss=8.601025\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=8.682269859313966\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] Epoch[163] Batch [10]#011Speed: 874.88 samples/sec#011loss=8.682270\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] processed a total of 667 examples\n",
      "#metrics {\"StartTime\": 1727755872.6813579, \"EndTime\": 1727755873.9729, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1291.4888858795166, \"count\": 1, \"min\": 1291.4888858795166, \"max\": 1291.4888858795166}}}\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=516.4239548583269 records/second\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=163, train loss <loss>=8.601024714383213\n",
      "[10/01/2024 04:11:13 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:14 INFO 140492683822912] Epoch[164] Batch[0] avg_epoch_loss=8.826094\n",
      "[10/01/2024 04:11:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=8.826093673706055\n",
      "[10/01/2024 04:11:14 INFO 140492683822912] Epoch[164] Batch[5] avg_epoch_loss=8.714717\n",
      "[10/01/2024 04:11:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=8.714717229207357\n",
      "[10/01/2024 04:11:14 INFO 140492683822912] Epoch[164] Batch [5]#011Speed: 926.82 samples/sec#011loss=8.714717\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] Epoch[164] Batch[10] avg_epoch_loss=8.541681\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=8.33403730392456\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] Epoch[164] Batch [10]#011Speed: 891.44 samples/sec#011loss=8.334037\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] processed a total of 641 examples\n",
      "#metrics {\"StartTime\": 1727755873.9729583, \"EndTime\": 1727755875.2576091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1284.3856811523438, \"count\": 1, \"min\": 1284.3856811523438, \"max\": 1284.3856811523438}}}\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=499.03486981060036 records/second\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=164, train loss <loss>=8.54168089953336\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] Epoch[165] Batch[0] avg_epoch_loss=8.838297\n",
      "[10/01/2024 04:11:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=8.838296890258789\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] Epoch[165] Batch[5] avg_epoch_loss=8.677043\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=8.677042802174887\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] Epoch[165] Batch [5]#011Speed: 934.91 samples/sec#011loss=8.677043\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] Epoch[165] Batch[10] avg_epoch_loss=8.638992\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=8.593330574035644\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] Epoch[165] Batch [10]#011Speed: 855.04 samples/sec#011loss=8.593331\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] processed a total of 665 examples\n",
      "#metrics {\"StartTime\": 1727755875.2576737, \"EndTime\": 1727755876.5432074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1285.2470874786377, \"count\": 1, \"min\": 1285.2470874786377, \"max\": 1285.2470874786377}}}\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=517.372998670959 records/second\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=165, train loss <loss>=8.638991789384322\n",
      "[10/01/2024 04:11:16 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] Epoch[166] Batch[0] avg_epoch_loss=8.978740\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=8.978739738464355\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] Epoch[166] Batch[5] avg_epoch_loss=8.656474\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=8.656474113464355\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] Epoch[166] Batch [5]#011Speed: 913.22 samples/sec#011loss=8.656474\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] Epoch[166] Batch[10] avg_epoch_loss=8.727757\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=8.813296508789062\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] Epoch[166] Batch [10]#011Speed: 876.68 samples/sec#011loss=8.813297\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] processed a total of 654 examples\n",
      "#metrics {\"StartTime\": 1727755876.5432727, \"EndTime\": 1727755877.8306997, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1287.0709896087646, \"count\": 1, \"min\": 1287.0709896087646, \"max\": 1287.0709896087646}}}\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.09546747860935 records/second\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=166, train loss <loss>=8.727757020430131\n",
      "[10/01/2024 04:11:17 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:18 INFO 140492683822912] Epoch[167] Batch[0] avg_epoch_loss=8.656569\n",
      "[10/01/2024 04:11:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=8.656569480895996\n",
      "[10/01/2024 04:11:18 INFO 140492683822912] Epoch[167] Batch[5] avg_epoch_loss=8.623393\n",
      "[10/01/2024 04:11:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=8.623393217722574\n",
      "[10/01/2024 04:11:18 INFO 140492683822912] Epoch[167] Batch [5]#011Speed: 930.57 samples/sec#011loss=8.623393\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] Epoch[167] Batch[10] avg_epoch_loss=8.597298\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=8.565983200073243\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] Epoch[167] Batch [10]#011Speed: 842.81 samples/sec#011loss=8.565983\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] processed a total of 671 examples\n",
      "#metrics {\"StartTime\": 1727755877.8307602, \"EndTime\": 1727755879.1283755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1297.3580360412598, \"count\": 1, \"min\": 1297.3580360412598, \"max\": 1297.3580360412598}}}\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=517.157621850154 records/second\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=167, train loss <loss>=8.597297755154697\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] Epoch[168] Batch[0] avg_epoch_loss=8.590119\n",
      "[10/01/2024 04:11:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=8.590119361877441\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] Epoch[168] Batch[5] avg_epoch_loss=8.503806\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=8.503806432088217\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] Epoch[168] Batch [5]#011Speed: 951.26 samples/sec#011loss=8.503806\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] processed a total of 617 examples\n",
      "#metrics {\"StartTime\": 1727755879.1284664, \"EndTime\": 1727755880.3186057, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1189.8682117462158, \"count\": 1, \"min\": 1189.8682117462158, \"max\": 1189.8682117462158}}}\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.5028485858652 records/second\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=168, train loss <loss>=8.568844318389893\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] Epoch[169] Batch[0] avg_epoch_loss=8.619059\n",
      "[10/01/2024 04:11:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=8.619058609008789\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] Epoch[169] Batch[5] avg_epoch_loss=8.562486\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=8.562486012776693\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] Epoch[169] Batch [5]#011Speed: 946.52 samples/sec#011loss=8.562486\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] processed a total of 635 examples\n",
      "#metrics {\"StartTime\": 1727755880.318673, \"EndTime\": 1727755881.5148342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1195.8484649658203, \"count\": 1, \"min\": 1195.8484649658203, \"max\": 1195.8484649658203}}}\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=530.960331823414 records/second\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=169, train loss <loss>=8.582258701324463\n",
      "[10/01/2024 04:11:21 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] Epoch[170] Batch[0] avg_epoch_loss=8.630027\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=8.630026817321777\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] Epoch[170] Batch[5] avg_epoch_loss=8.566068\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=8.566068331400553\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] Epoch[170] Batch [5]#011Speed: 932.56 samples/sec#011loss=8.566068\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] processed a total of 587 examples\n",
      "#metrics {\"StartTime\": 1727755881.5149024, \"EndTime\": 1727755882.716426, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1201.2100219726562, \"count\": 1, \"min\": 1201.2100219726562, \"max\": 1201.2100219726562}}}\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=488.63278996178354 records/second\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=170, train loss <loss>=8.370292663574219\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:11:22 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_1b5cede0-309e-4c56-affd-c7d39e789454-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755882.7164967, \"EndTime\": 1727755882.7273302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.509014129638672, \"count\": 1, \"min\": 10.509014129638672, \"max\": 10.509014129638672}}}\n",
      "[10/01/2024 04:11:23 INFO 140492683822912] Epoch[171] Batch[0] avg_epoch_loss=8.751014\n",
      "[10/01/2024 04:11:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=8.75101375579834\n",
      "[10/01/2024 04:11:23 INFO 140492683822912] Epoch[171] Batch[5] avg_epoch_loss=8.876496\n",
      "[10/01/2024 04:11:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=8.876495838165283\n",
      "[10/01/2024 04:11:23 INFO 140492683822912] Epoch[171] Batch [5]#011Speed: 929.90 samples/sec#011loss=8.876496\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] Epoch[171] Batch[10] avg_epoch_loss=8.940466\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=9.017230033874512\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] Epoch[171] Batch [10]#011Speed: 835.95 samples/sec#011loss=9.017230\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] processed a total of 678 examples\n",
      "#metrics {\"StartTime\": 1727755882.727386, \"EndTime\": 1727755884.0047114, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1277.2493362426758, \"count\": 1, \"min\": 1277.2493362426758, \"max\": 1277.2493362426758}}}\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=530.758478173067 records/second\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=171, train loss <loss>=8.940465927124023\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] Epoch[172] Batch[0] avg_epoch_loss=8.993150\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=8.993149757385254\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] Epoch[172] Batch[5] avg_epoch_loss=8.947807\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=8.94780699412028\n",
      "[10/01/2024 04:11:24 INFO 140492683822912] Epoch[172] Batch [5]#011Speed: 939.25 samples/sec#011loss=8.947807\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] Epoch[172] Batch[10] avg_epoch_loss=9.001138\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=9.065135383605957\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] Epoch[172] Batch [10]#011Speed: 882.39 samples/sec#011loss=9.065135\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] processed a total of 660 examples\n",
      "#metrics {\"StartTime\": 1727755884.0048258, \"EndTime\": 1727755885.3180404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1312.896966934204, \"count\": 1, \"min\": 1312.896966934204, \"max\": 1312.896966934204}}}\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.6612838647225 records/second\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=172, train loss <loss>=9.001138080250133\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] Epoch[173] Batch[0] avg_epoch_loss=8.718374\n",
      "[10/01/2024 04:11:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=8.718374252319336\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] Epoch[173] Batch[5] avg_epoch_loss=8.683248\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=8.683247725168863\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] Epoch[173] Batch [5]#011Speed: 948.14 samples/sec#011loss=8.683248\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] processed a total of 634 examples\n",
      "#metrics {\"StartTime\": 1727755885.3181233, \"EndTime\": 1727755886.5244908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1205.845832824707, \"count\": 1, \"min\": 1205.845832824707, \"max\": 1205.845832824707}}}\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=525.7212953612491 records/second\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=173, train loss <loss>=8.668789672851563\n",
      "[10/01/2024 04:11:26 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] Epoch[174] Batch[0] avg_epoch_loss=8.472571\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=8.47257137298584\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] Epoch[174] Batch[5] avg_epoch_loss=8.607585\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=8.607584794362387\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] Epoch[174] Batch [5]#011Speed: 937.96 samples/sec#011loss=8.607585\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] Epoch[174] Batch[10] avg_epoch_loss=8.658358\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=8.719286346435547\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] Epoch[174] Batch [10]#011Speed: 832.47 samples/sec#011loss=8.719286\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] processed a total of 657 examples\n",
      "#metrics {\"StartTime\": 1727755886.5245755, \"EndTime\": 1727755887.8257875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1300.7280826568604, \"count\": 1, \"min\": 1300.7280826568604, \"max\": 1300.7280826568604}}}\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.0640477297154 records/second\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=174, train loss <loss>=8.658358227122914\n",
      "[10/01/2024 04:11:27 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:28 INFO 140492683822912] Epoch[175] Batch[0] avg_epoch_loss=8.774661\n",
      "[10/01/2024 04:11:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=8.77466106414795\n",
      "[10/01/2024 04:11:28 INFO 140492683822912] Epoch[175] Batch[5] avg_epoch_loss=8.594624\n",
      "[10/01/2024 04:11:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=8.594623883565268\n",
      "[10/01/2024 04:11:28 INFO 140492683822912] Epoch[175] Batch [5]#011Speed: 931.60 samples/sec#011loss=8.594624\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] Epoch[175] Batch[10] avg_epoch_loss=8.595682\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=8.596951103210449\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] Epoch[175] Batch [10]#011Speed: 835.60 samples/sec#011loss=8.596951\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] processed a total of 689 examples\n",
      "#metrics {\"StartTime\": 1727755887.8258572, \"EndTime\": 1727755889.1135237, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1287.306785583496, \"count\": 1, \"min\": 1287.306785583496, \"max\": 1287.306785583496}}}\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=535.1870968793359 records/second\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=175, train loss <loss>=8.595681710676713\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] Epoch[176] Batch[0] avg_epoch_loss=8.439709\n",
      "[10/01/2024 04:11:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=8.439708709716797\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] Epoch[176] Batch[5] avg_epoch_loss=8.545132\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=8.54513168334961\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] Epoch[176] Batch [5]#011Speed: 952.41 samples/sec#011loss=8.545132\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] Epoch[176] Batch[10] avg_epoch_loss=8.565038\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=8.588925552368163\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] Epoch[176] Batch [10]#011Speed: 860.84 samples/sec#011loss=8.588926\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] processed a total of 669 examples\n",
      "#metrics {\"StartTime\": 1727755889.1135838, \"EndTime\": 1727755890.4163845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1302.3622035980225, \"count\": 1, \"min\": 1302.3622035980225, \"max\": 1302.3622035980225}}}\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.6454054006559 records/second\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=176, train loss <loss>=8.565037987448953\n",
      "[10/01/2024 04:11:30 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] Epoch[177] Batch[0] avg_epoch_loss=8.529881\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=8.529881477355957\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] Epoch[177] Batch[5] avg_epoch_loss=8.592202\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=8.592201709747314\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] Epoch[177] Batch [5]#011Speed: 948.08 samples/sec#011loss=8.592202\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] Epoch[177] Batch[10] avg_epoch_loss=8.527585\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=8.450045394897462\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] Epoch[177] Batch [10]#011Speed: 806.55 samples/sec#011loss=8.450045\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] processed a total of 697 examples\n",
      "#metrics {\"StartTime\": 1727755890.416446, \"EndTime\": 1727755891.749829, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1333.11128616333, \"count\": 1, \"min\": 1333.11128616333, \"max\": 1333.11128616333}}}\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=522.7968663267467 records/second\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=177, train loss <loss>=8.52758520299738\n",
      "[10/01/2024 04:11:31 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] Epoch[178] Batch[0] avg_epoch_loss=8.473472\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=8.473471641540527\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] Epoch[178] Batch[5] avg_epoch_loss=8.525548\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=8.525547981262207\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] Epoch[178] Batch [5]#011Speed: 921.56 samples/sec#011loss=8.525548\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] processed a total of 622 examples\n",
      "#metrics {\"StartTime\": 1727755891.7498987, \"EndTime\": 1727755892.961129, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1210.85524559021, \"count\": 1, \"min\": 1210.85524559021, \"max\": 1210.85524559021}}}\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.6436236284285 records/second\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=178, train loss <loss>=8.534828472137452\n",
      "[10/01/2024 04:11:32 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:33 INFO 140492683822912] Epoch[179] Batch[0] avg_epoch_loss=8.562860\n",
      "[10/01/2024 04:11:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=8.562859535217285\n",
      "[10/01/2024 04:11:33 INFO 140492683822912] Epoch[179] Batch[5] avg_epoch_loss=8.532365\n",
      "[10/01/2024 04:11:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=8.532365163167318\n",
      "[10/01/2024 04:11:33 INFO 140492683822912] Epoch[179] Batch [5]#011Speed: 919.69 samples/sec#011loss=8.532365\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] Epoch[179] Batch[10] avg_epoch_loss=8.528434\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=8.523715591430664\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] Epoch[179] Batch [10]#011Speed: 843.41 samples/sec#011loss=8.523716\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] processed a total of 669 examples\n",
      "#metrics {\"StartTime\": 1727755892.961194, \"EndTime\": 1727755894.2488148, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1287.1992588043213, \"count\": 1, \"min\": 1287.1992588043213, \"max\": 1287.1992588043213}}}\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=519.68684878 records/second\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=179, train loss <loss>=8.528433539650656\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] Epoch[180] Batch[0] avg_epoch_loss=8.333041\n",
      "[10/01/2024 04:11:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=8.333041191101074\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] Epoch[180] Batch[5] avg_epoch_loss=8.480337\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=8.480336825052897\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] Epoch[180] Batch [5]#011Speed: 940.35 samples/sec#011loss=8.480337\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] Epoch[180] Batch[10] avg_epoch_loss=8.555916\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=8.646611785888672\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] Epoch[180] Batch [10]#011Speed: 864.00 samples/sec#011loss=8.646612\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] processed a total of 649 examples\n",
      "#metrics {\"StartTime\": 1727755894.2488933, \"EndTime\": 1727755895.533585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1284.325361251831, \"count\": 1, \"min\": 1284.325361251831, \"max\": 1284.325361251831}}}\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.2838951046679 records/second\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=180, train loss <loss>=8.555916352705522\n",
      "[10/01/2024 04:11:35 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] Epoch[181] Batch[0] avg_epoch_loss=8.577353\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=8.577353477478027\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] Epoch[181] Batch[5] avg_epoch_loss=8.548302\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=8.548302173614502\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] Epoch[181] Batch [5]#011Speed: 918.72 samples/sec#011loss=8.548302\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] Epoch[181] Batch[10] avg_epoch_loss=8.477191\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=8.391857624053955\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] Epoch[181] Batch [10]#011Speed: 841.89 samples/sec#011loss=8.391858\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] processed a total of 641 examples\n",
      "#metrics {\"StartTime\": 1727755895.5336514, \"EndTime\": 1727755896.8434572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1309.3767166137695, \"count\": 1, \"min\": 1309.3767166137695, \"max\": 1309.3767166137695}}}\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=489.4997278077766 records/second\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=181, train loss <loss>=8.477191014723344\n",
      "[10/01/2024 04:11:36 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:37 INFO 140492683822912] Epoch[182] Batch[0] avg_epoch_loss=8.508188\n",
      "[10/01/2024 04:11:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=8.508188247680664\n",
      "[10/01/2024 04:11:37 INFO 140492683822912] Epoch[182] Batch[5] avg_epoch_loss=8.440295\n",
      "[10/01/2024 04:11:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=8.440294901529947\n",
      "[10/01/2024 04:11:37 INFO 140492683822912] Epoch[182] Batch [5]#011Speed: 926.03 samples/sec#011loss=8.440295\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] processed a total of 633 examples\n",
      "#metrics {\"StartTime\": 1727755896.8435228, \"EndTime\": 1727755898.04363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1199.5480060577393, \"count\": 1, \"min\": 1199.5480060577393, \"max\": 1199.5480060577393}}}\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=527.6549260715144 records/second\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=182, train loss <loss>=8.487480354309081\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] Epoch[183] Batch[0] avg_epoch_loss=8.671309\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=8.671308517456055\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] Epoch[183] Batch[5] avg_epoch_loss=8.569731\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=8.569730917612711\n",
      "[10/01/2024 04:11:38 INFO 140492683822912] Epoch[183] Batch [5]#011Speed: 940.05 samples/sec#011loss=8.569731\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] Epoch[183] Batch[10] avg_epoch_loss=8.563461\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=8.555936431884765\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] Epoch[183] Batch [10]#011Speed: 853.06 samples/sec#011loss=8.555936\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] processed a total of 676 examples\n",
      "#metrics {\"StartTime\": 1727755898.043697, \"EndTime\": 1727755899.3362076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1292.2091484069824, \"count\": 1, \"min\": 1292.2091484069824, \"max\": 1292.2091484069824}}}\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=523.0928566315571 records/second\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=183, train loss <loss>=8.563460696827281\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] Epoch[184] Batch[0] avg_epoch_loss=8.566122\n",
      "[10/01/2024 04:11:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=8.566122055053711\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] Epoch[184] Batch[5] avg_epoch_loss=8.519920\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=8.519919713338217\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] Epoch[184] Batch [5]#011Speed: 892.64 samples/sec#011loss=8.519920\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] Epoch[184] Batch[10] avg_epoch_loss=8.403239\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=8.263221168518067\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] Epoch[184] Batch [10]#011Speed: 847.47 samples/sec#011loss=8.263221\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] processed a total of 663 examples\n",
      "#metrics {\"StartTime\": 1727755899.3362787, \"EndTime\": 1727755900.6391277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1302.4930953979492, \"count\": 1, \"min\": 1302.4930953979492, \"max\": 1302.4930953979492}}}\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.9820722979775 records/second\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=184, train loss <loss>=8.403238556601785\n",
      "[10/01/2024 04:11:40 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] Epoch[185] Batch[0] avg_epoch_loss=8.692357\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=8.692357063293457\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] Epoch[185] Batch[5] avg_epoch_loss=8.595923\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=8.595923264821371\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] Epoch[185] Batch [5]#011Speed: 949.02 samples/sec#011loss=8.595923\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] Epoch[185] Batch[10] avg_epoch_loss=8.442014\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=8.257323741912842\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] Epoch[185] Batch [10]#011Speed: 859.44 samples/sec#011loss=8.257324\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] processed a total of 655 examples\n",
      "#metrics {\"StartTime\": 1727755900.6392043, \"EndTime\": 1727755901.9171789, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1277.5917053222656, \"count\": 1, \"min\": 1277.5917053222656, \"max\": 1277.5917053222656}}}\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=512.6471910917476 records/second\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=185, train loss <loss>=8.442014390772039\n",
      "[10/01/2024 04:11:41 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:42 INFO 140492683822912] Epoch[186] Batch[0] avg_epoch_loss=8.697136\n",
      "[10/01/2024 04:11:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=8.697135925292969\n",
      "[10/01/2024 04:11:42 INFO 140492683822912] Epoch[186] Batch[5] avg_epoch_loss=8.983666\n",
      "[10/01/2024 04:11:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=8.983665784200033\n",
      "[10/01/2024 04:11:42 INFO 140492683822912] Epoch[186] Batch [5]#011Speed: 938.70 samples/sec#011loss=8.983666\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] Epoch[186] Batch[10] avg_epoch_loss=8.896246\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=8.791342163085938\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] Epoch[186] Batch [10]#011Speed: 897.86 samples/sec#011loss=8.791342\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] processed a total of 658 examples\n",
      "#metrics {\"StartTime\": 1727755901.9172404, \"EndTime\": 1727755903.1854374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1267.9340839385986, \"count\": 1, \"min\": 1267.9340839385986, \"max\": 1267.9340839385986}}}\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.916270251041 records/second\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=186, train loss <loss>=8.896245956420898\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] Epoch[187] Batch[0] avg_epoch_loss=9.071753\n",
      "[10/01/2024 04:11:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=9.071752548217773\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] Epoch[187] Batch[5] avg_epoch_loss=9.067431\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=9.067431290944418\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] Epoch[187] Batch [5]#011Speed: 950.29 samples/sec#011loss=9.067431\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] Epoch[187] Batch[10] avg_epoch_loss=9.068519\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=9.069824028015137\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] Epoch[187] Batch [10]#011Speed: 906.03 samples/sec#011loss=9.069824\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] processed a total of 649 examples\n",
      "#metrics {\"StartTime\": 1727755903.1855006, \"EndTime\": 1727755904.4626098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1276.8349647521973, \"count\": 1, \"min\": 1276.8349647521973, \"max\": 1276.8349647521973}}}\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.2493650858259 records/second\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=187, train loss <loss>=9.068518898703836\n",
      "[10/01/2024 04:11:44 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] Epoch[188] Batch[0] avg_epoch_loss=8.772874\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=8.772873878479004\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] Epoch[188] Batch[5] avg_epoch_loss=8.656004\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=8.656003952026367\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] Epoch[188] Batch [5]#011Speed: 944.92 samples/sec#011loss=8.656004\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] Epoch[188] Batch[10] avg_epoch_loss=8.687914\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=8.726205444335937\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] Epoch[188] Batch [10]#011Speed: 854.15 samples/sec#011loss=8.726205\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] processed a total of 662 examples\n",
      "#metrics {\"StartTime\": 1727755904.4626713, \"EndTime\": 1727755905.7403252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1277.2977352142334, \"count\": 1, \"min\": 1277.2977352142334, \"max\": 1277.2977352142334}}}\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.2299157693951 records/second\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=188, train loss <loss>=8.68791372125799\n",
      "[10/01/2024 04:11:45 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:46 INFO 140492683822912] Epoch[189] Batch[0] avg_epoch_loss=8.587820\n",
      "[10/01/2024 04:11:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=8.587820053100586\n",
      "[10/01/2024 04:11:46 INFO 140492683822912] Epoch[189] Batch[5] avg_epoch_loss=8.646897\n",
      "[10/01/2024 04:11:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=8.646897474924723\n",
      "[10/01/2024 04:11:46 INFO 140492683822912] Epoch[189] Batch [5]#011Speed: 933.11 samples/sec#011loss=8.646897\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] Epoch[189] Batch[10] avg_epoch_loss=8.618206\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=8.583776092529297\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] Epoch[189] Batch [10]#011Speed: 803.71 samples/sec#011loss=8.583776\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] processed a total of 660 examples\n",
      "#metrics {\"StartTime\": 1727755905.7404177, \"EndTime\": 1727755907.050518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1309.7138404846191, \"count\": 1, \"min\": 1309.7138404846191, \"max\": 1309.7138404846191}}}\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.88807230602134 records/second\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=189, train loss <loss>=8.618205937472256\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] Epoch[190] Batch[0] avg_epoch_loss=8.645651\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=8.645650863647461\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] Epoch[190] Batch[5] avg_epoch_loss=8.585431\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=8.585431098937988\n",
      "[10/01/2024 04:11:47 INFO 140492683822912] Epoch[190] Batch [5]#011Speed: 905.41 samples/sec#011loss=8.585431\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] Epoch[190] Batch[10] avg_epoch_loss=8.621673\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=8.665163230895995\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] Epoch[190] Batch [10]#011Speed: 865.77 samples/sec#011loss=8.665163\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] processed a total of 664 examples\n",
      "#metrics {\"StartTime\": 1727755907.0505888, \"EndTime\": 1727755908.3449275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1293.968915939331, \"count\": 1, \"min\": 1293.968915939331, \"max\": 1293.968915939331}}}\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.1151872646549 records/second\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=190, train loss <loss>=8.621672977100719\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] Epoch[191] Batch[0] avg_epoch_loss=8.645786\n",
      "[10/01/2024 04:11:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=8.64578628540039\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] Epoch[191] Batch[5] avg_epoch_loss=8.602490\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=8.602490425109863\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] Epoch[191] Batch [5]#011Speed: 949.20 samples/sec#011loss=8.602490\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] processed a total of 617 examples\n",
      "#metrics {\"StartTime\": 1727755908.3449862, \"EndTime\": 1727755909.5409346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1195.6872940063477, \"count\": 1, \"min\": 1195.6872940063477, \"max\": 1195.6872940063477}}}\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.9624606755619 records/second\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=191, train loss <loss>=8.46777377128601\n",
      "[10/01/2024 04:11:49 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] Epoch[192] Batch[0] avg_epoch_loss=8.442492\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=8.442492485046387\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] Epoch[192] Batch[5] avg_epoch_loss=8.504167\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=8.504167397816977\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] Epoch[192] Batch [5]#011Speed: 953.90 samples/sec#011loss=8.504167\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] Epoch[192] Batch[10] avg_epoch_loss=8.513548\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=8.524803733825683\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] Epoch[192] Batch [10]#011Speed: 847.62 samples/sec#011loss=8.524804\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] processed a total of 673 examples\n",
      "#metrics {\"StartTime\": 1727755909.5410416, \"EndTime\": 1727755910.816304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1274.738073348999, \"count\": 1, \"min\": 1274.738073348999, \"max\": 1274.738073348999}}}\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=527.9132856445274 records/second\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=192, train loss <loss>=8.513547550548207\n",
      "[10/01/2024 04:11:50 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] Epoch[193] Batch[0] avg_epoch_loss=8.298795\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=8.298794746398926\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] Epoch[193] Batch[5] avg_epoch_loss=8.536587\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=8.536587397257486\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] Epoch[193] Batch [5]#011Speed: 928.82 samples/sec#011loss=8.536587\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] processed a total of 569 examples\n",
      "#metrics {\"StartTime\": 1727755910.8163664, \"EndTime\": 1727755911.9360077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1119.2190647125244, \"count\": 1, \"min\": 1119.2190647125244, \"max\": 1119.2190647125244}}}\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=508.34536469284154 records/second\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=193, train loss <loss>=8.519258711073133\n",
      "[10/01/2024 04:11:51 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:52 INFO 140492683822912] Epoch[194] Batch[0] avg_epoch_loss=8.678386\n",
      "[10/01/2024 04:11:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=8.678385734558105\n",
      "[10/01/2024 04:11:52 INFO 140492683822912] Epoch[194] Batch[5] avg_epoch_loss=8.487300\n",
      "[10/01/2024 04:11:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=8.487300395965576\n",
      "[10/01/2024 04:11:52 INFO 140492683822912] Epoch[194] Batch [5]#011Speed: 939.54 samples/sec#011loss=8.487300\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] Epoch[194] Batch[10] avg_epoch_loss=8.569501\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=8.668142509460449\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] Epoch[194] Batch [10]#011Speed: 875.44 samples/sec#011loss=8.668143\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] processed a total of 659 examples\n",
      "#metrics {\"StartTime\": 1727755911.936077, \"EndTime\": 1727755913.2143295, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1277.9138088226318, \"count\": 1, \"min\": 1277.9138088226318, \"max\": 1277.9138088226318}}}\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.6470965954617 records/second\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=194, train loss <loss>=8.569501356645064\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] Epoch[195] Batch[0] avg_epoch_loss=8.358064\n",
      "[10/01/2024 04:11:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=8.358063697814941\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] Epoch[195] Batch[5] avg_epoch_loss=8.486288\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=8.486287911732992\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] Epoch[195] Batch [5]#011Speed: 932.54 samples/sec#011loss=8.486288\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] Epoch[195] Batch[10] avg_epoch_loss=8.474967\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=8.461381721496583\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] Epoch[195] Batch [10]#011Speed: 880.63 samples/sec#011loss=8.461382\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] processed a total of 643 examples\n",
      "#metrics {\"StartTime\": 1727755913.214392, \"EndTime\": 1727755914.5017264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1287.0657444000244, \"count\": 1, \"min\": 1287.0657444000244, \"max\": 1287.0657444000244}}}\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=499.5514624027408 records/second\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=195, train loss <loss>=8.474966916170986\n",
      "[10/01/2024 04:11:54 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] Epoch[196] Batch[0] avg_epoch_loss=8.720153\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=8.720152854919434\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] Epoch[196] Batch[5] avg_epoch_loss=8.426653\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=8.426652749379477\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] Epoch[196] Batch [5]#011Speed: 953.53 samples/sec#011loss=8.426653\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] processed a total of 640 examples\n",
      "#metrics {\"StartTime\": 1727755914.501786, \"EndTime\": 1727755915.6977878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1195.7218647003174, \"count\": 1, \"min\": 1195.7218647003174, \"max\": 1195.7218647003174}}}\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=535.186359415105 records/second\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=196, train loss <loss>=8.53648681640625\n",
      "[10/01/2024 04:11:55 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] Epoch[197] Batch[0] avg_epoch_loss=8.374646\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=8.374646186828613\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] Epoch[197] Batch[5] avg_epoch_loss=8.485824\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=8.48582410812378\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] Epoch[197] Batch [5]#011Speed: 932.06 samples/sec#011loss=8.485824\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] Epoch[197] Batch[10] avg_epoch_loss=8.491609\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=8.498551559448241\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] Epoch[197] Batch [10]#011Speed: 907.62 samples/sec#011loss=8.498552\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] processed a total of 644 examples\n",
      "#metrics {\"StartTime\": 1727755915.6978776, \"EndTime\": 1727755916.9929519, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1294.5740222930908, \"count\": 1, \"min\": 1294.5740222930908, \"max\": 1294.5740222930908}}}\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=497.4193419836985 records/second\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=197, train loss <loss>=8.491609313271262\n",
      "[10/01/2024 04:11:56 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:57 INFO 140492683822912] Epoch[198] Batch[0] avg_epoch_loss=8.625212\n",
      "[10/01/2024 04:11:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=8.625211715698242\n",
      "[10/01/2024 04:11:57 INFO 140492683822912] Epoch[198] Batch[5] avg_epoch_loss=8.452588\n",
      "[10/01/2024 04:11:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=8.452588081359863\n",
      "[10/01/2024 04:11:57 INFO 140492683822912] Epoch[198] Batch [5]#011Speed: 956.51 samples/sec#011loss=8.452588\n",
      "[10/01/2024 04:11:58 INFO 140492683822912] processed a total of 638 examples\n",
      "#metrics {\"StartTime\": 1727755916.9930255, \"EndTime\": 1727755918.1896036, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1196.1801052093506, \"count\": 1, \"min\": 1196.1801052093506, \"max\": 1196.1801052093506}}}\n",
      "[10/01/2024 04:11:58 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=533.3150680563328 records/second\n",
      "[10/01/2024 04:11:58 INFO 140492683822912] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[10/01/2024 04:11:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=198, train loss <loss>=8.491840267181397\n",
      "[10/01/2024 04:11:58 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:11:58 INFO 140492683822912] Epoch[199] Batch[0] avg_epoch_loss=8.381354\n",
      "[10/01/2024 04:11:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=8.381354331970215\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] Epoch[199] Batch[5] avg_epoch_loss=8.468062\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=8.468062241872152\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] Epoch[199] Batch [5]#011Speed: 924.14 samples/sec#011loss=8.468062\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] Epoch[199] Batch[10] avg_epoch_loss=8.528801\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=8.601687240600587\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] Epoch[199] Batch [10]#011Speed: 864.87 samples/sec#011loss=8.601687\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] processed a total of 651 examples\n",
      "#metrics {\"StartTime\": 1727755918.1896796, \"EndTime\": 1727755919.477857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1287.6787185668945, \"count\": 1, \"min\": 1287.6787185668945, \"max\": 1287.6787185668945}}}\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.5199880474392 records/second\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=199, train loss <loss>=8.528800877657803\n",
      "[10/01/2024 04:11:59 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] Epoch[200] Batch[0] avg_epoch_loss=8.302813\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=8.302812576293945\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] Epoch[200] Batch[5] avg_epoch_loss=8.590409\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=8.59040880203247\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] Epoch[200] Batch [5]#011Speed: 894.81 samples/sec#011loss=8.590409\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] processed a total of 630 examples\n",
      "#metrics {\"StartTime\": 1727755919.4779265, \"EndTime\": 1727755920.7030854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1224.7812747955322, \"count\": 1, \"min\": 1224.7812747955322, \"max\": 1224.7812747955322}}}\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=514.3323022985438 records/second\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=200, train loss <loss>=8.553962421417236\n",
      "[10/01/2024 04:12:00 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:01 INFO 140492683822912] Epoch[201] Batch[0] avg_epoch_loss=8.476448\n",
      "[10/01/2024 04:12:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=8.476448059082031\n",
      "[10/01/2024 04:12:01 INFO 140492683822912] Epoch[201] Batch[5] avg_epoch_loss=8.521561\n",
      "[10/01/2024 04:12:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=8.52156114578247\n",
      "[10/01/2024 04:12:01 INFO 140492683822912] Epoch[201] Batch [5]#011Speed: 810.75 samples/sec#011loss=8.521561\n",
      "[10/01/2024 04:12:02 INFO 140492683822912] processed a total of 634 examples\n",
      "#metrics {\"StartTime\": 1727755920.7031589, \"EndTime\": 1727755922.0638833, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1360.3553771972656, \"count\": 1, \"min\": 1360.3553771972656, \"max\": 1360.3553771972656}}}\n",
      "[10/01/2024 04:12:02 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=466.0178518259541 records/second\n",
      "[10/01/2024 04:12:02 INFO 140492683822912] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[10/01/2024 04:12:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=201, train loss <loss>=8.490962314605714\n",
      "[10/01/2024 04:12:02 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:02 INFO 140492683822912] Epoch[202] Batch[0] avg_epoch_loss=8.480698\n",
      "[10/01/2024 04:12:02 INFO 140492683822912] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=8.480697631835938\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] Epoch[202] Batch[5] avg_epoch_loss=8.528767\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=8.528766632080078\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] Epoch[202] Batch [5]#011Speed: 668.64 samples/sec#011loss=8.528767\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] Epoch[202] Batch[10] avg_epoch_loss=8.533192\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=8.538503074645996\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] Epoch[202] Batch [10]#011Speed: 651.92 samples/sec#011loss=8.538503\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] processed a total of 686 examples\n",
      "#metrics {\"StartTime\": 1727755922.0639572, \"EndTime\": 1727755923.7053385, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1641.0276889801025, \"count\": 1, \"min\": 1641.0276889801025, \"max\": 1641.0276889801025}}}\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=418.00558591611133 records/second\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] #quality_metric: host=algo-1, epoch=202, train loss <loss>=8.53319228779186\n",
      "[10/01/2024 04:12:03 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] Epoch[203] Batch[0] avg_epoch_loss=8.537966\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=8.537965774536133\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] Epoch[203] Batch[5] avg_epoch_loss=8.492496\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=8.492496013641357\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] Epoch[203] Batch [5]#011Speed: 940.27 samples/sec#011loss=8.492496\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] Epoch[203] Batch[10] avg_epoch_loss=8.516493\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=8.545289993286133\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] Epoch[203] Batch [10]#011Speed: 859.63 samples/sec#011loss=8.545290\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] processed a total of 667 examples\n",
      "#metrics {\"StartTime\": 1727755923.7054038, \"EndTime\": 1727755924.9821103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1276.3571739196777, \"count\": 1, \"min\": 1276.3571739196777, \"max\": 1276.3571739196777}}}\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=522.5400955462136 records/second\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] #quality_metric: host=algo-1, epoch=203, train loss <loss>=8.516493277116256\n",
      "[10/01/2024 04:12:04 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:05 INFO 140492683822912] Epoch[204] Batch[0] avg_epoch_loss=8.523568\n",
      "[10/01/2024 04:12:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=8.523568153381348\n",
      "[10/01/2024 04:12:05 INFO 140492683822912] Epoch[204] Batch[5] avg_epoch_loss=8.488734\n",
      "[10/01/2024 04:12:05 INFO 140492683822912] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=8.488733609517416\n",
      "[10/01/2024 04:12:05 INFO 140492683822912] Epoch[204] Batch [5]#011Speed: 921.19 samples/sec#011loss=8.488734\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] Epoch[204] Batch[10] avg_epoch_loss=8.446335\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=8.395457077026368\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] Epoch[204] Batch [10]#011Speed: 841.73 samples/sec#011loss=8.395457\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] processed a total of 672 examples\n",
      "#metrics {\"StartTime\": 1727755924.982179, \"EndTime\": 1727755926.2742734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1291.7137145996094, \"count\": 1, \"min\": 1291.7137145996094, \"max\": 1291.7137145996094}}}\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=520.2017648202024 records/second\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=204, train loss <loss>=8.446335185657848\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] Epoch[205] Batch[0] avg_epoch_loss=8.532411\n",
      "[10/01/2024 04:12:06 INFO 140492683822912] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=8.532410621643066\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] Epoch[205] Batch[5] avg_epoch_loss=8.449960\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=8.449960072835287\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] Epoch[205] Batch [5]#011Speed: 905.48 samples/sec#011loss=8.449960\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] Epoch[205] Batch[10] avg_epoch_loss=8.427117\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=8.39970531463623\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] Epoch[205] Batch [10]#011Speed: 860.06 samples/sec#011loss=8.399705\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] processed a total of 651 examples\n",
      "#metrics {\"StartTime\": 1727755926.2743359, \"EndTime\": 1727755927.5871637, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1312.4566078186035, \"count\": 1, \"min\": 1312.4566078186035, \"max\": 1312.4566078186035}}}\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=495.98144019414264 records/second\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] #quality_metric: host=algo-1, epoch=205, train loss <loss>=8.427117000926625\n",
      "[10/01/2024 04:12:07 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] Epoch[206] Batch[0] avg_epoch_loss=8.697261\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=8.697260856628418\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] Epoch[206] Batch[5] avg_epoch_loss=8.489252\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=8.48925224939982\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] Epoch[206] Batch [5]#011Speed: 909.41 samples/sec#011loss=8.489252\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] processed a total of 588 examples\n",
      "#metrics {\"StartTime\": 1727755927.5872273, \"EndTime\": 1727755928.803875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1216.3527011871338, \"count\": 1, \"min\": 1216.3527011871338, \"max\": 1216.3527011871338}}}\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=483.3728136512869 records/second\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] #quality_metric: host=algo-1, epoch=206, train loss <loss>=8.510008716583252\n",
      "[10/01/2024 04:12:08 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:09 INFO 140492683822912] Epoch[207] Batch[0] avg_epoch_loss=8.739783\n",
      "[10/01/2024 04:12:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=8.73978328704834\n",
      "[10/01/2024 04:12:09 INFO 140492683822912] Epoch[207] Batch[5] avg_epoch_loss=8.456267\n",
      "[10/01/2024 04:12:09 INFO 140492683822912] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=8.45626703898112\n",
      "[10/01/2024 04:12:09 INFO 140492683822912] Epoch[207] Batch [5]#011Speed: 916.11 samples/sec#011loss=8.456267\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] processed a total of 621 examples\n",
      "#metrics {\"StartTime\": 1727755928.8039424, \"EndTime\": 1727755930.0176783, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1213.4184837341309, \"count\": 1, \"min\": 1213.4184837341309, \"max\": 1213.4184837341309}}}\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=511.73272815969074 records/second\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=207, train loss <loss>=8.452146911621094\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] Epoch[208] Batch[0] avg_epoch_loss=8.410935\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=8.410935401916504\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] Epoch[208] Batch[5] avg_epoch_loss=8.405520\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=8.40552012125651\n",
      "[10/01/2024 04:12:10 INFO 140492683822912] Epoch[208] Batch [5]#011Speed: 916.68 samples/sec#011loss=8.405520\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] Epoch[208] Batch[10] avg_epoch_loss=8.208835\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=7.972812461853027\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] Epoch[208] Batch [10]#011Speed: 875.15 samples/sec#011loss=7.972812\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] processed a total of 645 examples\n",
      "#metrics {\"StartTime\": 1727755930.0177512, \"EndTime\": 1727755931.3135128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1295.4201698303223, \"count\": 1, \"min\": 1295.4201698303223, \"max\": 1295.4201698303223}}}\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=497.873037250217 records/second\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=208, train loss <loss>=8.208834821527654\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] best epoch loss so far\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/state_3bf72d17-4204-4e56-a961-183d102c4594-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755931.3135743, \"EndTime\": 1727755931.323657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.680509567260742, \"count\": 1, \"min\": 9.680509567260742, \"max\": 9.680509567260742}}}\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] Epoch[209] Batch[0] avg_epoch_loss=8.592795\n",
      "[10/01/2024 04:12:11 INFO 140492683822912] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=8.592795372009277\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] Epoch[209] Batch[5] avg_epoch_loss=8.577591\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=8.577591260274252\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] Epoch[209] Batch [5]#011Speed: 890.55 samples/sec#011loss=8.577591\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] processed a total of 606 examples\n",
      "#metrics {\"StartTime\": 1727755931.3237472, \"EndTime\": 1727755932.5381773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1214.3757343292236, \"count\": 1, \"min\": 1214.3757343292236, \"max\": 1214.3757343292236}}}\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=498.982348959454 records/second\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] #quality_metric: host=algo-1, epoch=209, train loss <loss>=8.507020044326783\n",
      "[10/01/2024 04:12:12 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] Epoch[210] Batch[0] avg_epoch_loss=8.727510\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=8.727510452270508\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] Epoch[210] Batch[5] avg_epoch_loss=8.521662\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=8.521662394205729\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] Epoch[210] Batch [5]#011Speed: 889.35 samples/sec#011loss=8.521662\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] processed a total of 627 examples\n",
      "#metrics {\"StartTime\": 1727755932.5382447, \"EndTime\": 1727755933.7622223, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1223.677158355713, \"count\": 1, \"min\": 1223.677158355713, \"max\": 1223.677158355713}}}\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=512.3501196405756 records/second\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] #quality_metric: host=algo-1, epoch=210, train loss <loss>=8.558716011047363\n",
      "[10/01/2024 04:12:13 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] Epoch[211] Batch[0] avg_epoch_loss=8.505902\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=8.505902290344238\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] Epoch[211] Batch[5] avg_epoch_loss=8.548284\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=8.548283576965332\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] Epoch[211] Batch [5]#011Speed: 934.90 samples/sec#011loss=8.548284\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] processed a total of 637 examples\n",
      "#metrics {\"StartTime\": 1727755933.762288, \"EndTime\": 1727755934.965722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1203.1269073486328, \"count\": 1, \"min\": 1203.1269073486328, \"max\": 1203.1269073486328}}}\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=529.408384706716 records/second\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] #quality_metric: host=algo-1, epoch=211, train loss <loss>=8.54771556854248\n",
      "[10/01/2024 04:12:14 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:15 INFO 140492683822912] Epoch[212] Batch[0] avg_epoch_loss=8.544586\n",
      "[10/01/2024 04:12:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=8.544586181640625\n",
      "[10/01/2024 04:12:15 INFO 140492683822912] Epoch[212] Batch[5] avg_epoch_loss=8.519045\n",
      "[10/01/2024 04:12:15 INFO 140492683822912] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=8.519045193990072\n",
      "[10/01/2024 04:12:15 INFO 140492683822912] Epoch[212] Batch [5]#011Speed: 924.55 samples/sec#011loss=8.519045\n",
      "[10/01/2024 04:12:16 INFO 140492683822912] processed a total of 633 examples\n",
      "#metrics {\"StartTime\": 1727755934.9657881, \"EndTime\": 1727755936.1725605, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1206.3591480255127, \"count\": 1, \"min\": 1206.3591480255127, \"max\": 1206.3591480255127}}}\n",
      "[10/01/2024 04:12:16 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=524.6766378492442 records/second\n",
      "[10/01/2024 04:12:16 INFO 140492683822912] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[10/01/2024 04:12:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=212, train loss <loss>=8.54155511856079\n",
      "[10/01/2024 04:12:16 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:16 INFO 140492683822912] Epoch[213] Batch[0] avg_epoch_loss=8.624861\n",
      "[10/01/2024 04:12:16 INFO 140492683822912] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=8.624860763549805\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] Epoch[213] Batch[5] avg_epoch_loss=8.476965\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=8.476965427398682\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] Epoch[213] Batch [5]#011Speed: 930.59 samples/sec#011loss=8.476965\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] Epoch[213] Batch[10] avg_epoch_loss=8.602485\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=8.753107833862305\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] Epoch[213] Batch [10]#011Speed: 887.05 samples/sec#011loss=8.753108\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] processed a total of 645 examples\n",
      "#metrics {\"StartTime\": 1727755936.1726282, \"EndTime\": 1727755937.4559386, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1283.0071449279785, \"count\": 1, \"min\": 1283.0071449279785, \"max\": 1283.0071449279785}}}\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.68968441582234 records/second\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] #quality_metric: host=algo-1, epoch=213, train loss <loss>=8.602484703063965\n",
      "[10/01/2024 04:12:17 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] Epoch[214] Batch[0] avg_epoch_loss=8.323225\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=8.323225021362305\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] Epoch[214] Batch[5] avg_epoch_loss=8.464372\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=8.46437152226766\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] Epoch[214] Batch [5]#011Speed: 925.16 samples/sec#011loss=8.464372\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] Epoch[214] Batch[10] avg_epoch_loss=8.550862\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=8.65465087890625\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] Epoch[214] Batch [10]#011Speed: 846.71 samples/sec#011loss=8.654651\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] processed a total of 665 examples\n",
      "#metrics {\"StartTime\": 1727755937.4559999, \"EndTime\": 1727755938.744483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1288.1531715393066, \"count\": 1, \"min\": 1288.1531715393066, \"max\": 1288.1531715393066}}}\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=516.2038785449303 records/second\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] #quality_metric: host=algo-1, epoch=214, train loss <loss>=8.550862138921564\n",
      "[10/01/2024 04:12:18 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:19 INFO 140492683822912] Epoch[215] Batch[0] avg_epoch_loss=8.394585\n",
      "[10/01/2024 04:12:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=8.394584655761719\n",
      "[10/01/2024 04:12:19 INFO 140492683822912] Epoch[215] Batch[5] avg_epoch_loss=8.529022\n",
      "[10/01/2024 04:12:19 INFO 140492683822912] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=8.529021739959717\n",
      "[10/01/2024 04:12:19 INFO 140492683822912] Epoch[215] Batch [5]#011Speed: 935.55 samples/sec#011loss=8.529022\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] Epoch[215] Batch[10] avg_epoch_loss=8.478788\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=8.41850757598877\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] Epoch[215] Batch [10]#011Speed: 825.01 samples/sec#011loss=8.418508\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] processed a total of 689 examples\n",
      "#metrics {\"StartTime\": 1727755938.7445524, \"EndTime\": 1727755940.0413198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1296.440839767456, \"count\": 1, \"min\": 1296.440839767456, \"max\": 1296.440839767456}}}\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=531.4170093136223 records/second\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=215, train loss <loss>=8.478788029063832\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] Epoch[216] Batch[0] avg_epoch_loss=8.615821\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=8.61582088470459\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] Epoch[216] Batch[5] avg_epoch_loss=8.527592\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=8.527591705322266\n",
      "[10/01/2024 04:12:20 INFO 140492683822912] Epoch[216] Batch [5]#011Speed: 940.21 samples/sec#011loss=8.527592\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] Epoch[216] Batch[10] avg_epoch_loss=8.464521\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=8.388835906982422\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] Epoch[216] Batch [10]#011Speed: 910.91 samples/sec#011loss=8.388836\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] processed a total of 644 examples\n",
      "#metrics {\"StartTime\": 1727755940.041383, \"EndTime\": 1727755941.3143587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1272.7055549621582, \"count\": 1, \"min\": 1272.7055549621582, \"max\": 1272.7055549621582}}}\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.9735640305375 records/second\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=216, train loss <loss>=8.464520887895064\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] Epoch[217] Batch[0] avg_epoch_loss=8.432532\n",
      "[10/01/2024 04:12:21 INFO 140492683822912] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=8.43253231048584\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] Epoch[217] Batch[5] avg_epoch_loss=8.561078\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=8.561078071594238\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] Epoch[217] Batch [5]#011Speed: 950.47 samples/sec#011loss=8.561078\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] Epoch[217] Batch[10] avg_epoch_loss=8.544467\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=8.524533081054688\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] Epoch[217] Batch [10]#011Speed: 898.64 samples/sec#011loss=8.524533\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] processed a total of 643 examples\n",
      "#metrics {\"StartTime\": 1727755941.314418, \"EndTime\": 1727755942.587691, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1273.008108139038, \"count\": 1, \"min\": 1273.008108139038, \"max\": 1273.008108139038}}}\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.0674538185914 records/second\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] #quality_metric: host=algo-1, epoch=217, train loss <loss>=8.544466712258078\n",
      "[10/01/2024 04:12:22 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] Epoch[218] Batch[0] avg_epoch_loss=8.668640\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=8.66864013671875\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] Epoch[218] Batch[5] avg_epoch_loss=8.533275\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=8.53327496846517\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] Epoch[218] Batch [5]#011Speed: 942.25 samples/sec#011loss=8.533275\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] processed a total of 609 examples\n",
      "#metrics {\"StartTime\": 1727755942.5877514, \"EndTime\": 1727755943.774577, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1186.3465309143066, \"count\": 1, \"min\": 1186.3465309143066, \"max\": 1186.3465309143066}}}\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.2966870130066 records/second\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] #quality_metric: host=algo-1, epoch=218, train loss <loss>=8.570239543914795\n",
      "[10/01/2024 04:12:23 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:24 INFO 140492683822912] Epoch[219] Batch[0] avg_epoch_loss=8.568638\n",
      "[10/01/2024 04:12:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=8.56863784790039\n",
      "[10/01/2024 04:12:24 INFO 140492683822912] Epoch[219] Batch[5] avg_epoch_loss=8.509153\n",
      "[10/01/2024 04:12:24 INFO 140492683822912] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=8.509153207143148\n",
      "[10/01/2024 04:12:24 INFO 140492683822912] Epoch[219] Batch [5]#011Speed: 806.90 samples/sec#011loss=8.509153\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] Epoch[219] Batch[10] avg_epoch_loss=8.466037\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=8.414298248291015\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] Epoch[219] Batch [10]#011Speed: 861.70 samples/sec#011loss=8.414298\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] processed a total of 676 examples\n",
      "#metrics {\"StartTime\": 1727755943.7746468, \"EndTime\": 1727755945.1024468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1327.444076538086, \"count\": 1, \"min\": 1327.444076538086, \"max\": 1327.444076538086}}}\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=509.21283316777726 records/second\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=219, train loss <loss>=8.466037316755815\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] Epoch[220] Batch[0] avg_epoch_loss=8.488570\n",
      "[10/01/2024 04:12:25 INFO 140492683822912] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=8.488570213317871\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] Epoch[220] Batch[5] avg_epoch_loss=8.511474\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=8.511474132537842\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] Epoch[220] Batch [5]#011Speed: 945.50 samples/sec#011loss=8.511474\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] processed a total of 634 examples\n",
      "#metrics {\"StartTime\": 1727755945.1025126, \"EndTime\": 1727755946.2996387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1196.751356124878, \"count\": 1, \"min\": 1196.751356124878, \"max\": 1196.751356124878}}}\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=529.7221429056634 records/second\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=220, train loss <loss>=8.526301193237305\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] Epoch[221] Batch[0] avg_epoch_loss=8.401118\n",
      "[10/01/2024 04:12:26 INFO 140492683822912] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=8.401118278503418\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] Epoch[221] Batch[5] avg_epoch_loss=8.572352\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=8.572351773579916\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] Epoch[221] Batch [5]#011Speed: 939.99 samples/sec#011loss=8.572352\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] processed a total of 625 examples\n",
      "#metrics {\"StartTime\": 1727755946.2997086, \"EndTime\": 1727755947.5024786, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1202.4226188659668, \"count\": 1, \"min\": 1202.4226188659668, \"max\": 1202.4226188659668}}}\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=519.7407878471255 records/second\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] #quality_metric: host=algo-1, epoch=221, train loss <loss>=8.554588127136231\n",
      "[10/01/2024 04:12:27 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] Epoch[222] Batch[0] avg_epoch_loss=8.572069\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=8.57206916809082\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] Epoch[222] Batch[5] avg_epoch_loss=8.550614\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=8.55061419804891\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] Epoch[222] Batch [5]#011Speed: 931.84 samples/sec#011loss=8.550614\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] processed a total of 584 examples\n",
      "#metrics {\"StartTime\": 1727755947.5025487, \"EndTime\": 1727755948.6962767, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1193.4199333190918, \"count\": 1, \"min\": 1193.4199333190918, \"max\": 1193.4199333190918}}}\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=489.31056824363077 records/second\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] #quality_metric: host=algo-1, epoch=222, train loss <loss>=8.494423770904541\n",
      "[10/01/2024 04:12:28 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] Epoch[223] Batch[0] avg_epoch_loss=8.465153\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=8.465152740478516\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] Epoch[223] Batch[5] avg_epoch_loss=8.371769\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=8.371768633524576\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] Epoch[223] Batch [5]#011Speed: 940.78 samples/sec#011loss=8.371769\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] processed a total of 615 examples\n",
      "#metrics {\"StartTime\": 1727755948.6963427, \"EndTime\": 1727755949.8957736, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1199.1004943847656, \"count\": 1, \"min\": 1199.1004943847656, \"max\": 1199.1004943847656}}}\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=512.8204182090727 records/second\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] #quality_metric: host=algo-1, epoch=223, train loss <loss>=8.448997592926025\n",
      "[10/01/2024 04:12:29 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:30 INFO 140492683822912] Epoch[224] Batch[0] avg_epoch_loss=8.487182\n",
      "[10/01/2024 04:12:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=8.487181663513184\n",
      "[10/01/2024 04:12:30 INFO 140492683822912] Epoch[224] Batch[5] avg_epoch_loss=8.463553\n",
      "[10/01/2024 04:12:30 INFO 140492683822912] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=8.463552633921305\n",
      "[10/01/2024 04:12:30 INFO 140492683822912] Epoch[224] Batch [5]#011Speed: 946.02 samples/sec#011loss=8.463553\n",
      "[10/01/2024 04:12:31 INFO 140492683822912] processed a total of 615 examples\n",
      "#metrics {\"StartTime\": 1727755949.8958817, \"EndTime\": 1727755951.093363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1197.1149444580078, \"count\": 1, \"min\": 1197.1149444580078, \"max\": 1197.1149444580078}}}\n",
      "[10/01/2024 04:12:31 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=513.691034243786 records/second\n",
      "[10/01/2024 04:12:31 INFO 140492683822912] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[10/01/2024 04:12:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=224, train loss <loss>=8.312875461578368\n",
      "[10/01/2024 04:12:31 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:31 INFO 140492683822912] Epoch[225] Batch[0] avg_epoch_loss=8.686965\n",
      "[10/01/2024 04:12:31 INFO 140492683822912] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=8.686964988708496\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] Epoch[225] Batch[5] avg_epoch_loss=8.727049\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=8.727049350738525\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] Epoch[225] Batch [5]#011Speed: 877.28 samples/sec#011loss=8.727049\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] Epoch[225] Batch[10] avg_epoch_loss=8.590162\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=8.425898170471191\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] Epoch[225] Batch [10]#011Speed: 797.39 samples/sec#011loss=8.425898\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] processed a total of 691 examples\n",
      "#metrics {\"StartTime\": 1727755951.093436, \"EndTime\": 1727755952.429551, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1335.5121612548828, \"count\": 1, \"min\": 1335.5121612548828, \"max\": 1335.5121612548828}}}\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=517.3695856529241 records/second\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] #quality_metric: host=algo-1, epoch=225, train loss <loss>=8.59016245061701\n",
      "[10/01/2024 04:12:32 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] Epoch[226] Batch[0] avg_epoch_loss=8.791842\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=8.791841506958008\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] Epoch[226] Batch[5] avg_epoch_loss=8.590450\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=8.590450445810953\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] Epoch[226] Batch [5]#011Speed: 938.98 samples/sec#011loss=8.590450\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] processed a total of 604 examples\n",
      "#metrics {\"StartTime\": 1727755952.4296105, \"EndTime\": 1727755953.6325305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1202.63671875, \"count\": 1, \"min\": 1202.63671875, \"max\": 1202.63671875}}}\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=502.1888830410922 records/second\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] #quality_metric: host=algo-1, epoch=226, train loss <loss>=8.56101598739624\n",
      "[10/01/2024 04:12:33 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] Epoch[227] Batch[0] avg_epoch_loss=8.543979\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=8.543978691101074\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] Epoch[227] Batch[5] avg_epoch_loss=8.545617\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=8.54561710357666\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] Epoch[227] Batch [5]#011Speed: 930.68 samples/sec#011loss=8.545617\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] Epoch[227] Batch[10] avg_epoch_loss=8.612433\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=8.6926118850708\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] Epoch[227] Batch [10]#011Speed: 880.11 samples/sec#011loss=8.692612\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] processed a total of 647 examples\n",
      "#metrics {\"StartTime\": 1727755953.632598, \"EndTime\": 1727755954.9290853, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1296.067237854004, \"count\": 1, \"min\": 1296.067237854004, \"max\": 1296.067237854004}}}\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=499.1665925686256 records/second\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] #quality_metric: host=algo-1, epoch=227, train loss <loss>=8.612432913346725\n",
      "[10/01/2024 04:12:34 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:35 INFO 140492683822912] Epoch[228] Batch[0] avg_epoch_loss=8.584060\n",
      "[10/01/2024 04:12:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=8.584059715270996\n",
      "[10/01/2024 04:12:35 INFO 140492683822912] Epoch[228] Batch[5] avg_epoch_loss=8.528717\n",
      "[10/01/2024 04:12:35 INFO 140492683822912] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=8.528716723124186\n",
      "[10/01/2024 04:12:35 INFO 140492683822912] Epoch[228] Batch [5]#011Speed: 943.91 samples/sec#011loss=8.528717\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] Epoch[228] Batch[10] avg_epoch_loss=8.402070\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=8.250094127655029\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] Epoch[228] Batch [10]#011Speed: 891.32 samples/sec#011loss=8.250094\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] processed a total of 652 examples\n",
      "#metrics {\"StartTime\": 1727755954.9291496, \"EndTime\": 1727755956.2161074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1286.5424156188965, \"count\": 1, \"min\": 1286.5424156188965, \"max\": 1286.5424156188965}}}\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=506.7481598854377 records/second\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=228, train loss <loss>=8.402070088820023\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] Epoch[229] Batch[0] avg_epoch_loss=8.475422\n",
      "[10/01/2024 04:12:36 INFO 140492683822912] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=8.475421905517578\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] Epoch[229] Batch[5] avg_epoch_loss=8.543522\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=8.543521881103516\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] Epoch[229] Batch [5]#011Speed: 953.39 samples/sec#011loss=8.543522\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] Epoch[229] Batch[10] avg_epoch_loss=8.663988\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=8.808546257019042\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] Epoch[229] Batch [10]#011Speed: 901.76 samples/sec#011loss=8.808546\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] processed a total of 643 examples\n",
      "#metrics {\"StartTime\": 1727755956.2161708, \"EndTime\": 1727755957.4872203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1270.6127166748047, \"count\": 1, \"min\": 1270.6127166748047, \"max\": 1270.6127166748047}}}\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=506.0156603938908 records/second\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] #quality_metric: host=algo-1, epoch=229, train loss <loss>=8.663987506519664\n",
      "[10/01/2024 04:12:37 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] Epoch[230] Batch[0] avg_epoch_loss=8.530726\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=8.530726432800293\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] Epoch[230] Batch[5] avg_epoch_loss=8.460454\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=8.460454305013021\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] Epoch[230] Batch [5]#011Speed: 928.66 samples/sec#011loss=8.460454\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] Epoch[230] Batch[10] avg_epoch_loss=8.389682\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=8.304755783081054\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] Epoch[230] Batch [10]#011Speed: 838.13 samples/sec#011loss=8.304756\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] processed a total of 659 examples\n",
      "#metrics {\"StartTime\": 1727755957.4872847, \"EndTime\": 1727755958.7893636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1301.4616966247559, \"count\": 1, \"min\": 1301.4616966247559, \"max\": 1301.4616966247559}}}\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=506.31775339368255 records/second\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] #quality_metric: host=algo-1, epoch=230, train loss <loss>=8.3896822495894\n",
      "[10/01/2024 04:12:38 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:39 INFO 140492683822912] Epoch[231] Batch[0] avg_epoch_loss=8.625240\n",
      "[10/01/2024 04:12:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=8.625240325927734\n",
      "[10/01/2024 04:12:39 INFO 140492683822912] Epoch[231] Batch[5] avg_epoch_loss=8.778562\n",
      "[10/01/2024 04:12:39 INFO 140492683822912] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=8.77856175104777\n",
      "[10/01/2024 04:12:39 INFO 140492683822912] Epoch[231] Batch [5]#011Speed: 875.57 samples/sec#011loss=8.778562\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] Epoch[231] Batch[10] avg_epoch_loss=8.913938\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=9.076390266418457\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] Epoch[231] Batch [10]#011Speed: 864.14 samples/sec#011loss=9.076390\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] processed a total of 655 examples\n",
      "#metrics {\"StartTime\": 1727755958.7894263, \"EndTime\": 1727755960.097592, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1307.8994750976562, \"count\": 1, \"min\": 1307.8994750976562, \"max\": 1307.8994750976562}}}\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.76750459386847 records/second\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=231, train loss <loss>=8.913938348943537\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] Epoch[232] Batch[0] avg_epoch_loss=8.625994\n",
      "[10/01/2024 04:12:40 INFO 140492683822912] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=8.625993728637695\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] Epoch[232] Batch[5] avg_epoch_loss=8.728661\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=8.72866121927897\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] Epoch[232] Batch [5]#011Speed: 935.55 samples/sec#011loss=8.728661\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] processed a total of 631 examples\n",
      "#metrics {\"StartTime\": 1727755960.0976565, \"EndTime\": 1727755961.296749, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1198.7555027008057, \"count\": 1, \"min\": 1198.7555027008057, \"max\": 1198.7555027008057}}}\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=526.3324386801984 records/second\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=232, train loss <loss>=8.742552566528321\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] Epoch[233] Batch[0] avg_epoch_loss=8.528184\n",
      "[10/01/2024 04:12:41 INFO 140492683822912] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=8.528183937072754\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] Epoch[233] Batch[5] avg_epoch_loss=8.551562\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=8.55156167348226\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] Epoch[233] Batch [5]#011Speed: 947.51 samples/sec#011loss=8.551562\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] Epoch[233] Batch[10] avg_epoch_loss=8.561667\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=8.573793029785156\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] Epoch[233] Batch [10]#011Speed: 868.24 samples/sec#011loss=8.573793\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] processed a total of 661 examples\n",
      "#metrics {\"StartTime\": 1727755961.2968168, \"EndTime\": 1727755962.5731742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1275.7859230041504, \"count\": 1, \"min\": 1275.7859230041504, \"max\": 1275.7859230041504}}}\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.0754058928746 records/second\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] #quality_metric: host=algo-1, epoch=233, train loss <loss>=8.561666835438121\n",
      "[10/01/2024 04:12:42 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:43 INFO 140492683822912] Epoch[234] Batch[0] avg_epoch_loss=8.760038\n",
      "[10/01/2024 04:12:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=8.760038375854492\n",
      "[10/01/2024 04:12:43 INFO 140492683822912] Epoch[234] Batch[5] avg_epoch_loss=8.587344\n",
      "[10/01/2024 04:12:43 INFO 140492683822912] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=8.58734401067098\n",
      "[10/01/2024 04:12:43 INFO 140492683822912] Epoch[234] Batch [5]#011Speed: 800.31 samples/sec#011loss=8.587344\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] Epoch[234] Batch[10] avg_epoch_loss=8.580823\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=8.572998046875\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] Epoch[234] Batch [10]#011Speed: 587.68 samples/sec#011loss=8.572998\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] processed a total of 682 examples\n",
      "#metrics {\"StartTime\": 1727755962.5732338, \"EndTime\": 1727755964.0774484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1503.9551258087158, \"count\": 1, \"min\": 1503.9551258087158, \"max\": 1503.9551258087158}}}\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=453.44200792334345 records/second\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=234, train loss <loss>=8.580823118036443\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] Epoch[235] Batch[0] avg_epoch_loss=8.279610\n",
      "[10/01/2024 04:12:44 INFO 140492683822912] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=8.279609680175781\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] Epoch[235] Batch[5] avg_epoch_loss=8.365100\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=8.365100224812826\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] Epoch[235] Batch [5]#011Speed: 931.93 samples/sec#011loss=8.365100\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] processed a total of 631 examples\n",
      "#metrics {\"StartTime\": 1727755964.0775156, \"EndTime\": 1727755965.3016741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1223.508358001709, \"count\": 1, \"min\": 1223.508358001709, \"max\": 1223.508358001709}}}\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=515.6872198078325 records/second\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=235, train loss <loss>=8.433755016326904\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] Epoch[236] Batch[0] avg_epoch_loss=8.398658\n",
      "[10/01/2024 04:12:45 INFO 140492683822912] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=8.39865779876709\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] Epoch[236] Batch[5] avg_epoch_loss=8.434088\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=8.434088071187338\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] Epoch[236] Batch [5]#011Speed: 933.91 samples/sec#011loss=8.434088\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] Epoch[236] Batch[10] avg_epoch_loss=8.478369\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=8.531505966186524\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] Epoch[236] Batch [10]#011Speed: 862.20 samples/sec#011loss=8.531506\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] processed a total of 647 examples\n",
      "#metrics {\"StartTime\": 1727755965.301743, \"EndTime\": 1727755966.5940566, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1291.9394969940186, \"count\": 1, \"min\": 1291.9394969940186, \"max\": 1291.9394969940186}}}\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=500.75798593670595 records/second\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] #quality_metric: host=algo-1, epoch=236, train loss <loss>=8.478368932550604\n",
      "[10/01/2024 04:12:46 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] Epoch[237] Batch[0] avg_epoch_loss=8.541511\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=8.541510581970215\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] Epoch[237] Batch[5] avg_epoch_loss=8.519707\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=8.519707043965658\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] Epoch[237] Batch [5]#011Speed: 953.25 samples/sec#011loss=8.519707\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] Epoch[237] Batch[10] avg_epoch_loss=8.456757\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=8.381215858459473\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] Epoch[237] Batch [10]#011Speed: 817.19 samples/sec#011loss=8.381216\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] processed a total of 662 examples\n",
      "#metrics {\"StartTime\": 1727755966.5941246, \"EndTime\": 1727755967.9050055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1310.5113506317139, \"count\": 1, \"min\": 1310.5113506317139, \"max\": 1310.5113506317139}}}\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=505.11187038594096 records/second\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] #quality_metric: host=algo-1, epoch=237, train loss <loss>=8.456756505099209\n",
      "[10/01/2024 04:12:47 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:48 INFO 140492683822912] Epoch[238] Batch[0] avg_epoch_loss=8.750003\n",
      "[10/01/2024 04:12:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=8.75000286102295\n",
      "[10/01/2024 04:12:48 INFO 140492683822912] Epoch[238] Batch[5] avg_epoch_loss=8.556468\n",
      "[10/01/2024 04:12:48 INFO 140492683822912] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=8.556468486785889\n",
      "[10/01/2024 04:12:48 INFO 140492683822912] Epoch[238] Batch [5]#011Speed: 930.63 samples/sec#011loss=8.556468\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] Epoch[238] Batch[10] avg_epoch_loss=8.481358\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=8.39122486114502\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] Epoch[238] Batch [10]#011Speed: 846.30 samples/sec#011loss=8.391225\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] processed a total of 645 examples\n",
      "#metrics {\"StartTime\": 1727755967.9050655, \"EndTime\": 1727755969.2046292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1299.3028163909912, \"count\": 1, \"min\": 1299.3028163909912, \"max\": 1299.3028163909912}}}\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=496.38427732224795 records/second\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=238, train loss <loss>=8.48135774785822\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] Epoch[239] Batch[0] avg_epoch_loss=8.480522\n",
      "[10/01/2024 04:12:49 INFO 140492683822912] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=8.480522155761719\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] Epoch[239] Batch[5] avg_epoch_loss=8.491247\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=8.491247336069742\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] Epoch[239] Batch [5]#011Speed: 948.04 samples/sec#011loss=8.491247\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] processed a total of 636 examples\n",
      "#metrics {\"StartTime\": 1727755969.2046947, \"EndTime\": 1727755970.4044285, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1199.4349956512451, \"count\": 1, \"min\": 1199.4349956512451, \"max\": 1199.4349956512451}}}\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=530.2061341928221 records/second\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=239, train loss <loss>=8.495232582092285\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] Epoch[240] Batch[0] avg_epoch_loss=8.514388\n",
      "[10/01/2024 04:12:50 INFO 140492683822912] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=8.514388084411621\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] Epoch[240] Batch[5] avg_epoch_loss=8.391528\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=8.391528288523356\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] Epoch[240] Batch [5]#011Speed: 947.24 samples/sec#011loss=8.391528\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] processed a total of 639 examples\n",
      "#metrics {\"StartTime\": 1727755970.404497, \"EndTime\": 1727755971.598241, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1193.2766437530518, \"count\": 1, \"min\": 1193.2766437530518, \"max\": 1193.2766437530518}}}\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=535.4563285555371 records/second\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] #quality_metric: host=algo-1, epoch=240, train loss <loss>=8.436735153198242\n",
      "[10/01/2024 04:12:51 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] Epoch[241] Batch[0] avg_epoch_loss=8.533350\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=8.533349990844727\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] Epoch[241] Batch[5] avg_epoch_loss=8.511085\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=8.51108455657959\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] Epoch[241] Batch [5]#011Speed: 951.94 samples/sec#011loss=8.511085\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] processed a total of 609 examples\n",
      "#metrics {\"StartTime\": 1727755971.598308, \"EndTime\": 1727755972.798254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1199.4895935058594, \"count\": 1, \"min\": 1199.4895935058594, \"max\": 1199.4895935058594}}}\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=507.6684237984933 records/second\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] #quality_metric: host=algo-1, epoch=241, train loss <loss>=8.37658429145813\n",
      "[10/01/2024 04:12:52 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:53 INFO 140492683822912] Epoch[242] Batch[0] avg_epoch_loss=8.554389\n",
      "[10/01/2024 04:12:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=8.554388999938965\n",
      "[10/01/2024 04:12:53 INFO 140492683822912] Epoch[242] Batch[5] avg_epoch_loss=8.486081\n",
      "[10/01/2024 04:12:53 INFO 140492683822912] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=8.486080646514893\n",
      "[10/01/2024 04:12:53 INFO 140492683822912] Epoch[242] Batch [5]#011Speed: 918.27 samples/sec#011loss=8.486081\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] Epoch[242] Batch[10] avg_epoch_loss=8.574614\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=8.680853271484375\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] Epoch[242] Batch [10]#011Speed: 915.21 samples/sec#011loss=8.680853\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] processed a total of 643 examples\n",
      "#metrics {\"StartTime\": 1727755972.798322, \"EndTime\": 1727755974.0744593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1275.7508754730225, \"count\": 1, \"min\": 1275.7508754730225, \"max\": 1275.7508754730225}}}\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.9816731047131 records/second\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=242, train loss <loss>=8.574613657864658\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] Epoch[243] Batch[0] avg_epoch_loss=8.262872\n",
      "[10/01/2024 04:12:54 INFO 140492683822912] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=8.262871742248535\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] Epoch[243] Batch[5] avg_epoch_loss=8.442518\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=8.44251807530721\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] Epoch[243] Batch [5]#011Speed: 939.30 samples/sec#011loss=8.442518\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] Epoch[243] Batch[10] avg_epoch_loss=8.591988\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=8.771352386474609\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] Epoch[243] Batch [10]#011Speed: 881.93 samples/sec#011loss=8.771352\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] processed a total of 648 examples\n",
      "#metrics {\"StartTime\": 1727755974.0745196, \"EndTime\": 1727755975.372291, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1297.5010871887207, \"count\": 1, \"min\": 1297.5010871887207, \"max\": 1297.5010871887207}}}\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=499.38364880872433 records/second\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=243, train loss <loss>=8.591988216746937\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] Epoch[244] Batch[0] avg_epoch_loss=8.408488\n",
      "[10/01/2024 04:12:55 INFO 140492683822912] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=8.408488273620605\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] Epoch[244] Batch[5] avg_epoch_loss=8.451782\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=8.451781749725342\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] Epoch[244] Batch [5]#011Speed: 934.30 samples/sec#011loss=8.451782\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] processed a total of 632 examples\n",
      "#metrics {\"StartTime\": 1727755975.3723595, \"EndTime\": 1727755976.5862305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1213.507890701294, \"count\": 1, \"min\": 1213.507890701294, \"max\": 1213.507890701294}}}\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=520.762552875824 records/second\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] #quality_metric: host=algo-1, epoch=244, train loss <loss>=8.483685779571534\n",
      "[10/01/2024 04:12:56 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] Epoch[245] Batch[0] avg_epoch_loss=8.506527\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=8.506526947021484\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] Epoch[245] Batch[5] avg_epoch_loss=8.455973\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=8.455972989400228\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] Epoch[245] Batch [5]#011Speed: 956.24 samples/sec#011loss=8.455973\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] processed a total of 590 examples\n",
      "#metrics {\"StartTime\": 1727755976.5862966, \"EndTime\": 1727755977.7734287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1186.7315769195557, \"count\": 1, \"min\": 1186.7315769195557, \"max\": 1186.7315769195557}}}\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=497.12027182279286 records/second\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] #quality_metric: host=algo-1, epoch=245, train loss <loss>=8.475217628479005\n",
      "[10/01/2024 04:12:57 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:58 INFO 140492683822912] Epoch[246] Batch[0] avg_epoch_loss=8.388103\n",
      "[10/01/2024 04:12:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=8.388103485107422\n",
      "[10/01/2024 04:12:58 INFO 140492683822912] Epoch[246] Batch[5] avg_epoch_loss=8.374452\n",
      "[10/01/2024 04:12:58 INFO 140492683822912] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=8.374451637268066\n",
      "[10/01/2024 04:12:58 INFO 140492683822912] Epoch[246] Batch [5]#011Speed: 942.18 samples/sec#011loss=8.374452\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] Epoch[246] Batch[10] avg_epoch_loss=8.349180\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=8.318853950500488\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] Epoch[246] Batch [10]#011Speed: 886.11 samples/sec#011loss=8.318854\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] processed a total of 643 examples\n",
      "#metrics {\"StartTime\": 1727755977.7735035, \"EndTime\": 1727755979.0521176, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1278.196096420288, \"count\": 1, \"min\": 1278.196096420288, \"max\": 1278.196096420288}}}\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=503.01770469397087 records/second\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=246, train loss <loss>=8.349179961464621\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] Epoch[247] Batch[0] avg_epoch_loss=8.343321\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=8.343320846557617\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] Epoch[247] Batch[5] avg_epoch_loss=8.475966\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=8.475965976715088\n",
      "[10/01/2024 04:12:59 INFO 140492683822912] Epoch[247] Batch [5]#011Speed: 924.75 samples/sec#011loss=8.475966\n",
      "[10/01/2024 04:13:00 INFO 140492683822912] processed a total of 626 examples\n",
      "#metrics {\"StartTime\": 1727755979.052178, \"EndTime\": 1727755980.2594883, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1207.03125, \"count\": 1, \"min\": 1207.03125, \"max\": 1207.03125}}}\n",
      "[10/01/2024 04:13:00 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=518.5814297104803 records/second\n",
      "[10/01/2024 04:13:00 INFO 140492683822912] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[10/01/2024 04:13:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=247, train loss <loss>=8.464898490905762\n",
      "[10/01/2024 04:13:00 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:13:00 INFO 140492683822912] Epoch[248] Batch[0] avg_epoch_loss=8.526731\n",
      "[10/01/2024 04:13:00 INFO 140492683822912] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=8.52673053741455\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Epoch[248] Batch[5] avg_epoch_loss=8.470931\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=8.470930576324463\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Epoch[248] Batch [5]#011Speed: 810.81 samples/sec#011loss=8.470931\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] processed a total of 619 examples\n",
      "#metrics {\"StartTime\": 1727755980.259564, \"EndTime\": 1727755981.608715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1348.7365245819092, \"count\": 1, \"min\": 1348.7365245819092, \"max\": 1348.7365245819092}}}\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] #throughput_metric: host=algo-1, train throughput=458.91527773727046 records/second\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] #quality_metric: host=algo-1, epoch=248, train loss <loss>=8.51501522064209\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] loss did not improve\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Loading parameters from best epoch (208)\n",
      "#metrics {\"StartTime\": 1727755981.608782, \"EndTime\": 1727755981.6146553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 5.502223968505859, \"count\": 1, \"min\": 5.502223968505859, \"max\": 5.502223968505859}}}\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] stopping training now\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Final loss: 8.208834821527654 (occurred at epoch 208)\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] #quality_metric: host=algo-1, train final_loss <loss>=8.208834821527654\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Worker algo-1 finished training.\n",
      "[10/01/2024 04:13:01 WARNING 140492683822912] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1727755981.614716, \"EndTime\": 1727755981.7115011, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 95.75271606445312, \"count\": 1, \"min\": 95.75271606445312, \"max\": 95.75271606445312}}}\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1727755981.7115674, \"EndTime\": 1727755981.739406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 123.79670143127441, \"count\": 1, \"min\": 123.79670143127441, \"max\": 123.79670143127441}}}\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Serializing to /opt/ml/model/model_algo-1\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1727755981.7394865, \"EndTime\": 1727755981.7439919, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 4.474401473999023, \"count\": 1, \"min\": 4.474401473999023, \"max\": 4.474401473999023}}}\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Successfully serialized the model for prediction.\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] #memory_usage::<batchbuffer> = 29.92919921875 mb\n",
      "[10/01/2024 04:13:01 INFO 140492683822912] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1727755981.7440345, \"EndTime\": 1727755981.7536151, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.03719329833984375, \"count\": 1, \"min\": 0.03719329833984375, \"max\": 0.03719329833984375}}}\n",
      "[10/01/2024 04:13:05 INFO 140492683822912] Number of test batches scored: 10\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] Number of test batches scored: 20\n",
      "#metrics {\"StartTime\": 1727755981.7536774, \"EndTime\": 1727755988.1017652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 6348.195314407349, \"count\": 1, \"min\": 6348.195314407349, \"max\": 6348.195314407349}}}\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, RMSE): 5273.286962554369\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, mean_absolute_QuantileLoss): 17621524.423730385\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, mean_wQuantileLoss): 0.12961222511882975\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.1]): 0.06582907202466746\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.2]): 0.10011188429884071\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.3]): 0.12515109633830523\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.4]): 0.1436293946483109\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.5]): 0.15572022495311752\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.6]): 0.16080449222389512\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.7]): 0.157798311817115\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.8]): 0.14405241176881983\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #test_score (algo-1, wQuantileLoss[0.9]): 0.11341313799639582\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #quality_metric: host=algo-1, test RMSE <loss>=5273.286962554369\n",
      "[10/01/2024 04:13:08 INFO 140492683822912] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.12961222511882975\n",
      "#metrics {\"StartTime\": 1727755988.1018434, \"EndTime\": 1727755988.1162004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 4.38380241394043, \"count\": 1, \"min\": 4.38380241394043, \"max\": 4.38380241394043}, \"totaltime\": {\"sum\": 323841.33076667786, \"count\": 1, \"min\": 323841.33076667786, \"max\": 323841.33076667786}}}\n",
      "\n",
      "2024-10-01 04:13:42 Uploading - Uploading generated training model\n",
      "2024-10-01 04:13:42 Completed - Training job completed\n",
      "Training seconds: 632\n",
      "Billable seconds: 632\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_deepar_gold_dataset_path), \"test\": \"{}/val/\".format(s3_deepar_gold_dataset_path)}\n",
    "history = estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# initialize estimator\n",
    "tuned_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m5.xlarge\",\n",
    "    base_job_name=\"store-sales-forecasting-deepar\",\n",
    "    output_path=s3_output_path,\n",
    "    hyperparameters={\"time_freq\": deepar_freq, \"prediction_length\": str(deepar_prediction_length)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {    \n",
    "    \"epochs\": IntegerParameter(50, 1000),\n",
    "    \"context_length\": IntegerParameter(1, 200),\n",
    "    \"mini_batch_size\": IntegerParameter(32, 1028),\n",
    "    \"learning_rate\": ContinuousParameter(0.00001, 0.1, scaling_type=\"Logarithmic\"),\n",
    "    \"num_cells\": IntegerParameter(30, 200)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: deepar-hyperparamete-241001-0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "# run hyperparameter tuner to search for optimal hyperparameters\n",
    "training_job_name = \"deepar-hyperparameter-tuning-job\"\n",
    "tuner = HyperparameterTuner(\n",
    "    tuned_estimator,\n",
    "    \"test:RMSE\",\n",
    "    hyperparameter_ranges,\n",
    "    [{\"Name\": \"test:RMSE\", \"Regex\": \"test:RMSE: ([0-9\\\\.]+)\"}],\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=\"Minimize\",\n",
    "    base_tuning_job_name=training_job_name,\n",
    ")\n",
    "tuner.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the tuning job name for monitoring\n",
    "tuning_job_name  = \"deepar-hyperparamete-241001-0503\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reminder: the tuning job has not been completed.\n",
      "7 training jobs have completed\n",
      "{'BestTrainingJob': {'CreationTime': datetime.datetime(2024, 10, 1, 5, 3, 39, tzinfo=tzlocal()),\n",
      "                     'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'test:RMSE',\n",
      "                                                                     'Value': 4681.43701171875},\n",
      "                     'ObjectiveStatus': 'Succeeded',\n",
      "                     'TrainingEndTime': datetime.datetime(2024, 10, 1, 5, 30, 50, tzinfo=tzlocal()),\n",
      "                     'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:053585949834:training-job/deepar-hyperparamete-241001-0503-001-918206fd',\n",
      "                     'TrainingJobName': 'deepar-hyperparamete-241001-0503-001-918206fd',\n",
      "                     'TrainingJobStatus': 'Completed',\n",
      "                     'TrainingStartTime': datetime.datetime(2024, 10, 1, 5, 4, 24, tzinfo=tzlocal()),\n",
      "                     'TunedHyperParameters': {'context_length': '3',\n",
      "                                              'epochs': '101',\n",
      "                                              'learning_rate': '0.0006294407061415784',\n",
      "                                              'mini_batch_size': '1024',\n",
      "                                              'num_cells': '97'}},\n",
      " 'ConsumedResources': {'RuntimeInSeconds': 38418},\n",
      " 'CreationTime': datetime.datetime(2024, 10, 1, 5, 3, 33, 972000, tzinfo=tzlocal()),\n",
      " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:053585949834:hyper-parameter-tuning-job/deepar-hyperparamete-241001-0503',\n",
      " 'HyperParameterTuningJobConfig': {'HyperParameterTuningJobObjective': {'MetricName': 'test:RMSE',\n",
      "                                                                        'Type': 'Minimize'},\n",
      "                                   'ParameterRanges': {'CategoricalParameterRanges': [],\n",
      "                                                       'ContinuousParameterRanges': [{'MaxValue': '0.1',\n",
      "                                                                                      'MinValue': '1e-05',\n",
      "                                                                                      'Name': 'learning_rate',\n",
      "                                                                                      'ScalingType': 'Logarithmic'}],\n",
      "                                                       'IntegerParameterRanges': [{'MaxValue': '1000',\n",
      "                                                                                   'MinValue': '50',\n",
      "                                                                                   'Name': 'epochs',\n",
      "                                                                                   'ScalingType': 'Auto'},\n",
      "                                                                                  {'MaxValue': '200',\n",
      "                                                                                   'MinValue': '1',\n",
      "                                                                                   'Name': 'context_length',\n",
      "                                                                                   'ScalingType': 'Auto'},\n",
      "                                                                                  {'MaxValue': '1028',\n",
      "                                                                                   'MinValue': '32',\n",
      "                                                                                   'Name': 'mini_batch_size',\n",
      "                                                                                   'ScalingType': 'Auto'},\n",
      "                                                                                  {'MaxValue': '200',\n",
      "                                                                                   'MinValue': '30',\n",
      "                                                                                   'Name': 'num_cells',\n",
      "                                                                                   'ScalingType': 'Auto'}]},\n",
      "                                   'ResourceLimits': {'MaxNumberOfTrainingJobs': 10,\n",
      "                                                      'MaxParallelTrainingJobs': 2},\n",
      "                                   'Strategy': 'Bayesian',\n",
      "                                   'TrainingJobEarlyStoppingType': 'Off'},\n",
      " 'HyperParameterTuningJobName': 'deepar-hyperparamete-241001-0503',\n",
      " 'HyperParameterTuningJobStatus': 'InProgress',\n",
      " 'LastModifiedTime': datetime.datetime(2024, 10, 1, 15, 43, 52, 249000, tzinfo=tzlocal()),\n",
      " 'ObjectiveStatusCounters': {'Failed': 2, 'Pending': 1, 'Succeeded': 7},\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '4117',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Tue, 01 Oct 2024 15:50:10 GMT',\n",
      "                                      'x-amzn-requestid': '2de4f874-4c57-4be7-ac9a-c11f0c9ec8f9'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '2de4f874-4c57-4be7-ac9a-c11f0c9ec8f9',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TrainingJobDefinition': {'AlgorithmSpecification': {'MetricDefinitions': [{'Name': 'test:mean_wQuantileLoss',\n",
      "                                                                             'Regex': '#quality_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'test '\n",
      "                                                                                      'mean_wQuantileLoss '\n",
      "                                                                                      '<loss>=(\\\\S+)'},\n",
      "                                                                            {'Name': 'train:loss:batch',\n",
      "                                                                             'Regex': '#quality_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'epoch=\\\\S+, '\n",
      "                                                                                      'batch=\\\\S+ '\n",
      "                                                                                      'train '\n",
      "                                                                                      'loss '\n",
      "                                                                                      '<loss>=(\\\\S+)'},\n",
      "                                                                            {'Name': 'train:progress',\n",
      "                                                                             'Regex': '#progress_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'completed '\n",
      "                                                                                      '(\\\\S+) '\n",
      "                                                                                      '%'},\n",
      "                                                                            {'Name': 'train:loss',\n",
      "                                                                             'Regex': '#quality_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'epoch=\\\\S+, '\n",
      "                                                                                      'train '\n",
      "                                                                                      'loss '\n",
      "                                                                                      '<loss>=(\\\\S+)'},\n",
      "                                                                            {'Name': 'train:final_loss',\n",
      "                                                                             'Regex': '#quality_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'train '\n",
      "                                                                                      'final_loss '\n",
      "                                                                                      '<loss>=(\\\\S+)'},\n",
      "                                                                            {'Name': 'train:throughput',\n",
      "                                                                             'Regex': '#throughput_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'train '\n",
      "                                                                                      'throughput=(\\\\S+) '\n",
      "                                                                                      'records/second'},\n",
      "                                                                            {'Name': 'test:RMSE',\n",
      "                                                                             'Regex': '#quality_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'test '\n",
      "                                                                                      'RMSE '\n",
      "                                                                                      '<loss>=(\\\\S+)'},\n",
      "                                                                            {'Name': 'test:RMSE',\n",
      "                                                                             'Regex': 'test:RMSE: '\n",
      "                                                                                      '([0-9\\\\.]+)'},\n",
      "                                                                            {'Name': 'ObjectiveMetric',\n",
      "                                                                             'Regex': '#quality_metric: '\n",
      "                                                                                      'host=\\\\S+, '\n",
      "                                                                                      'test '\n",
      "                                                                                      'RMSE '\n",
      "                                                                                      '<loss>=(\\\\S+)'}],\n",
      "                                                      'TrainingImage': '522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:1',\n",
      "                                                      'TrainingInputMode': 'File'},\n",
      "                           'EnableInterContainerTrafficEncryption': False,\n",
      "                           'EnableManagedSpotTraining': False,\n",
      "                           'EnableNetworkIsolation': False,\n",
      "                           'InputDataConfig': [{'ChannelName': 'train',\n",
      "                                                'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                                'S3DataType': 'S3Prefix',\n",
      "                                                                                'S3Uri': 's3://sagemaker-us-east-1-053585949834/store-sales-forecasting/deepar/gold-dataset/train/'}}},\n",
      "                                               {'ChannelName': 'test',\n",
      "                                                'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                                'S3DataType': 'S3Prefix',\n",
      "                                                                                'S3Uri': 's3://sagemaker-us-east-1-053585949834/store-sales-forecasting/deepar/gold-dataset/val/'}}}],\n",
      "                           'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-053585949834/store-sales-forecasting/deepar/gold-dataset/output'},\n",
      "                           'ResourceConfig': {'InstanceCount': 1,\n",
      "                                              'InstanceType': 'ml.m5.xlarge',\n",
      "                                              'VolumeSizeInGB': 30},\n",
      "                           'RoleArn': 'arn:aws:iam::053585949834:role/LabRole',\n",
      "                           'StaticHyperParameters': {'_tuning_objective_metric': 'test:RMSE',\n",
      "                                                     'prediction_length': '7',\n",
      "                                                     'time_freq': '1D'},\n",
      "                           'StoppingCondition': {'MaxRuntimeInSeconds': 86400}},\n",
      " 'TrainingJobStatusCounters': {'Completed': 7,\n",
      "                               'InProgress': 1,\n",
      "                               'NonRetryableError': 2,\n",
      "                               'RetryableError': 0,\n",
      "                               'Stopped': 0},\n",
      " 'TuningJobCompletionDetails': {'NumberOfTrainingJobsObjectiveNotImproving': 6}}\n"
     ]
    }
   ],
   "source": [
    "# Monitor status of the tuning job\n",
    "from pprint import pprint\n",
    "\n",
    "tuning_job_result = sm.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "\n",
    "status = tuning_job_result[\"HyperParameterTuningJobStatus\"]\n",
    "if status != \"Completed\":\n",
    "    print(\"Reminder: the tuning job has not been completed.\")\n",
    "\n",
    "job_count = tuning_job_result[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "\n",
    "objective = tuning_job_result[\"HyperParameterTuningJobConfig\"][\"HyperParameterTuningJobObjective\"]\n",
    "is_minimize = objective[\"Type\"] != \"Maximize\"\n",
    "objective_name = objective[\"MetricName\"]\n",
    "\n",
    "# print out full job\n",
    "pprint(tuning_job_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found so far:\n",
      "{'CreationTime': datetime.datetime(2024, 10, 1, 5, 3, 39, tzinfo=tzlocal()),\n",
      " 'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'test:RMSE',\n",
      "                                                 'Value': 4681.43701171875},\n",
      " 'ObjectiveStatus': 'Succeeded',\n",
      " 'TrainingEndTime': datetime.datetime(2024, 10, 1, 5, 30, 50, tzinfo=tzlocal()),\n",
      " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:053585949834:training-job/deepar-hyperparamete-241001-0503-001-918206fd',\n",
      " 'TrainingJobName': 'deepar-hyperparamete-241001-0503-001-918206fd',\n",
      " 'TrainingJobStatus': 'Completed',\n",
      " 'TrainingStartTime': datetime.datetime(2024, 10, 1, 5, 4, 24, tzinfo=tzlocal()),\n",
      " 'TunedHyperParameters': {'context_length': '3',\n",
      "                          'epochs': '101',\n",
      "                          'learning_rate': '0.0006294407061415784',\n",
      "                          'mini_batch_size': '1024',\n",
      "                          'num_cells': '97'}}\n"
     ]
    }
   ],
   "source": [
    "# Check best training run from tuning job\n",
    "if tuning_job_result.get(\"BestTrainingJob\", None):\n",
    "    print(\"Best model found so far:\")\n",
    "    pprint(tuning_job_result[\"BestTrainingJob\"])\n",
    "else:\n",
    "    print(\"No training jobs have reported results yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training jobs with valid objective: 7\n",
      "{'lowest': 4681.43701171875, 'highest': 9720.05859375}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_length</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mini_batch_size</th>\n",
       "      <th>num_cells</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>deepar-hyperparamete-241001-0503-001-918206fd</td>\n",
       "      <td>Completed</td>\n",
       "      <td>4681.437012</td>\n",
       "      <td>2024-10-01 05:04:24+00:00</td>\n",
       "      <td>2024-10-01 05:30:50+00:00</td>\n",
       "      <td>1586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>819.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>deepar-hyperparamete-241001-0503-004-d1d4c01b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>4798.756836</td>\n",
       "      <td>2024-10-01 05:43:53+00:00</td>\n",
       "      <td>2024-10-01 06:24:11+00:00</td>\n",
       "      <td>2418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>380.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>deepar-hyperparamete-241001-0503-003-215f7d5a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>4963.909668</td>\n",
       "      <td>2024-10-01 05:33:24+00:00</td>\n",
       "      <td>2024-10-01 06:49:46+00:00</td>\n",
       "      <td>4582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>284.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>deepar-hyperparamete-241001-0503-002-7c75891b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>5310.428223</td>\n",
       "      <td>2024-10-01 05:04:29+00:00</td>\n",
       "      <td>2024-10-01 05:43:34+00:00</td>\n",
       "      <td>2345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>deepar-hyperparamete-241001-0503-007-0525f32c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>5316.124023</td>\n",
       "      <td>2024-10-01 06:50:07+00:00</td>\n",
       "      <td>2024-10-01 09:07:54+00:00</td>\n",
       "      <td>8267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>184.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>deepar-hyperparamete-241001-0503-005-4e1dbda4</td>\n",
       "      <td>Completed</td>\n",
       "      <td>5653.986816</td>\n",
       "      <td>2024-10-01 06:26:11+00:00</td>\n",
       "      <td>2024-10-01 06:41:45+00:00</td>\n",
       "      <td>934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>929.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>deepar-hyperparamete-241001-0503-009-274cf983</td>\n",
       "      <td>Completed</td>\n",
       "      <td>9720.058594</td>\n",
       "      <td>2024-10-01 09:11:21+00:00</td>\n",
       "      <td>2024-10-01 09:38:16+00:00</td>\n",
       "      <td>1615.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_length  epochs  learning_rate  mini_batch_size  num_cells  \\\n",
       "9             3.0   101.0       0.000629           1024.0       97.0   \n",
       "6             2.0   223.0       0.006197            819.0      146.0   \n",
       "7             1.0   819.0       0.001059            380.0      182.0   \n",
       "8             3.0   542.0       0.010141            284.0      102.0   \n",
       "3             6.0   759.0       0.000242           1028.0       34.0   \n",
       "5             1.0   426.0       0.001845            184.0       52.0   \n",
       "1             1.0   154.0       0.000010            929.0       78.0   \n",
       "\n",
       "                                 TrainingJobName TrainingJobStatus  \\\n",
       "9  deepar-hyperparamete-241001-0503-001-918206fd         Completed   \n",
       "6  deepar-hyperparamete-241001-0503-004-d1d4c01b         Completed   \n",
       "7  deepar-hyperparamete-241001-0503-003-215f7d5a         Completed   \n",
       "8  deepar-hyperparamete-241001-0503-002-7c75891b         Completed   \n",
       "3  deepar-hyperparamete-241001-0503-007-0525f32c         Completed   \n",
       "5  deepar-hyperparamete-241001-0503-005-4e1dbda4         Completed   \n",
       "1  deepar-hyperparamete-241001-0503-009-274cf983         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "9          4681.437012 2024-10-01 05:04:24+00:00 2024-10-01 05:30:50+00:00   \n",
       "6          4798.756836 2024-10-01 05:43:53+00:00 2024-10-01 06:24:11+00:00   \n",
       "7          4963.909668 2024-10-01 05:33:24+00:00 2024-10-01 06:49:46+00:00   \n",
       "8          5310.428223 2024-10-01 05:04:29+00:00 2024-10-01 05:43:34+00:00   \n",
       "3          5316.124023 2024-10-01 06:50:07+00:00 2024-10-01 09:07:54+00:00   \n",
       "5          5653.986816 2024-10-01 06:26:11+00:00 2024-10-01 06:41:45+00:00   \n",
       "1          9720.058594 2024-10-01 09:11:21+00:00 2024-10-01 09:38:16+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "9                      1586.0  \n",
       "6                      2418.0  \n",
       "7                      4582.0  \n",
       "8                      2345.0  \n",
       "3                      8267.0  \n",
       "5                       934.0  \n",
       "1                      1615.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values(\"FinalObjectiveValue\", ascending=is_minimize)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\": min(df[\"FinalObjectiveValue\"]), \"highest\": max(df[\"FinalObjectiveValue\"])})\n",
    "        pd.set_option(\"display.max_colwidth\", None)  # Don't truncate TrainingJobName\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
