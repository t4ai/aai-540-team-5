{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62604f2-2f03-4bd4-b777-5b79a625edea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Stored 's3_datalake_path_csv' (str)\n",
      "Stored 'local_data_path_csv' (str)\n",
      "Stored 's3_datalake_path_parquet' (str)\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "%run 0-Environment_Setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7729f9-5f1c-4d58-8fa5-64544ad81088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set session variables\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "train_prefix = \"store-sales-forecasting/train\"\n",
    "test_prefix = \"store-sales-forecasting/test\"\n",
    "val_prefix = \"store-sales-forecasting/val\"\n",
    "transform_input_prefix = \"store-sales-forecasting/transform-input\"\n",
    "transform_output_prefix = \"store-sales-forecasting/transform-output\"\n",
    "transform_results_prefix = \"store-sales-forecasting/transform-results\"\n",
    "baseline_prefix = \"store-sales-forecasting/baseline\"\n",
    "ground_truth_prefix = \"store-sales-forecasting/ground-truth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d1a3a49-2b65-4916-9c94-3c29ecf6e1af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/transform-input/validation_data.ndjson'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.upload_data(\"tmp/validation_data.ndjson\", bucket=bucket, key_prefix=transform_input_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b37bfcd-f00c-440c-8f35-5524752749a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Output path: s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/transform-outputs\n",
      "Capture path: s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/datacapture\n",
      "Report path: s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/reports\n"
     ]
    }
   ],
   "source": [
    "prefix = \"store-sales-forecasting\"\n",
    "data_capture_prefix = \"{}/datacapture\".format(prefix)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(bucket, data_capture_prefix)\n",
    "reports_prefix = \"{}/reports\".format(prefix)\n",
    "s3_report_path = \"s3://{}/{}\".format(bucket, reports_prefix)\n",
    "\n",
    "transform_output_path = \"s3://{}/{}/transform-outputs\".format(bucket, prefix)\n",
    "\n",
    "print(\"Transform Output path: {}\".format(transform_output_path))\n",
    "print(\"Capture path: {}\".format(s3_capture_upload_path))\n",
    "print(\"Report path: {}\".format(s3_report_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965ae122-9981-4c13-844a-48732bebe9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store-sales-forecasting-custom-model-2024-10-15-05-53-46\n",
      "{'ModelName': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46', 'PrimaryContainer': {'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.6-cpu', 'Mode': 'SingleModel', 'ModelDataUrl': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz', 'ModelDataSource': {'S3DataSource': {'S3Uri': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz', 'S3DataType': 'S3Object', 'CompressionType': 'Gzip'}}, 'Environment': {'SAGEMAKER_TFS_NGINX_LOGLEVEL': 'info'}}, 'ExecutionRoleArn': 'arn:aws:iam::342408968837:role/LabRole', 'CreationTime': datetime.datetime(2024, 10, 15, 5, 53, 47, 276000, tzinfo=tzlocal()), 'ModelArn': 'arn:aws:sagemaker:us-east-1:342408968837:model/store-sales-forecasting-custom-model-2024-10-15-05-53-46', 'EnableNetworkIsolation': False, 'DeploymentRecommendation': {'RecommendationStatus': 'COMPLETED', 'RealTimeInferenceRecommendations': [{'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/waO1grQ5', 'InstanceType': 'ml.c6i.xlarge', 'Environment': {}}, {'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/Fl7Duel9', 'InstanceType': 'ml.c5.2xlarge', 'Environment': {}}, {'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/V7SKdrtB', 'InstanceType': 'ml.c5.large', 'Environment': {}}]}, 'ResponseMetadata': {'RequestId': '58a5eaec-5d4c-4142-8e01-8f1e0f798cbc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '58a5eaec-5d4c-4142-8e01-8f1e0f798cbc', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1399', 'date': 'Wed, 16 Oct 2024 17:22:53 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Get most recent model info\n",
    "model_name = sm_client.list_models()['Models'][0]['ModelName']\n",
    "model_info = sm_client.describe_model(ModelName=model_name)\n",
    "model_container = {\n",
    "    \"Image\": model_info['PrimaryContainer']['Image'],\n",
    "    \"ModelDataUrl\": model_info['PrimaryContainer']['ModelDataUrl']\n",
    "}\n",
    "    \n",
    "print(model_name)\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b00966f6-950b-47e7-a14e-05ec6a986cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import BatchDataCaptureConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1fbb78-cac3-4fd0-8b41-863513d61165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: tensorflow-inference-2024-10-16-17-23-53-228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[34mINFO:__main__:PYTHON SERVICE: False\u001b[0m\n",
      "\u001b[34mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[34mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[34mmodel_config_list: {\n",
      "  config: {\n",
      "    name: 'model'\n",
      "    base_path: '/opt/ml/model'\n",
      "    model_platform: 'tensorflow'\n",
      "    model_version_policy: {\n",
      "      specific: {\n",
      "        versions: 1\n",
      "      }\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:15.808730: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:15.808837: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34mTensorFlow ModelServer: 2.6.0-rc2+dev.sha.dca3641\u001b[0m\n",
      "\u001b[34mTensorFlow Library: 2.6.0\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0    \u001b[0m\n",
      "\u001b[34mINFO:__main__:started tensorflow serving (pid: 16)\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:Trying to connect with model server: http://localhost:10001/v1/models/model\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280940>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.300621: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.300733: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.302572: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.302602: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.402932: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.402981: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.402991: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.403004: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.403053: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.433072: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.433125: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.433252: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.434413: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280bb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.561578: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.698662: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.766158: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 363099 microseconds.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.774507: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.785112: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.785162: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.786302: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.786380: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.786395: I tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.787876: I tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[34m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.788730: I tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[34m[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280dc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:<Response [200]>\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:model: http://localhost:10001/v1/models/model is available now\u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[34mload_module modules/ngx_http_js_module.so;\u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr info;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_import tensorflowServing.js;\n",
      "  proxy_read_timeout 60;  \n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "    set $tfs_version 2.6;\n",
      "    set $default_tfs_model model;\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "    location /ping {\n",
      "        js_content tensorflowServing.ping;\n",
      "    }\n",
      "    location /invocations {\n",
      "        js_content tensorflowServing.invocations;\n",
      "    }\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "  \u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[34mnginx version: nginx/1.22.0\u001b[0m\n",
      "\u001b[34mbuilt by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34mbuilt with OpenSSL 1.1.1f  31 Mar 2020\u001b[0m\n",
      "\u001b[34mTLS SNI support enabled\u001b[0m\n",
      "\u001b[34mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.22.0/debian/debuild-base/nginx-1.22.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[34mINFO:__main__:started nginx (pid: 73)\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: nginx/1.22.0\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: built by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: OS: Linux 4.14.352-268.568.amzn2.x86_64\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker processes\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 74\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 75\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 76\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 77\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:20 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:20 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:20 [info] 74#74: *1 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\n",
      "\u001b[32m2024-10-16T17:29:20.117:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:23 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:23 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:23 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [16/Oct/2024:17:29:23 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:26 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:26 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:26 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [16/Oct/2024:17:29:26 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mINFO:__main__:PYTHON SERVICE: False\u001b[0m\n",
      "\u001b[34mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[34mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[34mmodel_config_list: {\n",
      "  config: {\n",
      "    name: 'model'\n",
      "    base_path: '/opt/ml/model'\n",
      "    model_platform: 'tensorflow'\n",
      "    model_version_policy: {\n",
      "      specific: {\n",
      "        versions: 1\n",
      "      }\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:15.808730: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:15.808837: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35mINFO:__main__:PYTHON SERVICE: False\u001b[0m\n",
      "\u001b[35mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[35mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[35mmodel_config_list: {\n",
      "  config: {\n",
      "    name: 'model'\n",
      "    base_path: '/opt/ml/model'\n",
      "    model_platform: 'tensorflow'\n",
      "    model_version_policy: {\n",
      "      specific: {\n",
      "        versions: 1\n",
      "      }\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:15.808730: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:15.808837: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34mTensorFlow ModelServer: 2.6.0-rc2+dev.sha.dca3641\u001b[0m\n",
      "\u001b[34mTensorFlow Library: 2.6.0\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0    \u001b[0m\n",
      "\u001b[34mINFO:__main__:started tensorflow serving (pid: 16)\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:Trying to connect with model server: http://localhost:10001/v1/models/model\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280940>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.300621: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.300733: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.302572: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.302602: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.402932: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.402981: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.402991: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.403004: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.403053: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.433072: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.433125: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.433252: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.434413: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280bb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.561578: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.698662: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.766158: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 363099 microseconds.\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.774507: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.785112: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.785162: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.786302: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.786380: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.786395: I tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\u001b[0m\n",
      "\u001b[35mTensorFlow ModelServer: 2.6.0-rc2+dev.sha.dca3641\u001b[0m\n",
      "\u001b[35mTensorFlow Library: 2.6.0\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0    \u001b[0m\n",
      "\u001b[35mINFO:__main__:started tensorflow serving (pid: 16)\u001b[0m\n",
      "\u001b[35mINFO:tfs_utils:Trying to connect with model server: http://localhost:10001/v1/models/model\u001b[0m\n",
      "\u001b[35mWARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280940>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.300621: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.300733: W external/org_tensorflow/tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.302572: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.302602: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.402932: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.402981: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.402991: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.403004: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.403053: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.433072: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.433125: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/1\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.433252: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.434413: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[35mWARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280bb0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.561578: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.698662: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.766158: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 363099 microseconds.\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.774507: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.785112: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.785162: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.786302: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.786380: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.786395: I tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.787876: I tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[34m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[34m2024-10-16 17:29:16.788730: I tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[34m[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[34mWARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280dc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:<Response [200]>\u001b[0m\n",
      "\u001b[34mINFO:tfs_utils:model: http://localhost:10001/v1/models/model is available now\u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[34mload_module modules/ngx_http_js_module.so;\u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr info;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.787876: I tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[35m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[35m2024-10-16 17:29:16.788730: I tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[35m[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[35mWARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f76f8280dc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /v1/models/model\u001b[0m\n",
      "\u001b[35mINFO:tfs_utils:<Response [200]>\u001b[0m\n",
      "\u001b[35mINFO:tfs_utils:model: http://localhost:10001/v1/models/model is available now\u001b[0m\n",
      "\u001b[35mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[35mload_module modules/ngx_http_js_module.so;\u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr info;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_import tensorflowServing.js;\n",
      "  proxy_read_timeout 60;  \n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "    set $tfs_version 2.6;\n",
      "    set $default_tfs_model model;\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "    location /ping {\n",
      "        js_content tensorflowServing.ping;\n",
      "    }\n",
      "    location /invocations {\n",
      "        js_content tensorflowServing.invocations;\n",
      "    }\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "  \u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[34mnginx version: nginx/1.22.0\u001b[0m\n",
      "\u001b[34mbuilt by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34mbuilt with OpenSSL 1.1.1f  31 Mar 2020\u001b[0m\n",
      "\u001b[34mTLS SNI support enabled\u001b[0m\n",
      "\u001b[34mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.22.0/debian/debuild-base/nginx-1.22.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[34mINFO:__main__:started nginx (pid: 73)\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: nginx/1.22.0\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: built by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: OS: Linux 4.14.352-268.568.amzn2.x86_64\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker processes\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 74\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 75\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_import tensorflowServing.js;\n",
      "  proxy_read_timeout 60;  \n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "    set $tfs_version 2.6;\n",
      "    set $default_tfs_model model;\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "    location /ping {\n",
      "        js_content tensorflowServing.ping;\n",
      "    }\n",
      "    location /invocations {\n",
      "        js_content tensorflowServing.invocations;\n",
      "    }\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "  \u001b[0m\n",
      "\u001b[35mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[35mnginx version: nginx/1.22.0\u001b[0m\n",
      "\u001b[35mbuilt by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[35mbuilt with OpenSSL 1.1.1f  31 Mar 2020\u001b[0m\n",
      "\u001b[35mTLS SNI support enabled\u001b[0m\n",
      "\u001b[35mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.22.0/debian/debuild-base/nginx-1.22.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[35mINFO:__main__:started nginx (pid: 73)\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: using the \"epoll\" event method\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: nginx/1.22.0\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: built by gcc 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: OS: Linux 4.14.352-268.568.amzn2.x86_64\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: getrlimit(RLIMIT_NOFILE): 65536:99999\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: start worker processes\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: start worker process 74\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: start worker process 75\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 76\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:16 [notice] 73#73: start worker process 77\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: start worker process 76\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:16 [notice] 73#73: start worker process 77\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:20 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:20 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:20 [info] 74#74: *1 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [16/Oct/2024:17:29:20 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [16/Oct/2024:17:29:20 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:20 [info] 74#74: *1 client 169.254.255.130 closed keepalive connection\u001b[0m\n",
      "\u001b[32m2024-10-16T17:29:20.117:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:23 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:23 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:23 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [16/Oct/2024:17:29:23 +0000] \"POST /invocations HTTP/1.1\" 200 70681 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2024/10/16 17:29:26 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [16/Oct/2024:17:29:26 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2024/10/16 17:29:26 [warn] 75#75: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/2/00/0000000002 while reading upstream, client: 169.254.255.130, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:10001/v1/models/model:predict\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [16/Oct/2024:17:29:26 +0000] \"POST /invocations HTTP/1.1\" 200 61986 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Configure a transformer for the model\n",
    "transformer = Transformer(\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=transform_output_path,\n",
    "    accept=\"application/jsonlines\"\n",
    ")\n",
    "\n",
    "# Run a batch transform job\n",
    "transformer.transform(\n",
    "    data=f\"s3://{bucket}/{transform_input_prefix}\",\n",
    "    content_type=\"application/jsonlines\",\n",
    "    split_type=\"Line\",\n",
    "    batch_data_capture_config=BatchDataCaptureConfig(\n",
    "        destination_s3_uri=s3_capture_upload_path,\n",
    "        # set it to true for model quality monitoring\n",
    "        generate_inference_id=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "transformer.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "eb061e52-50ea-4b5e-bc68-1c9ede281b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/transform-outputs'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "12c0eb45-2b46-4783-b6dc-2452a660fb23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-16 01:53:05        118 store-sales-forecasting/datacapture/input/2024/10/16/01/4389b70a-87b7-4649-99eb-29a5278a083e.json\n",
      "2024-10-16 04:23:40        118 store-sales-forecasting/datacapture/input/2024/10/16/04/5d4eb61e-075a-482c-addd-b4d00c32c660.json\n",
      "2024-10-16 05:39:07        118 store-sales-forecasting/datacapture/input/2024/10/16/05/c503cfd7-91e9-4460-b13a-7797fc27d28b.json\n",
      "2024-10-16 06:33:55        118 store-sales-forecasting/datacapture/input/2024/10/16/06/9b3fc865-1c0a-4700-834f-fc8648c33f17.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {s3_capture_upload_path}/input/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "69d6444d-57ca-4e56-b55a-0cc9edd98453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-16 01:53:05        124 store-sales-forecasting/datacapture/output/2024/10/16/01/c756b496-6ae5-4900-b4c9-322ad22ca01b.json\n",
      "2024-10-16 04:23:40        124 store-sales-forecasting/datacapture/output/2024/10/16/04/05b1f1f3-54e0-4b8e-83c8-7969328d2ad6.json\n",
      "2024-10-16 05:39:07        124 store-sales-forecasting/datacapture/output/2024/10/16/05/c3a0beac-94f2-4cae-a16d-01b34798b78b.json\n",
      "2024-10-16 06:33:55        124 store-sales-forecasting/datacapture/output/2024/10/16/06/2072fd4b-3ed4-47e3-afb0-f7cd60f1763e.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {s3_capture_upload_path}/output/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc928b2d-65ac-453b-acd2-d3b985aa1670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tmp/validation_data.ndjson.out']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.download_data(path=\"tmp/\", bucket=bucket, key_prefix=\"store-sales-forecasting/transform-outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f10fccd3-63aa-425a-8549-ea5f4ce581cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_targets = np.load(os.path.join(\"tmp\", 'val_targets.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1fb8bc1-0da2-437f-abc2-25d55eb5f4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 54, 1)\n",
      "(76, 54, 1)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "transform_outputs = []\n",
    "with open(\"tmp/validation_data.ndjson.out\", \"r\") as f:\n",
    "    for line in f:\n",
    "        outputs = {}\n",
    "        obj = json.loads(line.strip())\n",
    "       \n",
    "        outputs['SageMakerInferenceId'] = obj['SageMakerInferenceId']\n",
    "        outputs['predictions'] = obj['predictions']\n",
    "        transform_outputs.append(outputs)\n",
    "\n",
    "predictions_array1 = np.array(transform_outputs[0]['predictions'])\n",
    "predictions_array2 = np.array(transform_outputs[1]['predictions'])\n",
    "print(predictions_array1.shape)\n",
    "print(predictions_array2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd0cebc7-49e2-4705-b210-e6ffcde56799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 54, 1)\n",
      "(76, 54, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split val targets to have the same shape as the transform output\n",
    "val_targets1 = val_targets[:predictions_array1.shape[0]]\n",
    "val_targets2 = val_targets[:predictions_array2.shape[0]]\n",
    "print(val_targets1.shape)\n",
    "print(val_targets2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa823283-dc89-4185-acba-07b888c4f5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43a3c1ee-f6fd-486c-85f0-1fe8dbd01a05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9eeb46d4-ad00-4612-b83f-f18bf3f74c6b\n",
      "(4644,)\n",
      "44c45205-62c6-46fc-b43a-d453c7752554\n",
      "(4104,)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Clean out this folder before running again\n",
    "for targets, capture in zip([val_targets1, val_targets2], transform_outputs):\n",
    "    #print(len(item))\n",
    "    #print(item[0].shape)\n",
    "    #print(item[1]['SageMakerInferenceId'])\n",
    "    inference_id = capture['SageMakerInferenceId']\n",
    "    print(inference_id)\n",
    "    print(targets.flatten().shape)\n",
    "    flattened_data = \",\".join(map(str, targets.flatten()))\n",
    "    #flattened_data = \"1,2,3,4\"\n",
    "    \n",
    "    #print(flattened_data)\n",
    "    json.dump(\n",
    "        {\n",
    "            \"groundTruthData\": {\n",
    "                # note that the data has to be a comma delimited string\n",
    "                \"data\": flattened_data,\n",
    "                \"encoding\": \"CSV\",\n",
    "            },\n",
    "            \"eventMetadata\": {\n",
    "                \"eventId\": str(inference_id),\n",
    "            },\n",
    "            \"eventVersion\": \"0\",\n",
    "        },\n",
    "        open(f\"./tmp/ground-truth/{inference_id}.jsonl\", \"w\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c539ba9d-b14e-4171-8cfa-e7c705ecc223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/ground-truth/2024/10/16/06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/ground-truth/2024/10/16/06'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "upload_time = datetime.utcnow()\n",
    "ground_truth_output_path = f\"s3://{bucket}/{ground_truth_prefix}/{upload_time:%Y/%m/%d/%H}\"\n",
    "print(ground_truth_output_path)\n",
    "\n",
    "sagemaker_session.upload_data(f\"tmp/ground-truth/\", bucket=bucket, key_prefix=f\"{ground_truth_prefix}/{upload_time:%Y/%m/%d/%H}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d4ecbf2-013b-44ec-b1b2-f44e77abb4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor, MonitoringDatasetFormat, DatasetFormat, BatchTransformInput\n",
    "from sagemaker.model_monitor import CronExpressionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5722946a-291d-43be-a978-ed078e859d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=1800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5487d1b4-d6c1-42ea-83d9-c24d1172bd81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2024-10-15-23-04-07-046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................!"
     ]
    }
   ],
   "source": [
    "# Run a baseline job to get baseline metrics for the monitor\n",
    "baseline_job = model_quality_monitor.suggest_baseline(\n",
    "    baseline_dataset=f\"s3://{bucket}/{baseline_prefix}/baseline.csv\",\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=f\"s3://{bucket}/{baseline_prefix}/results/\",\n",
    "    problem_type=\"Regression\",\n",
    "    inference_attribute=\"predicted_sales\",\n",
    "    ground_truth_attribute=\"actual_sales\"\n",
    ")\n",
    "\n",
    "baseline_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff6c3158-c3ff-4ae8-bf0d-1dd5c3438817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.model_monitor.model_monitoring.BaseliningJob at 0x7fe942677700>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that baseline job finished\n",
    "baseline_job = model_quality_monitor.latest_baselining_job\n",
    "baseline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ad29bd2-c7c4-4754-82d8-82fb37c964dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': {'value': 0.36809090231994046,\n",
       "  'standard_deviation': 0.00423036689125015},\n",
       " 'mse': {'value': 0.4658149918758164,\n",
       "  'standard_deviation': 0.019959703107999428},\n",
       " 'rmse': {'value': 0.68250640427458,\n",
       "  'standard_deviation': 0.014535927309843825},\n",
       " 'r2': {'value': 0.6925847662229317,\n",
       "  'standard_deviation': 0.006409018712575836}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_job.baseline_statistics().body_dict[\"regression_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "249dc09c-df22-44fb-a825-872eb280c7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>comparison_operator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.368091</td>\n",
       "      <td>GreaterThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.465815</td>\n",
       "      <td>GreaterThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.682506</td>\n",
       "      <td>GreaterThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.692585</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold   comparison_operator\n",
       "mae   0.368091  GreaterThanThreshold\n",
       "mse   0.465815  GreaterThanThreshold\n",
       "rmse  0.682506  GreaterThanThreshold\n",
       "r2    0.692585     LessThanThreshold"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"regression_constraints\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab1172a7-714f-426e-b807-8f212384be1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: monitoring-schedule-2024-10-16-04-17-45-516\n"
     ]
    }
   ],
   "source": [
    "schedule = model_quality_monitor.create_monitoring_schedule(\n",
    "    batch_transform_input=BatchTransformInput(\n",
    "        data_captured_destination_s3_uri=s3_capture_upload_path,\n",
    "        destination=\"/opt/ml/processing/input\",\n",
    "        dataset_format=MonitoringDatasetFormat.json(),\n",
    "        inference_attribute=\"predictions\",\n",
    "    ),\n",
    "    ground_truth_input=f\"s3://{bucket}/{ground_truth_prefix}\",\n",
    "    output_s3_uri=f\"s3://{bucket}/{transform_results_prefix}\",\n",
    "    problem_type=\"Regression\",\n",
    "    constraints=f\"s3://{bucket}/{baseline_prefix}/results/constraints.json\",\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc8f8777-af9a-4982-a068-ca8510dcfdba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:342408968837:monitoring-schedule/monitoring-schedule-2024-10-16-01-55-09-247',\n",
       " 'MonitoringScheduleName': 'monitoring-schedule-2024-10-16-01-55-09-247',\n",
       " 'MonitoringScheduleStatus': 'Pending',\n",
       " 'MonitoringType': 'ModelQuality',\n",
       " 'CreationTime': datetime.datetime(2024, 10, 16, 1, 55, 9, 826000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 10, 16, 1, 55, 9, 888000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'model-quality-job-definition-2024-10-16-01-55-09-247',\n",
       "  'MonitoringType': 'ModelQuality'},\n",
       " 'ResponseMetadata': {'RequestId': '6bd2be42-e6bb-4076-890c-d83b53528a2b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '6bd2be42-e6bb-4076-890c-d83b53528a2b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '546',\n",
       "   'date': 'Wed, 16 Oct 2024 01:55:13 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quality_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4623495d-2e7f-472e-80f0-a65f5b545e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store-sales-forecasting-custom-model-2024-10-15-05-53-46\n",
      "{'ModelName': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46', 'PrimaryContainer': {'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.6-cpu', 'Mode': 'SingleModel', 'ModelDataUrl': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz', 'ModelDataSource': {'S3DataSource': {'S3Uri': 's3://sagemaker-us-east-1-342408968837/store-sales-forecasting/training-output/tensorflow-training-2024-10-15-05-41-38-410/output/model.tar.gz', 'S3DataType': 'S3Object', 'CompressionType': 'Gzip'}}, 'Environment': {'SAGEMAKER_TFS_NGINX_LOGLEVEL': 'info'}}, 'ExecutionRoleArn': 'arn:aws:iam::342408968837:role/LabRole', 'CreationTime': datetime.datetime(2024, 10, 15, 5, 53, 47, 276000, tzinfo=tzlocal()), 'ModelArn': 'arn:aws:sagemaker:us-east-1:342408968837:model/store-sales-forecasting-custom-model-2024-10-15-05-53-46', 'EnableNetworkIsolation': False, 'DeploymentRecommendation': {'RecommendationStatus': 'COMPLETED', 'RealTimeInferenceRecommendations': [{'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/waO1grQ5', 'InstanceType': 'ml.c6i.xlarge', 'Environment': {}}, {'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/Fl7Duel9', 'InstanceType': 'ml.c5.2xlarge', 'Environment': {}}, {'RecommendationId': 'store-sales-forecasting-custom-model-2024-10-15-05-53-46/V7SKdrtB', 'InstanceType': 'ml.c5.large', 'Environment': {}}]}, 'ResponseMetadata': {'RequestId': 'eb71ec99-5170-4864-aba4-4a3aacd569cc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'eb71ec99-5170-4864-aba4-4a3aacd569cc', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1399', 'date': 'Tue, 15 Oct 2024 23:09:25 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bbf34c1-53d1-4e34-9b43-f3320d2a68b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import BatchDataCaptureConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f68237f-7475-487f-93cb-03504dfcba34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d07f10c3-b20f-401f-a77a-36c45e430d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/transform-input/2024/10/16/00\n",
      "s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/transform-output/2024/10/16/00\n",
      "s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/ground-truth/2024/10/16/00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-342408968837/store-sales-forecasting/ground-truth/2024/10/16/00/ground_truth.ndjson'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# upload_time = datetime.utcnow()\n",
    "# transform_input_path = f\"s3://{bucket}/{transform_input_prefix}/{upload_time:%Y/%m/%d/%H}\"\n",
    "# transform_output_path = f\"s3://{bucket}/{transform_output_prefix}/{upload_time:%Y/%m/%d/%H}\"\n",
    "# ground_truth_output_path = f\"s3://{bucket}/{ground_truth_prefix}/{upload_time:%Y/%m/%d/%H}\"\n",
    "# print(transform_input_path)\n",
    "# print(transform_output_path)\n",
    "# print(ground_truth_output_path)\n",
    "\n",
    "# sagemaker_session.upload_data(\"tmp/validation_data.ndjson\", bucket=bucket, key_prefix=f\"{transform_input_prefix}/{upload_time:%Y/%m/%d/%H}\")\n",
    "# sagemaker_session.upload_data(f\"tmp/ground_truth.ndjson\", bucket=bucket, key_prefix=f\"{ground_truth_prefix}/{upload_time:%Y/%m/%d/%H}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6de16ac-e770-421f-89f1-a5d960f24d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Configure a transformer for the model\n",
    "# transformer = Transformer(\n",
    "#     model_name=model_name,\n",
    "#     instance_count=1,\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     strategy=\"MultiRecord\",\n",
    "#     assemble_with=\"Line\",\n",
    "#     output_path=transform_output_path,\n",
    "#     accept=\"application/jsonlines\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ec2d2-a4de-488b-9d1f-0e925adbccbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Run a batch transform job\n",
    "# transformer.transform(\n",
    "#     data=transform_input_path,\n",
    "#     content_type=\"application/jsonlines\",\n",
    "#     split_type=\"Line\"\n",
    "# )\n",
    "\n",
    "# transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a0d107d-9739-4acc-9e77-db5fc29daa4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:342408968837:monitoring-schedule/monitoring-schedule-2024-10-15-23-09-19-671',\n",
       " 'MonitoringScheduleName': 'monitoring-schedule-2024-10-15-23-09-19-671',\n",
       " 'MonitoringScheduleStatus': 'Scheduled',\n",
       " 'MonitoringType': 'ModelQuality',\n",
       " 'CreationTime': datetime.datetime(2024, 10, 15, 23, 9, 20, 245000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 10, 15, 23, 9, 29, 241000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'model-quality-job-definition-2024-10-15-23-09-19-671',\n",
       "  'MonitoringType': 'ModelQuality'},\n",
       " 'ResponseMetadata': {'RequestId': 'dfca7867-1d92-43af-905e-5b5787c2b42e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'dfca7867-1d92-43af-905e-5b5787c2b42e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '548',\n",
       "   'date': 'Tue, 15 Oct 2024 23:29:24 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution = model_quality_monitor.describe_schedule()\n",
    "execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbd17bba-48a2-47b9-8b36-bada4e876c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "866d6245-553b-4ef1-bca2-bb8aae5e46a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for first execution.................................\n",
      "Execution found!\n"
     ]
    }
   ],
   "source": [
    "# Wait for the first execution of the monitoring_schedule\n",
    "print(\"Waiting for first execution\", end=\"\")\n",
    "while True:\n",
    "    execution = model_quality_monitor.describe_schedule().get(\n",
    "        \"LastMonitoringExecutionSummary\"\n",
    "    )\n",
    "    if execution:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(10)\n",
    "print()\n",
    "print(\"Execution found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1bda1-a3c4-4f29-bb5e-bc52fbd72443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
